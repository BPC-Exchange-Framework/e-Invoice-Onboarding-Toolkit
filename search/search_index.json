{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Project Home Welcome Welcome to the E-Invoice Onboarding Toolkit This is a repository for open source software tools created to facilitate market adoption of e-invoices implemented conformant with the Four-Corner Model of an Exchange Framework. Project Goals GOALS: The features of the project as outlined in the project roadmap . Roadmap Feature Feature Phase Purpose of Feature Feature #1 - SML NAPTR DNS Lookup Discovery 1. Create an ID code based on the Buyer's party ID 2. Look up the ID code up in a global internet database to get the address of a website which has more information about the Buyer. Feature #2 - SMP REST API Query Discovery 3. Contact the website from the previous step to make sure the Buyer can in fact handle receiving an e-invoice and where to send it. Feature #3 - AS4 Message header format validation. Delivery 4. Validate that an e-mail message sent to the Buyer is in the correct format. Project Outcomes OUTCOMES: How the features are implemented. Outcome Feature Phase 1. Hashing functionality to derive the URN for look-up in a DNS NAPTR record. Feature #1 Discovery 2. Execute DNS NATPR lookup and extract the relevant SMP URI. Feature #1 Discovery 3. Two REST requests to an SMP server using a REST API to retrieve a Corner 3 URI. Feature #1 Discovery 4. Execute the web service requests to the SMP server. Feature #2 Discovery 5. Extract the Corner 3 endpoint URI from the response from the SMP server. Feature #2 Discovery 6. Validate an E-Invoice ebMS message header for compliance with an AS4 conformance profile. Feature #3 Delivery For information about E-Invoices and the Four-Corner Model please visit the Business Payments Coalition website . Additional documentation, reference materials, and standards can be found on the Oasis-Open.org website . Start with the ebXML specification Site Map Project Home FAQ Outcomes Assumptions Tools and Resources Configure a Python Environment Package Requirements Getting the Code Using the Code Using the Modules SML Hash Functionality DNS Query for SML urn SMP REST API Query Test Cases Discovery Validation JupyterLab/Notebooks Package/Library API accessor.py Project Roadmap Project Artifacts Workflow Glossary of Terms Standards License","title":"Project Home"},{"location":"#project-home","text":"","title":"Project Home"},{"location":"#welcome","text":"Welcome to the E-Invoice Onboarding Toolkit This is a repository for open source software tools created to facilitate market adoption of e-invoices implemented conformant with the Four-Corner Model of an Exchange Framework.","title":"Welcome"},{"location":"#project-goals","text":"GOALS: The features of the project as outlined in the project roadmap . Roadmap Feature Feature Phase Purpose of Feature Feature #1 - SML NAPTR DNS Lookup Discovery 1. Create an ID code based on the Buyer's party ID 2. Look up the ID code up in a global internet database to get the address of a website which has more information about the Buyer. Feature #2 - SMP REST API Query Discovery 3. Contact the website from the previous step to make sure the Buyer can in fact handle receiving an e-invoice and where to send it. Feature #3 - AS4 Message header format validation. Delivery 4. Validate that an e-mail message sent to the Buyer is in the correct format.","title":"Project Goals"},{"location":"#project-outcomes","text":"OUTCOMES: How the features are implemented. Outcome Feature Phase 1. Hashing functionality to derive the URN for look-up in a DNS NAPTR record. Feature #1 Discovery 2. Execute DNS NATPR lookup and extract the relevant SMP URI. Feature #1 Discovery 3. Two REST requests to an SMP server using a REST API to retrieve a Corner 3 URI. Feature #1 Discovery 4. Execute the web service requests to the SMP server. Feature #2 Discovery 5. Extract the Corner 3 endpoint URI from the response from the SMP server. Feature #2 Discovery 6. Validate an E-Invoice ebMS message header for compliance with an AS4 conformance profile. Feature #3 Delivery For information about E-Invoices and the Four-Corner Model please visit the Business Payments Coalition website . Additional documentation, reference materials, and standards can be found on the Oasis-Open.org website . Start with the ebXML specification","title":"Project Outcomes"},{"location":"#site-map","text":"Project Home FAQ Outcomes Assumptions Tools and Resources Configure a Python Environment Package Requirements Getting the Code Using the Code Using the Modules SML Hash Functionality DNS Query for SML urn SMP REST API Query Test Cases Discovery Validation JupyterLab/Notebooks Package/Library API accessor.py Project Roadmap Project Artifacts Workflow Glossary of Terms Standards License","title":"Site Map"},{"location":"_license/","text":"MIT License Copyright (c) 2022 BPC Open Source Tools Project Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"_license/#mit-license","text":"Copyright (c) 2022 BPC Open Source Tools Project Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"},{"location":"accessor/","text":"e-invoice Onboarding Toolkit API accessor Module ::: ../discovery.accessor.Accessor :docstring: :members: call_hash call_dns_lookup call_smp_service_group_url call_smp_service_url","title":"accessor.py"},{"location":"accessor/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"accessor/#accessor-module","text":"::: ../discovery.accessor.Accessor :docstring: :members: call_hash call_dns_lookup call_smp_service_group_url call_smp_service_url","title":"accessor Module"},{"location":"app_handler/","text":"e-invoice Onboarding Toolkit API app_logging Module ::: discovery/app_handler.create_logger :docstring: :members: create_logger","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"app_handler/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"app_handler/#app_logging-module","text":"::: discovery/app_handler.create_logger :docstring: :members: create_logger","title":"app_logging Module"},{"location":"app_logging/","text":"e-invoice Onboarding Toolkit API app_logging Module ::: discovery/app_logging.create_logger :docstring: :members: create_logger","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"app_logging/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"app_logging/#app_logging-module","text":"::: discovery/app_logging.create_logger :docstring: :members: create_logger","title":"app_logging Module"},{"location":"artifacts/","text":"The Repository Repository Layout This project includes the following files, i.e., \"artifacts\" in .py , . md , . txt and other formats, updated as of: 04/13/2022 (April 13th, 2022) /E-Invoice-Onboarding-Toolkit . \u251c\u2500\u2500 .gitignore \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 README.md \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u251c\u2500\u2500 einvoice \u2502 \u251c\u2500\u2500 .env.example.dev \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 delivery \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u2502 \u251c\u2500\u2500 import_xsd.py \u2502 \u2502 \u2514\u2500\u2500 sample_msg.xml \u2502 \u251c\u2500\u2500 discovery \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 accessor.py \u2502 \u2502 \u251c\u2500\u2500 app_handler.py \u2502 \u2502 \u251c\u2500\u2500 app_logging.py \u2502 \u2502 \u251c\u2500\u2500 conf \u2502 \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 config_tool.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 smp_config.py \u2502 \u2502 \u251c\u2500\u2500 create_tracking_id.py \u2502 \u2502 \u251c\u2500\u2500 data \u2502 \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 create_sample_data.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 item_list.csv \u2502 \u2502 \u2502 \u2514\u2500\u2500 per_item_list.csv \u2502 \u2502 \u251c\u2500\u2500 dns_query.py \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u2502 \u251c\u2500\u2500 ebms-header.xml \u2502 \u2502 \u251c\u2500\u2500 einvoice_message_package.py \u2502 \u2502 \u251c\u2500\u2500 line_item.py \u2502 \u2502 \u251c\u2500\u2500 party_address.py \u2502 \u2502 \u251c\u2500\u2500 semantic_model.py \u2502 \u2502 \u251c\u2500\u2500 smp_query.py \u2502 \u2502 \u251c\u2500\u2500 tests \u2502 \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u2502 \u2502 \u251c\u2500\u2500 ez_linter.sh \u2502 \u2502 \u2502 \u251c\u2500\u2500 flake8_linter.sh \u2502 \u2502 \u2502 \u251c\u2500\u2500 hardcore_linter.sh \u2502 \u2502 \u2502 \u251c\u2500\u2500 magic_linter.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 mypy_linter.sh \u2502 \u2502 \u2502 \u251c\u2500\u2500 pycodestyle_linter.sh \u2502 \u2502 \u2502 \u251c\u2500\u2500 pydocstyle_linter.sh \u2502 \u2502 \u2502 \u251c\u2500\u2500 pylint_linter.sh \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_accessor.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_app_logging.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_create_sample_data.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_create_tracking_id.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_dns_query.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_line_item.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_party_address.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_semantic_model.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_smp_query.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_urn.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_urn_hasher.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 unaptr_response.json \u2502 \u2502 \u251c\u2500\u2500 urn.py \u2502 \u2502 \u2514\u2500\u2500 urn_hasher.py \u2502 \u251c\u2500\u2500 docs \u2502 \u2502 \u251c\u2500\u2500 4corners.png \u2502 \u2502 \u251c\u2500\u2500 Four-Conrner-primer.md.txt \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 _license.md \u2502 \u2502 \u251c\u2500\u2500 accessor.md \u2502 \u2502 \u251c\u2500\u2500 accessor_results.png \u2502 \u2502 \u251c\u2500\u2500 app_handler.md \u2502 \u2502 \u251c\u2500\u2500 app_log.png \u2502 \u2502 \u251c\u2500\u2500 app_logging.md \u2502 \u2502 \u251c\u2500\u2500 artifacts.md \u2502 \u2502 \u251c\u2500\u2500 assumptions.md \u2502 \u2502 \u251c\u2500\u2500 create_tracking_id.md \u2502 \u2502 \u251c\u2500\u2500 css \u2502 \u2502 \u2502 \u2514\u2500\u2500 extra.css \u2502 \u2502 \u251c\u2500\u2500 discovery_validation.md \u2502 \u2502 \u251c\u2500\u2500 dns_query.md \u2502 \u2502 \u251c\u2500\u2500 drawio \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Entity Relationships 1.3.drawio \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Functional Capabilities 1.2.drawio \u2502 \u2502 \u2502 \u2514\u2500\u2500 Bounded Context - Participant 1.1.drawio \u2502 \u2502 \u251c\u2500\u2500 einvoice_design.xlsx \u2502 \u2502 \u251c\u2500\u2500 einvoice_message_package.md \u2502 \u2502 \u251c\u2500\u2500 faq.md \u2502 \u2502 \u251c\u2500\u2500 git_workflow.md \u2502 \u2502 \u251c\u2500\u2500 google_colab_pages.md \u2502 \u2502 \u251c\u2500\u2500 index.md \u2502 \u2502 \u251c\u2500\u2500 infrastructure_components.md \u2502 \u2502 \u251c\u2500\u2500 jupyterlab \u2502 \u2502 \u2502 \u251c\u2500\u2500 Validate_bdx-as4.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 Validate_bdx-as4_v2.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 dns_query.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20210119.xsd \u2502 \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u2502 \u2502 \u251c\u2500\u2500 naptr_lookup.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 python_dev.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 sample_msg.xml \u2502 \u2502 \u2502 \u251c\u2500\u2500 tracking_id_sandbox.ipynb \u2502 \u2502 \u2502 \u2514\u2500\u2500 urn_hash_work.ipynb \u2502 \u2502 \u251c\u2500\u2500 line_item.md \u2502 \u2502 \u251c\u2500\u2500 oasis_documentation.md \u2502 \u2502 \u251c\u2500\u2500 outcomes.md \u2502 \u2502 \u251c\u2500\u2500 party_address.md \u2502 \u2502 \u251c\u2500\u2500 pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 4-Corners_Workflow.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 BP-OpenSourceToolsRoadmap.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Functional Capabilities 1.2.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Participant 1.1.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Participants 1.2.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded _Context-Entity_Relationships_1.4.pdf \u2502 \u2502 \u2502 \u2514\u2500\u2500 Bounded_Context-Functional_Capabilities_1.3.pdf \u2502 \u2502 \u251c\u2500\u2500 project_roadmap.md \u2502 \u2502 \u251c\u2500\u2500 python_dev_env.md \u2502 \u2502 \u251c\u2500\u2500 requirements.md \u2502 \u2502 \u251c\u2500\u2500 semantic_model.md \u2502 \u2502 \u251c\u2500\u2500 smp_query.md \u2502 \u2502 \u251c\u2500\u2500 successful_tests.png \u2502 \u2502 \u251c\u2500\u2500 test_cases.md \u2502 \u2502 \u251c\u2500\u2500 the_hash.md \u2502 \u2502 \u251c\u2500\u2500 todo.md \u2502 \u2502 \u251c\u2500\u2500 tools_and_resources.md \u2502 \u2502 \u251c\u2500\u2500 urn.md \u2502 \u2502 \u251c\u2500\u2500 urn_handler.md \u2502 \u2502 \u251c\u2500\u2500 urn_hasher.md \u2502 \u2502 \u251c\u2500\u2500 using_the_modules.md \u2502 \u2502 \u2514\u2500\u2500 working_with_the_code.md \u2502 \u251c\u2500\u2500 mkdocs.yml \u2502 \u2514\u2500\u2500 test \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u251c\u2500\u2500 ez_linter.sh \u2502 \u251c\u2500\u2500 flake8_linter.sh \u2502 \u251c\u2500\u2500 hardcore_linter.sh \u2502 \u251c\u2500\u2500 magic_linter.py \u2502 \u251c\u2500\u2500 mypy_linter.sh \u2502 \u251c\u2500\u2500 pycodestyle_linter.sh \u2502 \u251c\u2500\u2500 pydocstyle_linter.sh \u2502 \u251c\u2500\u2500 pylint_linter.sh \u2502 \u251c\u2500\u2500 test_accessor.py \u2502 \u251c\u2500\u2500 test_app_logging.py \u2502 \u251c\u2500\u2500 test_create_sample_data.py \u2502 \u251c\u2500\u2500 test_create_tracking_id.py \u2502 \u251c\u2500\u2500 test_dns_query.py \u2502 \u251c\u2500\u2500 test_import_xsd.py \u2502 \u251c\u2500\u2500 test_line_item.py \u2502 \u251c\u2500\u2500 test_party_address.py \u2502 \u251c\u2500\u2500 test_semantic_model.py \u2502 \u251c\u2500\u2500 test_smp_query.py \u2502 \u251c\u2500\u2500 test_urn.py \u2502 \u251c\u2500\u2500 test_urn_hasher.py \u2502 \u2514\u2500\u2500 unaptr_response.json \u251c\u2500\u2500 requirements.txt \u2514\u2500\u2500 todo.md 12 directories, 141 files","title":"Project Artifacts"},{"location":"artifacts/#the-repository","text":"","title":"The Repository"},{"location":"artifacts/#repository-layout","text":"This project includes the following files, i.e., \"artifacts\" in .py , . md , . txt and other formats, updated as of: 04/13/2022 (April 13th, 2022) /E-Invoice-Onboarding-Toolkit . \u251c\u2500\u2500 .gitignore \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 README.md \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u251c\u2500\u2500 einvoice \u2502 \u251c\u2500\u2500 .env.example.dev \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 delivery \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u2502 \u251c\u2500\u2500 import_xsd.py \u2502 \u2502 \u2514\u2500\u2500 sample_msg.xml \u2502 \u251c\u2500\u2500 discovery \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 accessor.py \u2502 \u2502 \u251c\u2500\u2500 app_handler.py \u2502 \u2502 \u251c\u2500\u2500 app_logging.py \u2502 \u2502 \u251c\u2500\u2500 conf \u2502 \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 config_tool.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 smp_config.py \u2502 \u2502 \u251c\u2500\u2500 create_tracking_id.py \u2502 \u2502 \u251c\u2500\u2500 data \u2502 \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 create_sample_data.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 item_list.csv \u2502 \u2502 \u2502 \u2514\u2500\u2500 per_item_list.csv \u2502 \u2502 \u251c\u2500\u2500 dns_query.py \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u2502 \u251c\u2500\u2500 ebms-header.xml \u2502 \u2502 \u251c\u2500\u2500 einvoice_message_package.py \u2502 \u2502 \u251c\u2500\u2500 line_item.py \u2502 \u2502 \u251c\u2500\u2500 party_address.py \u2502 \u2502 \u251c\u2500\u2500 semantic_model.py \u2502 \u2502 \u251c\u2500\u2500 smp_query.py \u2502 \u2502 \u251c\u2500\u2500 tests \u2502 \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u2502 \u2502 \u251c\u2500\u2500 ez_linter.sh \u2502 \u2502 \u2502 \u251c\u2500\u2500 flake8_linter.sh \u2502 \u2502 \u2502 \u251c\u2500\u2500 hardcore_linter.sh \u2502 \u2502 \u2502 \u251c\u2500\u2500 magic_linter.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 mypy_linter.sh \u2502 \u2502 \u2502 \u251c\u2500\u2500 pycodestyle_linter.sh \u2502 \u2502 \u2502 \u251c\u2500\u2500 pydocstyle_linter.sh \u2502 \u2502 \u2502 \u251c\u2500\u2500 pylint_linter.sh \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_accessor.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_app_logging.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_create_sample_data.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_create_tracking_id.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_dns_query.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_line_item.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_party_address.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_semantic_model.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_smp_query.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_urn.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_urn_hasher.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 unaptr_response.json \u2502 \u2502 \u251c\u2500\u2500 urn.py \u2502 \u2502 \u2514\u2500\u2500 urn_hasher.py \u2502 \u251c\u2500\u2500 docs \u2502 \u2502 \u251c\u2500\u2500 4corners.png \u2502 \u2502 \u251c\u2500\u2500 Four-Conrner-primer.md.txt \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 _license.md \u2502 \u2502 \u251c\u2500\u2500 accessor.md \u2502 \u2502 \u251c\u2500\u2500 accessor_results.png \u2502 \u2502 \u251c\u2500\u2500 app_handler.md \u2502 \u2502 \u251c\u2500\u2500 app_log.png \u2502 \u2502 \u251c\u2500\u2500 app_logging.md \u2502 \u2502 \u251c\u2500\u2500 artifacts.md \u2502 \u2502 \u251c\u2500\u2500 assumptions.md \u2502 \u2502 \u251c\u2500\u2500 create_tracking_id.md \u2502 \u2502 \u251c\u2500\u2500 css \u2502 \u2502 \u2502 \u2514\u2500\u2500 extra.css \u2502 \u2502 \u251c\u2500\u2500 discovery_validation.md \u2502 \u2502 \u251c\u2500\u2500 dns_query.md \u2502 \u2502 \u251c\u2500\u2500 drawio \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Entity Relationships 1.3.drawio \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Functional Capabilities 1.2.drawio \u2502 \u2502 \u2502 \u2514\u2500\u2500 Bounded Context - Participant 1.1.drawio \u2502 \u2502 \u251c\u2500\u2500 einvoice_design.xlsx \u2502 \u2502 \u251c\u2500\u2500 einvoice_message_package.md \u2502 \u2502 \u251c\u2500\u2500 faq.md \u2502 \u2502 \u251c\u2500\u2500 git_workflow.md \u2502 \u2502 \u251c\u2500\u2500 google_colab_pages.md \u2502 \u2502 \u251c\u2500\u2500 index.md \u2502 \u2502 \u251c\u2500\u2500 infrastructure_components.md \u2502 \u2502 \u251c\u2500\u2500 jupyterlab \u2502 \u2502 \u2502 \u251c\u2500\u2500 Validate_bdx-as4.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 Validate_bdx-as4_v2.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 dns_query.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20210119.xsd \u2502 \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u2502 \u2502 \u251c\u2500\u2500 naptr_lookup.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 python_dev.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 sample_msg.xml \u2502 \u2502 \u2502 \u251c\u2500\u2500 tracking_id_sandbox.ipynb \u2502 \u2502 \u2502 \u2514\u2500\u2500 urn_hash_work.ipynb \u2502 \u2502 \u251c\u2500\u2500 line_item.md \u2502 \u2502 \u251c\u2500\u2500 oasis_documentation.md \u2502 \u2502 \u251c\u2500\u2500 outcomes.md \u2502 \u2502 \u251c\u2500\u2500 party_address.md \u2502 \u2502 \u251c\u2500\u2500 pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 4-Corners_Workflow.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 BP-OpenSourceToolsRoadmap.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Functional Capabilities 1.2.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Participant 1.1.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Participants 1.2.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded _Context-Entity_Relationships_1.4.pdf \u2502 \u2502 \u2502 \u2514\u2500\u2500 Bounded_Context-Functional_Capabilities_1.3.pdf \u2502 \u2502 \u251c\u2500\u2500 project_roadmap.md \u2502 \u2502 \u251c\u2500\u2500 python_dev_env.md \u2502 \u2502 \u251c\u2500\u2500 requirements.md \u2502 \u2502 \u251c\u2500\u2500 semantic_model.md \u2502 \u2502 \u251c\u2500\u2500 smp_query.md \u2502 \u2502 \u251c\u2500\u2500 successful_tests.png \u2502 \u2502 \u251c\u2500\u2500 test_cases.md \u2502 \u2502 \u251c\u2500\u2500 the_hash.md \u2502 \u2502 \u251c\u2500\u2500 todo.md \u2502 \u2502 \u251c\u2500\u2500 tools_and_resources.md \u2502 \u2502 \u251c\u2500\u2500 urn.md \u2502 \u2502 \u251c\u2500\u2500 urn_handler.md \u2502 \u2502 \u251c\u2500\u2500 urn_hasher.md \u2502 \u2502 \u251c\u2500\u2500 using_the_modules.md \u2502 \u2502 \u2514\u2500\u2500 working_with_the_code.md \u2502 \u251c\u2500\u2500 mkdocs.yml \u2502 \u2514\u2500\u2500 test \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u251c\u2500\u2500 ez_linter.sh \u2502 \u251c\u2500\u2500 flake8_linter.sh \u2502 \u251c\u2500\u2500 hardcore_linter.sh \u2502 \u251c\u2500\u2500 magic_linter.py \u2502 \u251c\u2500\u2500 mypy_linter.sh \u2502 \u251c\u2500\u2500 pycodestyle_linter.sh \u2502 \u251c\u2500\u2500 pydocstyle_linter.sh \u2502 \u251c\u2500\u2500 pylint_linter.sh \u2502 \u251c\u2500\u2500 test_accessor.py \u2502 \u251c\u2500\u2500 test_app_logging.py \u2502 \u251c\u2500\u2500 test_create_sample_data.py \u2502 \u251c\u2500\u2500 test_create_tracking_id.py \u2502 \u251c\u2500\u2500 test_dns_query.py \u2502 \u251c\u2500\u2500 test_import_xsd.py \u2502 \u251c\u2500\u2500 test_line_item.py \u2502 \u251c\u2500\u2500 test_party_address.py \u2502 \u251c\u2500\u2500 test_semantic_model.py \u2502 \u251c\u2500\u2500 test_smp_query.py \u2502 \u251c\u2500\u2500 test_urn.py \u2502 \u251c\u2500\u2500 test_urn_hasher.py \u2502 \u2514\u2500\u2500 unaptr_response.json \u251c\u2500\u2500 requirements.txt \u2514\u2500\u2500 todo.md 12 directories, 141 files","title":"Repository Layout"},{"location":"assumptions/","text":"About the E-Invoice Onboarding Toolkit About This project offers examples of Python code written to interact with an access point or discovery service of a Four-Corner Model. Please see the Business Payments Coalition website for more information and an overview of the Model . Assumptions The Four-Corner Model The software included with the project assumes a baseline understanding of the Four-Corner Model and its constituent components. Successful completion of all test cases. Python The primary programming language chosen for the project is Python. To implement and run the code in this project requires a working knowledge of Python. This wiki and additional documentation are intended to further outline how the software is designed to implement the Four-Corner Model.","title":"Assumptions"},{"location":"assumptions/#about-the-e-invoice-onboarding-toolkit","text":"","title":"About the E-Invoice Onboarding Toolkit"},{"location":"assumptions/#about","text":"This project offers examples of Python code written to interact with an access point or discovery service of a Four-Corner Model. Please see the Business Payments Coalition website for more information and an overview of the Model .","title":"About"},{"location":"assumptions/#assumptions","text":"","title":"Assumptions"},{"location":"assumptions/#the-four-corner-model","text":"The software included with the project assumes a baseline understanding of the Four-Corner Model and its constituent components. Successful completion of all test cases.","title":"The Four-Corner Model"},{"location":"assumptions/#python","text":"The primary programming language chosen for the project is Python. To implement and run the code in this project requires a working knowledge of Python. This wiki and additional documentation are intended to further outline how the software is designed to implement the Four-Corner Model.","title":"Python"},{"location":"create_tracking_id/","text":"e-invoice Onboarding Toolkit API create_tracking_id Module ::: ediscovery.accessor.Accessor","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"create_tracking_id/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"create_tracking_id/#create_tracking_id-module","text":"::: ediscovery.accessor.Accessor","title":"create_tracking_id Module"},{"location":"discovery_validation/","text":"Start-to-Finish Start-to-Finish Integration There is not currently an \"end-to-end\" test for the E-Invoice Four-Corner Model to validate the workflow in its entirety. The next best use case is a \"Start-to-Finish\" of the discovery process. Discovery validation entails testing: 1. The hashing functionality to derive the URN for look-up from the specification, the party ID, and the schema ID. 2. Executing the DNS NATPR lookup and extracting the relevant SMP URI. 3. Constructing the two REST requests including the smp service group url and the smp service url . 4. Executing the two REST requests to the SMP server. 5. Extracting the Corner 3 endpoint URI from the response from the SMP server. This funcitonality is provided in the accessor.py module and validation is done in a single test case called test_accessor.py. Execute the \"Start-to-Finish\" test as reference in the more detailed instructions for running the test cases . ./einvoice/discovery/pytest tests/test_accessor.py Successful completion of \"Start-to-Finish\" test case. Further review and analysis of the the Start-to_Finish process can be found in the app.log which for the accessor.py module resides in the ./einvoice/discovery directory. Successful completion of \"Start-to-Finish\" test case recorded in the app.log file.","title":"Discovery Validation"},{"location":"discovery_validation/#start-to-finish","text":"","title":"Start-to-Finish"},{"location":"discovery_validation/#start-to-finish-integration","text":"There is not currently an \"end-to-end\" test for the E-Invoice Four-Corner Model to validate the workflow in its entirety. The next best use case is a \"Start-to-Finish\" of the discovery process. Discovery validation entails testing: 1. The hashing functionality to derive the URN for look-up from the specification, the party ID, and the schema ID. 2. Executing the DNS NATPR lookup and extracting the relevant SMP URI. 3. Constructing the two REST requests including the smp service group url and the smp service url . 4. Executing the two REST requests to the SMP server. 5. Extracting the Corner 3 endpoint URI from the response from the SMP server. This funcitonality is provided in the accessor.py module and validation is done in a single test case called test_accessor.py. Execute the \"Start-to-Finish\" test as reference in the more detailed instructions for running the test cases . ./einvoice/discovery/pytest tests/test_accessor.py Successful completion of \"Start-to-Finish\" test case. Further review and analysis of the the Start-to_Finish process can be found in the app.log which for the accessor.py module resides in the ./einvoice/discovery directory. Successful completion of \"Start-to-Finish\" test case recorded in the app.log file.","title":"Start-to-Finish Integration"},{"location":"dns_query/","text":"e-invoice Onboarding Toolkit API dns_query Module","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"dns_query/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"dns_query/#dns_query-module","text":"","title":"dns_query Module"},{"location":"dns_query_sml/","text":"DNS Query Functionality The code below provides an example of how to query a DNS record, specifically using the NAPTR regex protocol. The important take-away from this exercise is the knowing the NAPTR fields treated as a set , using Python to iterate it, and using the regexp field to directly access the data. The BPC SML Domain The BPC SML Domain is: bpcb2b.net Example - Querying a DNS NAPTR Record 1. Import the necessary module The example implements the dns.resolver Python module. import dns.resolver 2. Provide the hashed URN for look-up For the example, the URN is already created, hashed, and the domain of \"sc-b2b.us\" is appended. (This was functional at the time of initial development.) hashed_value = \"6c24uvqpxrfyweqimfxmsuym3bbjvoikuwmmidquz2a2zzyikdya.sc-b2b.us\" 3. Do the DNS look-up The look-up is returned from the resolve() method of dns.resolver. In this implementation, the method takes two parameters, the query string, and the look-up type. See Resolver Functions and the Default Resolver for the complete method signature. dns.resolver.resolve() return type is dns.resolver.Answer The dns.resolver.resolve() method return type is dns.resolver.Answer . See The dns.resolver.Resolver and dns.resolver.Answer Classes for details on the Answer response class. 4. The NAPTR DNS query response 4a. The response as Rdata Rdata is typed data in one of the known DNS data types, i.e., an IPv4 address for a host, MX record, or NAPTR record. RRset is an Rdata object which supports the Python set API. For details on RRset see Rdataset, RRset, and Node Classes . 4b. The fields in the NAPTR response The returned Rdata data set is in the format as specified by the NATPR protocol and contains the following fields which may be iterated as a set: Domain TTL Class Type Order Preference Flags Service Regexp Replacement The set values are iterated using: for a in lookup.rrset: 4c. The \"regexp\" field of the NATPR response The value of the \"regexp\" field contains the terminal address of the SMP in the format of a regular expression, which is how it would otherwise be used if doing a Session Initiation Protocol (SIP) lookup. The value is directly accessed using: smp_uri = a.regexp 4d. The response as a string Use the String decode() method to change the returned response from Binary to String format. smp_uri = smp_uri.decode() The final response is the terminal SMP URL in the NAPTR regular expression substitution format. Code import dns.resolver hashed_value = \"6c24uvqpxrfyweqimfxmsuym3bbjvoikuwmmidquz2a2zzyikdya.sc-b2b.us\" lookup = dns.resolver.resolve(hashed_value,'NAPTR') print(type(lookup)) for a in lookup.rrset: smp_uri = a.regexp smp_uri = smp_uri.decode() print(smp_uri) Output <class 'dns.resolver.Answer'> !^.*$!https://my-smp-url.com/0123456789!","title":"DNS Query for SML urn"},{"location":"dns_query_sml/#dns-query-functionality","text":"The code below provides an example of how to query a DNS record, specifically using the NAPTR regex protocol. The important take-away from this exercise is the knowing the NAPTR fields treated as a set , using Python to iterate it, and using the regexp field to directly access the data. The BPC SML Domain The BPC SML Domain is: bpcb2b.net","title":"DNS Query Functionality"},{"location":"dns_query_sml/#example-querying-a-dns-naptr-record","text":"","title":"Example - Querying a DNS NAPTR Record"},{"location":"dns_query_sml/#1-import-the-necessary-module","text":"The example implements the dns.resolver Python module. import dns.resolver","title":"1.  Import the necessary module"},{"location":"dns_query_sml/#2-provide-the-hashed-urn-for-look-up","text":"For the example, the URN is already created, hashed, and the domain of \"sc-b2b.us\" is appended. (This was functional at the time of initial development.) hashed_value = \"6c24uvqpxrfyweqimfxmsuym3bbjvoikuwmmidquz2a2zzyikdya.sc-b2b.us\"","title":"2. Provide the hashed URN for look-up"},{"location":"dns_query_sml/#3-do-the-dns-look-up","text":"The look-up is returned from the resolve() method of dns.resolver. In this implementation, the method takes two parameters, the query string, and the look-up type. See Resolver Functions and the Default Resolver for the complete method signature. dns.resolver.resolve() return type is dns.resolver.Answer The dns.resolver.resolve() method return type is dns.resolver.Answer . See The dns.resolver.Resolver and dns.resolver.Answer Classes for details on the Answer response class.","title":"3. Do the DNS look-up"},{"location":"dns_query_sml/#4-the-naptr-dns-query-response","text":"","title":"4. The NAPTR DNS query response"},{"location":"dns_query_sml/#4a-the-response-as-rdata","text":"Rdata is typed data in one of the known DNS data types, i.e., an IPv4 address for a host, MX record, or NAPTR record. RRset is an Rdata object which supports the Python set API. For details on RRset see Rdataset, RRset, and Node Classes .","title":"4a.  The response as Rdata"},{"location":"dns_query_sml/#4b-the-fields-in-the-naptr-response","text":"The returned Rdata data set is in the format as specified by the NATPR protocol and contains the following fields which may be iterated as a set: Domain TTL Class Type Order Preference Flags Service Regexp Replacement The set values are iterated using: for a in lookup.rrset:","title":"4b. The fields in the NAPTR response"},{"location":"dns_query_sml/#4c-the-regexp-field-of-the-natpr-response","text":"The value of the \"regexp\" field contains the terminal address of the SMP in the format of a regular expression, which is how it would otherwise be used if doing a Session Initiation Protocol (SIP) lookup. The value is directly accessed using: smp_uri = a.regexp","title":"4c. The \"regexp\" field of the NATPR response"},{"location":"dns_query_sml/#4d-the-response-as-a-string","text":"Use the String decode() method to change the returned response from Binary to String format. smp_uri = smp_uri.decode() The final response is the terminal SMP URL in the NAPTR regular expression substitution format.","title":"4d. The response as a string"},{"location":"dns_query_sml/#code","text":"import dns.resolver hashed_value = \"6c24uvqpxrfyweqimfxmsuym3bbjvoikuwmmidquz2a2zzyikdya.sc-b2b.us\" lookup = dns.resolver.resolve(hashed_value,'NAPTR') print(type(lookup)) for a in lookup.rrset: smp_uri = a.regexp smp_uri = smp_uri.decode() print(smp_uri)","title":"Code"},{"location":"dns_query_sml/#output","text":"<class 'dns.resolver.Answer'> !^.*$!https://my-smp-url.com/0123456789!","title":"Output"},{"location":"einvoice_message_package/","text":"e-invoice Onboarding Toolkit API einvoice_message_package Module","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"einvoice_message_package/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"einvoice_message_package/#einvoice_message_package-module","text":"","title":"einvoice_message_package Module"},{"location":"faq/","text":"FAQ Q: Who is the audience for this project? A: This software is intended for those interested in participating as service endpoints in a Four-Corner Model framework. The code to implement in the repository is written in the Python programing language. Other toolsets to facilitate the initiative such as Markdown or Docker may also be incorporated where appropriate. Q: What do I need in order to use this code? A: Python 1. Intermediate knowledge of Python. 2. Python 3.6 or greater, Python 3.10 or greater is recommended. . Q: Does this code provide a full end-to-end solution to process an e-invoice? A: This code answers some very domain specific questions regarding e-invoice discovery and delivery using a Four-Corners exchange framework. Specifically it's helpful with: Discovery 1. The hashing functionality to derive the URN for look-up in a DNS NAPTR record. 2. How to do the DNS NATPR lookup and extract the relevant SMP URI. 3. How to construct the two REST requests to an SMP server to retrieve a Corner 3 URI. 4. How to execute the REST requests to the SMP server. 5. How to extract the Corner 3 endpoint URI from the response from the SMP server. Delivery 1. Validating an e-invoice ebXML message header for compliance with an AS4 conformance profile. Q: How do I use the code? A: Here are some ways the code can be examined or worked with: 1. Discovery Valdiation of the URI discovery process.. 2. Test Cases which demonstrate functionality of the modules. 3. Jupyter Notebook sandbox environments at Google Colab Pages which isolate and demonstrate the code in a sandbox. 4. Package/Library API see the Index for links to the code API on the modules themselves.","title":"FAQ"},{"location":"faq/#faq","text":"Q: Who is the audience for this project? A: This software is intended for those interested in participating as service endpoints in a Four-Corner Model framework. The code to implement in the repository is written in the Python programing language. Other toolsets to facilitate the initiative such as Markdown or Docker may also be incorporated where appropriate. Q: What do I need in order to use this code? A: Python 1. Intermediate knowledge of Python. 2. Python 3.6 or greater, Python 3.10 or greater is recommended. . Q: Does this code provide a full end-to-end solution to process an e-invoice? A: This code answers some very domain specific questions regarding e-invoice discovery and delivery using a Four-Corners exchange framework. Specifically it's helpful with: Discovery 1. The hashing functionality to derive the URN for look-up in a DNS NAPTR record. 2. How to do the DNS NATPR lookup and extract the relevant SMP URI. 3. How to construct the two REST requests to an SMP server to retrieve a Corner 3 URI. 4. How to execute the REST requests to the SMP server. 5. How to extract the Corner 3 endpoint URI from the response from the SMP server. Delivery 1. Validating an e-invoice ebXML message header for compliance with an AS4 conformance profile. Q: How do I use the code? A: Here are some ways the code can be examined or worked with: 1. Discovery Valdiation of the URI discovery process.. 2. Test Cases which demonstrate functionality of the modules. 3. Jupyter Notebook sandbox environments at Google Colab Pages which isolate and demonstrate the code in a sandbox. 4. Package/Library API see the Index for links to the code API on the modules themselves.","title":"FAQ"},{"location":"git_workflow/","text":"Sample git workflow A minimal git \"script\" to work with the code. This is a sample workflow of a very rudimentary process to create a branch in Github, add code, and push up to the repo on Github. Create a new branch: git checkout -b <insert branch name here`> Implement your changes Add into the repo: git add . git commit -m <your comment here> git push :pushes your changes up to the remote branch Either create a pull request in Github, or: git checkout main git merge <branch you want to merge here> git push to push main changes up to remote branch","title":"Workflow"},{"location":"git_workflow/#sample-git-workflow","text":"","title":"Sample git workflow"},{"location":"git_workflow/#a-minimal-git-script-to-work-with-the-code","text":"This is a sample workflow of a very rudimentary process to create a branch in Github, add code, and push up to the repo on Github. Create a new branch: git checkout -b <insert branch name here`> Implement your changes Add into the repo: git add . git commit -m <your comment here> git push :pushes your changes up to the remote branch Either create a pull request in Github, or: git checkout main git merge <branch you want to merge here> git push to push main changes up to remote branch","title":"A minimal git \"script\" to work with the code."},{"location":"glossary/","text":"Glossary of Common Terms Below are some of the terms used in context of the project. |Term|Definition| |------|------| | The Four Corners | The Four Corner Model is two parties and two intermediaries, each having a \"corner.\" The parties are the buyer and the seller. The seller initiates the process of sending an e-invoice to the recipient who is the buyer.| | Corner 1 | The Seller| | Corner 2 | The Seller's intermediary or \"Access Point 1.\"| | Corner 3 | The Buyer's intermediary or \"Access Point 2.\"| | Corner 4 | The Buyer| | SML | Service Metadata Locator| | SMP | Service Metadata Publishing|","title":"Glossary of Terms"},{"location":"glossary/#glossary-of-common-terms","text":"Below are some of the terms used in context of the project. |Term|Definition| |------|------| | The Four Corners | The Four Corner Model is two parties and two intermediaries, each having a \"corner.\" The parties are the buyer and the seller. The seller initiates the process of sending an e-invoice to the recipient who is the buyer.| | Corner 1 | The Seller| | Corner 2 | The Seller's intermediary or \"Access Point 1.\"| | Corner 3 | The Buyer's intermediary or \"Access Point 2.\"| | Corner 4 | The Buyer| | SML | Service Metadata Locator| | SMP | Service Metadata Publishing|","title":"Glossary of Common Terms"},{"location":"google_colab_pages/","text":"Jupyter Notebooks on Google Colab Colab Sandboxes JupyterLab is a sandbox development environment which allows for, among other things, rapid prototyping or testing of small units of code. They provide a framework to execute code without building a whole application or even a complete module. Most of the code already incorporated into the project started out in a JupyterLab runtime environment. JupyterLab is also useful for introspection of a piece of code. JupyterLab artifacts worked on for the project are stored as static documents in GitHub in the E-Invoice-Onboarding-Toolkit project under ./einvoice/docs/jupyterlab. Google Colab pages implement JupyterLab runtime with live sandbox environments. Pages can be linked from the E-Invoice-Onboarding-Toolkit GitHub repository, or pulled from the repository and saved locally by anyone with a Google account. URN hashing and DNS NAPTR lookup. The Colab JupyterLab Notebook with examples of how to hash the specification, the schema_id, and the party_id to create the URN and perform the NAPTR DNS query is at this Colab page . Examples 6, 7, 8, and 9 run the hash and submit against a DNS in real-time. The JupyterLab file is: urn_hash_work.ipynb . SMP query The Colab JupyterLab Notebook page with examples of how to transform the URN and party_id and submit it to the SMP URI is at this Colab page . They JupyterLab Notebook file is: smp_url_transformations.ipynb . ebMS Message Header validation The Colab JupyterLab Notebook pages with examples of reading an XSD file and validating an XML file has two Google Colab pages for different aspects of the work. Inspection and validation of the XSD file has this Google Colab Page . The JupyterLab file is: ebMS XML 3 schema.ipynb . Validation of an xml file against the XSD is done using this Google Colab Page The JupyterFile is: Validate_bdx-as4.ipynb . For ease of access these files are copies stored on the drive of one of the project Developers and is free and open to anyone to view and run. Interested individuals should make copies of the Labs for themselves and run on Google Colab under their own account or an instance of JupytyerLab running on Anaconda, VS Code, or a Python install.","title":"JupyterLab/Notebooks"},{"location":"google_colab_pages/#jupyter-notebooks-on-google-colab","text":"","title":"Jupyter Notebooks on Google Colab"},{"location":"google_colab_pages/#colab-sandboxes","text":"JupyterLab is a sandbox development environment which allows for, among other things, rapid prototyping or testing of small units of code. They provide a framework to execute code without building a whole application or even a complete module. Most of the code already incorporated into the project started out in a JupyterLab runtime environment. JupyterLab is also useful for introspection of a piece of code. JupyterLab artifacts worked on for the project are stored as static documents in GitHub in the E-Invoice-Onboarding-Toolkit project under ./einvoice/docs/jupyterlab. Google Colab pages implement JupyterLab runtime with live sandbox environments. Pages can be linked from the E-Invoice-Onboarding-Toolkit GitHub repository, or pulled from the repository and saved locally by anyone with a Google account.","title":"Colab Sandboxes"},{"location":"google_colab_pages/#urn-hashing-and-dns-naptr-lookup","text":"The Colab JupyterLab Notebook with examples of how to hash the specification, the schema_id, and the party_id to create the URN and perform the NAPTR DNS query is at this Colab page . Examples 6, 7, 8, and 9 run the hash and submit against a DNS in real-time. The JupyterLab file is: urn_hash_work.ipynb .","title":"URN hashing and DNS NAPTR lookup."},{"location":"google_colab_pages/#smp-query","text":"The Colab JupyterLab Notebook page with examples of how to transform the URN and party_id and submit it to the SMP URI is at this Colab page . They JupyterLab Notebook file is: smp_url_transformations.ipynb .","title":"SMP query"},{"location":"google_colab_pages/#ebms-message-header-validation","text":"The Colab JupyterLab Notebook pages with examples of reading an XSD file and validating an XML file has two Google Colab pages for different aspects of the work. Inspection and validation of the XSD file has this Google Colab Page . The JupyterLab file is: ebMS XML 3 schema.ipynb . Validation of an xml file against the XSD is done using this Google Colab Page The JupyterFile is: Validate_bdx-as4.ipynb . For ease of access these files are copies stored on the drive of one of the project Developers and is free and open to anyone to view and run. Interested individuals should make copies of the Labs for themselves and run on Google Colab under their own account or an instance of JupytyerLab running on Anaconda, VS Code, or a Python install.","title":"ebMS Message Header validation"},{"location":"infrastructure_components/","text":"Additional Infrastructure Build-out The code is intended to interact with other participants in the Four-Corner Model, including Access Providers, DNS servers and SMP service providers. SML Q: How do you test the toolkit? How do you create a NAPTR DNS record entry on a domain? A: In order to do the SML look-up, the appropriate NAPTR records must be in place. The assumption is that a NAPTR DNS record exists as a key:value pair. A look-up of the \"key\" in the DNS of the NAPTR record will return the \"value.\" The \"key\" is the hashed value of the urn. The value being sought and returned is the URI of the SMP for the next step in the Model. Access Point 1 in Corner 2 may be acting in the role of the SML and handling tasks associated with it. Theses task could include: Constructing the URN Creaitng the hash value of the URN Queryhing the DNS NATPR record URN Returning the SMP URI The Python modules provide examples of some ways the tasks of SML could be accomplished, either as, or by, an Access Point or an organization on its own behalf. For testing purposes there is an application to update a DNS entry with a NAPTR record key:value pair of URN:SMP URI repsonse. The applicatiion updates a the DNS via Amazon Web Services Route53 using the test domain of sc-b2b.us. This allows for the registration of URN hashes in the DNS domain of sc-b2b.us. These entries are live in the DNS and accessible worldwide. The REST API is available at https://sml-api.sc-b2b.us/docs to register SML entries, which are the DNS NATPR records on the sc-b2b.us domain. This process creates the URN hash based in inputs provided by the user. Organizations wishing to register a test URN to use for validation can open an issue in the project for assistance in using the web interface. Once these SML/DNS NATPR entries are created, they can queried using the toolkit to make public queries to DNS NAPTR look-up as soon as propated through the DNS. The code implemented to create the NAPTR DNS record on AWS Route53 is available in the GitHub repository: BPC-OpenSourceTools/sml-service-r53 . SMP There is an application to test the SMP REST API service calls on the same domain as the SML at https://smp-api.sc-b2b.us/docs . This is a REST API to make web service calls to test the toolkit. The SMP s a web service queried by a SOAP API call to return the Corner 3 URI or terminal endpoint. The specification for the actual API can be found in the document: Service Metadata Publishing (SMP) Version 2.0 dated 14 February 2021 as an Oasis standard. Section 5.4 Resources Resource URI Method XML resource root element HTTP Status Description of returned content ServiceGroup ./bdxr-smp-2/[{identifier scheme}::]{participant id} See section 3.6 for {participant id} format GET <ServiceGroup> 200; 500; 404 Holds the Participant Identifier of the recipient, and a list of references to individual ServiceMetadata resources that are associated with that participant identifier. ServiceMetadata ./bdxr-smp-2/[{identifier scheme}::]{participant id}/services/{service ID} See section 3.7 for {service ID} format GET <ServiceMetadata> 200; 500; 404 Holds all of the metadata about a Service, or a redirection URL to another Service Metadata Publisher holding this information. The SMP service registers a URN for query. Note that the API specification is essentially the URN with modifications to include some additional service capability codes but mostly to accomodate characters that would otherwise be illegal in a URL. After registering a URN(s) on the SML service, go to the SMP service at https://sml-api.sc-b2b.us/docs to register the urn there in order to get a reponse for testing SMP query functionality. The code implemented to create the NAPTR DNS record on AWS Route53 is available in the GitHub repository: BPC-OpenSourceTools/smp-service .","title":"Additional Infrastructure Build-out"},{"location":"infrastructure_components/#additional-infrastructure-build-out","text":"The code is intended to interact with other participants in the Four-Corner Model, including Access Providers, DNS servers and SMP service providers.","title":"Additional Infrastructure Build-out"},{"location":"infrastructure_components/#sml","text":"Q: How do you test the toolkit? How do you create a NAPTR DNS record entry on a domain? A: In order to do the SML look-up, the appropriate NAPTR records must be in place. The assumption is that a NAPTR DNS record exists as a key:value pair. A look-up of the \"key\" in the DNS of the NAPTR record will return the \"value.\" The \"key\" is the hashed value of the urn. The value being sought and returned is the URI of the SMP for the next step in the Model. Access Point 1 in Corner 2 may be acting in the role of the SML and handling tasks associated with it. Theses task could include: Constructing the URN Creaitng the hash value of the URN Queryhing the DNS NATPR record URN Returning the SMP URI The Python modules provide examples of some ways the tasks of SML could be accomplished, either as, or by, an Access Point or an organization on its own behalf. For testing purposes there is an application to update a DNS entry with a NAPTR record key:value pair of URN:SMP URI repsonse. The applicatiion updates a the DNS via Amazon Web Services Route53 using the test domain of sc-b2b.us. This allows for the registration of URN hashes in the DNS domain of sc-b2b.us. These entries are live in the DNS and accessible worldwide. The REST API is available at https://sml-api.sc-b2b.us/docs to register SML entries, which are the DNS NATPR records on the sc-b2b.us domain. This process creates the URN hash based in inputs provided by the user. Organizations wishing to register a test URN to use for validation can open an issue in the project for assistance in using the web interface. Once these SML/DNS NATPR entries are created, they can queried using the toolkit to make public queries to DNS NAPTR look-up as soon as propated through the DNS. The code implemented to create the NAPTR DNS record on AWS Route53 is available in the GitHub repository: BPC-OpenSourceTools/sml-service-r53 .","title":"SML"},{"location":"infrastructure_components/#smp","text":"There is an application to test the SMP REST API service calls on the same domain as the SML at https://smp-api.sc-b2b.us/docs . This is a REST API to make web service calls to test the toolkit. The SMP s a web service queried by a SOAP API call to return the Corner 3 URI or terminal endpoint. The specification for the actual API can be found in the document: Service Metadata Publishing (SMP) Version 2.0 dated 14 February 2021 as an Oasis standard. Section 5.4 Resources Resource URI Method XML resource root element HTTP Status Description of returned content ServiceGroup ./bdxr-smp-2/[{identifier scheme}::]{participant id} See section 3.6 for {participant id} format GET <ServiceGroup> 200; 500; 404 Holds the Participant Identifier of the recipient, and a list of references to individual ServiceMetadata resources that are associated with that participant identifier. ServiceMetadata ./bdxr-smp-2/[{identifier scheme}::]{participant id}/services/{service ID} See section 3.7 for {service ID} format GET <ServiceMetadata> 200; 500; 404 Holds all of the metadata about a Service, or a redirection URL to another Service Metadata Publisher holding this information. The SMP service registers a URN for query. Note that the API specification is essentially the URN with modifications to include some additional service capability codes but mostly to accomodate characters that would otherwise be illegal in a URL. After registering a URN(s) on the SML service, go to the SMP service at https://sml-api.sc-b2b.us/docs to register the urn there in order to get a reponse for testing SMP query functionality. The code implemented to create the NAPTR DNS record on AWS Route53 is available in the GitHub repository: BPC-OpenSourceTools/smp-service .","title":"SMP"},{"location":"line_item/","text":"e-invoice Onboarding Toolkit API line_item Module No Representations or Warranties THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"line_item/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"line_item/#line_item-module","text":"","title":"line_item Module"},{"location":"outcomes/","text":"Project Outcomes: Functionality Discovery a. Hashing functionality to derive the URN for look-up in a DNS NAPTR record. b. DNS NATPR lookup and extract the relevant SMP URI. c. Two REST requests to an SMP server to retrieve a Corner 3 URI. d. Execute the REST requests to the SMP server. e. Extract the Corner 3 endpoint URI from the response from the SMP server. Delivery a. Validate an e-invoice ebXML message header for compliance with an AS4 conformance profile. Implementation Functional Python code: Construct the URN from the specification, schema ID, and party ID, urn_hasher.py Hash the URN per the requirements to create a NAPTR record for a DNS look-up to obtain SMP service URI. urn_hasher.py accessor.py Execute DNS look-up to obtain the SMP service URI. accessor.py dns_query.py Query the SMP URI using the ebXML specifcation. accessor.py smp_query.py Dataclass object comprised of specification, schema ID, party ID, and a sample JSON E-Invoice payload. einvoice_message_package.py line_item_py party_address.py semnantic_model.py URN.py Test cases implemented using Test Driven Development test_accessor.py test_app_logging.py test_create_sample_data.py test_create_tracking_id.py test_dns_query.py test_import_xsd.py test_line_item.py test_party_address.py test_semantic_model.py test_smp_query.py test_urn.py test_urn_hasher.py Logging implemented through custom logging using standard Python modules. app_loggiing.py Documentation and code artifacts for Infrastructure components: Demonstrating implementation of DNS infrastructure using Amazon Route53 and code to provision, update, and delete NATPR records, acting as the SML. Demonstrating implementation of SMP infrastructure to reply to the REST API for service functionally and AS4 final endpoint. Documentation Previously created documentation and diagrams which were outcomes of analysis and process review. Jupyter Lab Notebooks running on Google Colab for real-time examples of a dev sandbox. Hash URN and SML query Lab Notebook (Hash URN and SML query are in the same Notebook) SMP query Lab Notebook Review of AS4 XSD specification Lab Notebook Validation of ebMS sample message header against AS4 XSD Lab Notebook Implementation Guide Documentation site written to facilitate utilization of the code and work product to be delivered via readthedocs.org site though the GitHub repository. readthedocs.org site registration/creation Create document set using mkdocs-material hosted on GitHub repository. Create list of assumptions FAQ and Outcomes pages for starting point/baseline documentation. Consolidation of documentation in the GitHub repository. To do A deployment package which includes Python code to: (In-progress)_ Creation of \"final\" Python package which delivers code artifacts as a library. Documentation (In-progress) Generated from python docstring using Sphinx mkdocs-material framework (In-progress) Documentation of supporting infrastructure including DNS and SMP provisioning. Notes Test-driven development methodology is being implemented to include test cases for code as it is being developed and delivered. CI/CD process implemented via GitHub workflow has been validated to ensure PEP8 code standards and checks using flake8, pylint, and pytest are valid. All changes and updates to code must pass CI/CD before it's merged into the repo.","title":"Outcomes"},{"location":"outcomes/#project-outcomes","text":"","title":"Project Outcomes:"},{"location":"outcomes/#functionality","text":"Discovery a. Hashing functionality to derive the URN for look-up in a DNS NAPTR record. b. DNS NATPR lookup and extract the relevant SMP URI. c. Two REST requests to an SMP server to retrieve a Corner 3 URI. d. Execute the REST requests to the SMP server. e. Extract the Corner 3 endpoint URI from the response from the SMP server. Delivery a. Validate an e-invoice ebXML message header for compliance with an AS4 conformance profile.","title":"Functionality"},{"location":"outcomes/#implementation","text":"Functional Python code: Construct the URN from the specification, schema ID, and party ID, urn_hasher.py Hash the URN per the requirements to create a NAPTR record for a DNS look-up to obtain SMP service URI. urn_hasher.py accessor.py Execute DNS look-up to obtain the SMP service URI. accessor.py dns_query.py Query the SMP URI using the ebXML specifcation. accessor.py smp_query.py Dataclass object comprised of specification, schema ID, party ID, and a sample JSON E-Invoice payload. einvoice_message_package.py line_item_py party_address.py semnantic_model.py URN.py Test cases implemented using Test Driven Development test_accessor.py test_app_logging.py test_create_sample_data.py test_create_tracking_id.py test_dns_query.py test_import_xsd.py test_line_item.py test_party_address.py test_semantic_model.py test_smp_query.py test_urn.py test_urn_hasher.py Logging implemented through custom logging using standard Python modules. app_loggiing.py Documentation and code artifacts for Infrastructure components: Demonstrating implementation of DNS infrastructure using Amazon Route53 and code to provision, update, and delete NATPR records, acting as the SML. Demonstrating implementation of SMP infrastructure to reply to the REST API for service functionally and AS4 final endpoint. Documentation Previously created documentation and diagrams which were outcomes of analysis and process review. Jupyter Lab Notebooks running on Google Colab for real-time examples of a dev sandbox. Hash URN and SML query Lab Notebook (Hash URN and SML query are in the same Notebook) SMP query Lab Notebook Review of AS4 XSD specification Lab Notebook Validation of ebMS sample message header against AS4 XSD Lab Notebook Implementation Guide Documentation site written to facilitate utilization of the code and work product to be delivered via readthedocs.org site though the GitHub repository. readthedocs.org site registration/creation Create document set using mkdocs-material hosted on GitHub repository. Create list of assumptions FAQ and Outcomes pages for starting point/baseline documentation. Consolidation of documentation in the GitHub repository.","title":"Implementation"},{"location":"outcomes/#to-do","text":"A deployment package which includes Python code to: (In-progress)_ Creation of \"final\" Python package which delivers code artifacts as a library. Documentation (In-progress) Generated from python docstring using Sphinx mkdocs-material framework (In-progress) Documentation of supporting infrastructure including DNS and SMP provisioning.","title":"To do"},{"location":"outcomes/#notes","text":"Test-driven development methodology is being implemented to include test cases for code as it is being developed and delivered. CI/CD process implemented via GitHub workflow has been validated to ensure PEP8 code standards and checks using flake8, pylint, and pytest are valid. All changes and updates to code must pass CI/CD before it's merged into the repo.","title":"Notes"},{"location":"party_address/","text":"e-invoice Onboarding Toolkit API party_address Module","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"party_address/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"party_address/#party_address-module","text":"","title":"party_address Module"},{"location":"project_roadmap/","text":"Project Roadmap Discovery #1 - SML NAPTR DNS Lookup Feature \u2013 Access Point A sends UNAPTR DNS query with a Party ID/Party ID Schema hash and obtains a valid response with connection information to the SMP. Action Actor Scoped? Generate the request to Access Point A, which includes Party ID, Party ID Schema, Invoice Data Seller No Transform and format contents of Seller\u2019s request to create UNAPTR DNS query Access Point A Yes Query DNS. Access Point A Yes Return response to query SML \u2013 Reply from UNAPTR DNS query. No Receive query response from DNS, which is the URI to the SMP Access Point A Yes Discovery #2 - SMP REST API Query Feature \u2013Access Point A sends a REST API query to the SMP URI to obtain a valid response with connection info of target Access Point and customers invoice capabilities. Action Actor Scoped? Send response with SMP URI to Access Point. SML No (not in this feature) Create REST query to service provider to obtain buyer\u2019s service capabilities. Access Point A Yes Send REST query to service provider to obtain participant\u2019s service capabilities. Access Point A Yes Receive query and send response with Sellers Capabilities and route to endpoint. SMP No Receive response to query of participant\u2019s capabilities. Access Point A Yes Delivery - AS4 Message Exchange Feature \u2013 An invoice with a semantically correct format is delivered using AS4 protocol. Action Actor Scoped? Compose semantically correct E-Invoice based on response from service provider about participant\u2019s capabilities. Access Point A Yes Format E-Invoice in compliant AS4 format. Access Point A Yes Send E-Invoice to final destination obtained from SMP service provider. Access Point A Yes Receives the request. Access Point B No","title":"Project Roadmap"},{"location":"project_roadmap/#project-roadmap","text":"","title":"Project Roadmap"},{"location":"project_roadmap/#discovery-1-sml-naptr-dns-lookup","text":"Feature \u2013 Access Point A sends UNAPTR DNS query with a Party ID/Party ID Schema hash and obtains a valid response with connection information to the SMP. Action Actor Scoped? Generate the request to Access Point A, which includes Party ID, Party ID Schema, Invoice Data Seller No Transform and format contents of Seller\u2019s request to create UNAPTR DNS query Access Point A Yes Query DNS. Access Point A Yes Return response to query SML \u2013 Reply from UNAPTR DNS query. No Receive query response from DNS, which is the URI to the SMP Access Point A Yes","title":"Discovery #1 - SML NAPTR DNS Lookup"},{"location":"project_roadmap/#discovery-2-smp-rest-api-query","text":"Feature \u2013Access Point A sends a REST API query to the SMP URI to obtain a valid response with connection info of target Access Point and customers invoice capabilities. Action Actor Scoped? Send response with SMP URI to Access Point. SML No (not in this feature) Create REST query to service provider to obtain buyer\u2019s service capabilities. Access Point A Yes Send REST query to service provider to obtain participant\u2019s service capabilities. Access Point A Yes Receive query and send response with Sellers Capabilities and route to endpoint. SMP No Receive response to query of participant\u2019s capabilities. Access Point A Yes","title":"Discovery #2 - SMP REST API Query"},{"location":"project_roadmap/#delivery-as4-message-exchange","text":"Feature \u2013 An invoice with a semantically correct format is delivered using AS4 protocol. Action Actor Scoped? Compose semantically correct E-Invoice based on response from service provider about participant\u2019s capabilities. Access Point A Yes Format E-Invoice in compliant AS4 format. Access Point A Yes Send E-Invoice to final destination obtained from SMP service provider. Access Point A Yes Receives the request. Access Point B No","title":"Delivery - AS4 Message Exchange"},{"location":"python_dev_env/","text":"Configure a Python Dev Environment Respecting individual preferences and work style these are some suggested guidelines for creation of a Python development environment. These are consistent with Python standards and best practices and appropriate as a starting point for professional software development in Python. Installing Python The correct method of installing Python varies depending on the OS. Here are some considerations based on popular OS. OS Considerations MacOS Mac OS comes configured with Python 2.x. This version of Python is required by the OS and removal will impair system function. Homebrew is a package installer for Mac. Using Homebrew to install Python versions prior to 3.7 may generate errors on instal due to deprecated libraries. That isues has been resolved for versions 3.7 and higher. Apple XCode Developer Tools installs Git and a version of Python. Available through the App Store it is a large download and system intensive program which may not run smoothly on older or less robust systmes. A more granular installation would be the XCode Command Line Tools which installs Git combined with a Python install pulled directly from Python.org. WindowsOS Python is now available on the Windows Store , though updates may lag behind current Python releases at python.org before arriving on the Windows Store. The option to set environment variables via a UI on a per user basis facilitates multiple installed versions simultaneously. VS Code from Miscrosoft integrates direcltly with a system installled version of Python. Windows WLS2 A fully native Python install on Ubuntu is available for Windows Subsystem for Linux 2 . The version of Python may need to be updated from a secondary repository as the official Ubuntu version trails official Python releases. Integration between VS Code running on Windows and integration with WSL2 Python may require custom configuration. Linux A variety of package managers based on the installed distro enable installation and updates through a GUI or command line. Python3 Python is officially referred to and invoked by specfiying either Python 2.x as \"Python2\" or Python 3.x.x as \"Python3.\" The difference is generally trivial except on Macs where Python2 is included as part of the OS install. On Mac and Linux based systems, adding an alias to .bashrc or .zshrc is an easy way to prevent inadvertent references to an incorrect version of Python, e.g., alias python='python3' alias pip='pip3' Note that the above included an alias for pip to pip3 as well. Create a virtual environment to use for Dev A Python virtual environment is a development sandbox which allows for segmentation of development environments. This allows for management of different combinations and versions of Python releases, deployed packages, development and testing environments, and shifting between entirely different development projects. See the Python documentation for venv for a more detailed explanation and rationalization of Python virtual environments. The use of Python virtual environments can't be overstated as a best practice to organize Python versions and package management. PEP-405 Creating virtual environments to use in Python programming can be done entirely with packages that are include in the Python install or by additional third party applications. The choice of tools to create and manage Python virtual environments is dependent on situation, preference, and use case. Tool/App Use Case venv Implementation of the virtualenv as a Python module included in the Python install since v.3.3. This tool does not require installation outside of the Python distribution itself. virtualenv Includes features not included in venv (see the comparison ). Anaconda A heavyweight package and virtual environment manager. It acts as an \"all in one\" for Python application versions, package management, virtual environments, additional programming languages such as R and Julia and tools such as visualizers and IDEs. The full fledged install can overtax some systems and performance can suffer from an overly ambitious installation configuration. A personal license for individuals is free for non-commercial use. Use by for-profit or governmental organizations with more than 200 people requires licensing. miniconda A slimmed down version of Anaconda focused on virtual environment and package management, includes only conda and Python, not open source, but free. conda The open source package manager utilized by Anaconda and miniconda. pip Included in Python 3.4 and later, this tool does not manage the virtual environment but does handle package management for both venv and virtualenv. Not all python tools have been integrated into the Anaconda repositories or packages for install. Some, such as mkdocs, must still be installed via pip even when using Anaconda3 or miniconda. 'virtualenv venv' vs. 'venv virtualenv' Avoid the confusion of the typical example given in the documentation of virtualenv which uses the command executed as \"virtualenv venv.\" This calls virtualenv to create a virtual environment named venv . Compare with \"venv virtualenv\" which calls venv to create a virtual environment called virtualenv . For most practical purposes when using Python 3.6 or greater it doesn't matter whether venv or virtualenv is used to create the virtual instance. It's recommended to name a virutal environment with a single word unique identifier as the word will be prefixed to the terminal command line when the virtual environment is activated. Other Python Tools Other tools such as virtualenvwrapper , pipenv , pew , tox and nox , poetry , and black may be useful but are not currently utilized in this project. Pyenv was deprecated in Python 3.5 and not utilized.","title":"Configure a Python Dev Environment"},{"location":"python_dev_env/#configure-a-python-dev-environment","text":"Respecting individual preferences and work style these are some suggested guidelines for creation of a Python development environment. These are consistent with Python standards and best practices and appropriate as a starting point for professional software development in Python.","title":"Configure a Python Dev Environment"},{"location":"python_dev_env/#installing-python","text":"The correct method of installing Python varies depending on the OS. Here are some considerations based on popular OS. OS Considerations MacOS Mac OS comes configured with Python 2.x. This version of Python is required by the OS and removal will impair system function. Homebrew is a package installer for Mac. Using Homebrew to install Python versions prior to 3.7 may generate errors on instal due to deprecated libraries. That isues has been resolved for versions 3.7 and higher. Apple XCode Developer Tools installs Git and a version of Python. Available through the App Store it is a large download and system intensive program which may not run smoothly on older or less robust systmes. A more granular installation would be the XCode Command Line Tools which installs Git combined with a Python install pulled directly from Python.org. WindowsOS Python is now available on the Windows Store , though updates may lag behind current Python releases at python.org before arriving on the Windows Store. The option to set environment variables via a UI on a per user basis facilitates multiple installed versions simultaneously. VS Code from Miscrosoft integrates direcltly with a system installled version of Python. Windows WLS2 A fully native Python install on Ubuntu is available for Windows Subsystem for Linux 2 . The version of Python may need to be updated from a secondary repository as the official Ubuntu version trails official Python releases. Integration between VS Code running on Windows and integration with WSL2 Python may require custom configuration. Linux A variety of package managers based on the installed distro enable installation and updates through a GUI or command line. Python3 Python is officially referred to and invoked by specfiying either Python 2.x as \"Python2\" or Python 3.x.x as \"Python3.\" The difference is generally trivial except on Macs where Python2 is included as part of the OS install. On Mac and Linux based systems, adding an alias to .bashrc or .zshrc is an easy way to prevent inadvertent references to an incorrect version of Python, e.g., alias python='python3' alias pip='pip3' Note that the above included an alias for pip to pip3 as well.","title":"Installing Python"},{"location":"python_dev_env/#create-a-virtual-environment-to-use-for-dev","text":"A Python virtual environment is a development sandbox which allows for segmentation of development environments. This allows for management of different combinations and versions of Python releases, deployed packages, development and testing environments, and shifting between entirely different development projects. See the Python documentation for venv for a more detailed explanation and rationalization of Python virtual environments. The use of Python virtual environments can't be overstated as a best practice to organize Python versions and package management. PEP-405 Creating virtual environments to use in Python programming can be done entirely with packages that are include in the Python install or by additional third party applications. The choice of tools to create and manage Python virtual environments is dependent on situation, preference, and use case. Tool/App Use Case venv Implementation of the virtualenv as a Python module included in the Python install since v.3.3. This tool does not require installation outside of the Python distribution itself. virtualenv Includes features not included in venv (see the comparison ). Anaconda A heavyweight package and virtual environment manager. It acts as an \"all in one\" for Python application versions, package management, virtual environments, additional programming languages such as R and Julia and tools such as visualizers and IDEs. The full fledged install can overtax some systems and performance can suffer from an overly ambitious installation configuration. A personal license for individuals is free for non-commercial use. Use by for-profit or governmental organizations with more than 200 people requires licensing. miniconda A slimmed down version of Anaconda focused on virtual environment and package management, includes only conda and Python, not open source, but free. conda The open source package manager utilized by Anaconda and miniconda. pip Included in Python 3.4 and later, this tool does not manage the virtual environment but does handle package management for both venv and virtualenv. Not all python tools have been integrated into the Anaconda repositories or packages for install. Some, such as mkdocs, must still be installed via pip even when using Anaconda3 or miniconda. 'virtualenv venv' vs. 'venv virtualenv' Avoid the confusion of the typical example given in the documentation of virtualenv which uses the command executed as \"virtualenv venv.\" This calls virtualenv to create a virtual environment named venv . Compare with \"venv virtualenv\" which calls venv to create a virtual environment called virtualenv . For most practical purposes when using Python 3.6 or greater it doesn't matter whether venv or virtualenv is used to create the virtual instance. It's recommended to name a virutal environment with a single word unique identifier as the word will be prefixed to the terminal command line when the virtual environment is activated. Other Python Tools Other tools such as virtualenvwrapper , pipenv , pew , tox and nox , poetry , and black may be useful but are not currently utilized in this project. Pyenv was deprecated in Python 3.5 and not utilized.","title":"Create a virtual environment to use for Dev"},{"location":"requirements/","text":"Project Package Requirements Currently implemented packages: This project utilizes the following packages, all of which should be available under an Open Source license via PyPI . List updated as of: 04/13/2022 (April 14th, 2022) Make sure to source the virtual environment first and then ' pip install <package> ' or ' conda install <package> ' to bring in the package. alabaster argh astroid attrs Babel brotlipy certifi cffi charset-normalizer click colorama cryptography dill dnspython docutils elementpath Faker flake8 future ghp-import idna imagesize importlib-metadata iniconfig isort Jinja2 joblib lazy-object-proxy livereload lunr Markdown MarkupSafe mccabe mergedeep mkautodoc mkdocs mkdocs-autorefs mkdocs-bootstrap mkdocs-material mkdocs-material-extensions mkdocs-print-site-plugin mkdocstrings mkdocstrings-python-legacy mypy mypy-extensions nltk packaging platformdirs pluggy psutil py pycodestyle pycparser pydocstyle pyflakes Pygments pylint pymdown-extensions pyOpenSSL pyparsing PySocks pytest python-dateutil python-dotenv pytkdocs pytz PyYAML pyyaml_env_tag regex requests six snowballstemmer text-unidecode toml tomli tornado tqdm typing_extensions urllib3 watchdog wrapt xmlschema zipp","title":"Package Requirements"},{"location":"requirements/#project-package-requirements","text":"","title":"Project Package Requirements"},{"location":"requirements/#currently-implemented-packages","text":"This project utilizes the following packages, all of which should be available under an Open Source license via PyPI . List updated as of: 04/13/2022 (April 14th, 2022) Make sure to source the virtual environment first and then ' pip install <package> ' or ' conda install <package> ' to bring in the package. alabaster argh astroid attrs Babel brotlipy certifi cffi charset-normalizer click colorama cryptography dill dnspython docutils elementpath Faker flake8 future ghp-import idna imagesize importlib-metadata iniconfig isort Jinja2 joblib lazy-object-proxy livereload lunr Markdown MarkupSafe mccabe mergedeep mkautodoc mkdocs mkdocs-autorefs mkdocs-bootstrap mkdocs-material mkdocs-material-extensions mkdocs-print-site-plugin mkdocstrings mkdocstrings-python-legacy mypy mypy-extensions nltk packaging platformdirs pluggy psutil py pycodestyle pycparser pydocstyle pyflakes Pygments pylint pymdown-extensions pyOpenSSL pyparsing PySocks pytest python-dateutil python-dotenv pytkdocs pytz PyYAML pyyaml_env_tag regex requests six snowballstemmer text-unidecode toml tomli tornado tqdm typing_extensions urllib3 watchdog wrapt xmlschema zipp","title":"Currently implemented packages:"},{"location":"semantic_model/","text":"e-invoice Onboarding Toolkit API semantic_model Module","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"semantic_model/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"semantic_model/#semantic_model-module","text":"","title":"semantic_model Module"},{"location":"sml_hash_func/","text":"Creating the SML URN Hash The SML look-up is a NAPTR DNS query which returns the URL of the SMP. The record queried is a URN constructed from the combined Specification, Schema, and Party ID and then hashed. After the hash is created, the URN is combined with the look-up domain. This combination of URN and domain is the record locator for the information in the DNS. The Python code, as script, function, or method, provides elaboration and implementation of the process as described in Section 3.2 of the BPC SML Profile Version 1.0 document found on the BPC-Exchange-Framework/BPC-Market-Pilot Github site . The BPC SML Domain The BPC SML Domain is: bpcb2b.net Information needed to create the URN Three data points are required to create the URN: Specification (urn:oasis:names:tc:ebcore:partyid-type) Schema (iso6523:0060) PartyID Note on non-functional requirements This process to create a URN hash for look-up does not specify or require the Specification, Schema, or PartyID in a particular format. The standard articulated for an ebCorePartyId referenced in the Business Document Metadata Service Location Version 1.0 referring to the OASIS ebCore Party Id Type Technical Specification Version 1.0 provides normative guidelines for the Specification and Schema. This code does not validate or enforce compliance with those standards. Conformance to those are assumed, however the code works on any string of data. Example - Creating the URN hash 1. Import Modules The hashlib and bas64 Python modules are used in this process. import hashlib import base64 2. Concatenate the string Strings are a primitive data type in Python. Instantiate and initialize string variables for the individual data values and concatenate them into a single string. Simple validation of the correct format of the urn is included. specification = \"urn:oasis:names:tc:ebcore:partyid-type:unregistered:myscheme\" schema = \"BPC01\" party_id = \"bpcBusid01\" urn = specification + \":\" + schema + \"::\" + party_id urn_test_case = \"urn:oasis:names:tc:ebcore:partyid-type:unregistered:myscheme:BPC01::bpcBusid01\" print(f\"urn is concatenated properly: {urn == urn_test_case}\") print(urn) Punctuation Note the use of a single and a double colon as separators between the values. These are includes as part of the string and are required . 3. Convert to lower-case Implements the Python String lower() method. lower_case_urn = urn.lower() print(f\"URN converted to lower case: {lower_case_urn}\") 4. Encode as utf-8 The sha256 and base32 operations done on the string are Buffered Protocols, which requires that they be in a bytes-like object format in Python. This is obtained using the String encode() method specifying \"utf-8\" as the format. The bytes(x, encoding, error) function could also be used here. urn_encoded = lower_case_urn.encode('utf-8') print (f\"URN encoded as utf-8: {urn_encoded}\") 5. Create sha256 hash This implements the sha256() method of the hashlib module imported in Step #1. sha256_urn = hashlib.sha256(urn_encoded) print (f\"URN hashed using sha256 {sha256_urn}\") 6. Obtain the 'digest' The digest is the concatenation of all of the data fed into the hash so far, i.e., the current value. (Though implemented as a single operation here, the buffered protocol allows for additions and updates to the hash.) The digest() method is included in the hashlib module. sha256_digest = sha256_urn.digest() print(f\"Digest of buffered stream containing results thus far: {sha256_digest}\") 7. Encode into base32 Why encode in base32? Encryption using sha256 results in a one-way hash. The original value of the URN is not intended to be derived from that hash as that is cryptographically impossible. (Encoding the sha256 hash into base32 is not one way.) The sha256 hash is 256 bits, or 32 bytes. A two digit hexadecimal representation of the 32 byte hash is 64 characters long. Since base32 encoding has a character set of 32 compared to hexadecimal's 16, the sha256 hashed value can be represented in 32 characters in base32 instead of the 64 required for hex. The irreversibility of the sha256 hash implies that the process is cryptographically significant. It is not. The hashed URN is ultimately used as a dictionary look-up in the DNS record for a given domain . Where a common specification and schema are in use by many participants, it becomes imperative that the PartyIDs are unique for a specific domain . Otherwise, while a sha256 hash can't be reversed, it can be duplicated . The output of this process is a 256 bit/32 byte value represented in a base 32 character set. Take the digest entry, still a bytes-like object, and encode it in base32, resulting in a string 32 characters in length. This implements the b32encode method of the base64 module. b32_urn = base64.b32encode(sha256_digest) print(f\"The base32 encoded representation of the URN: {b32_urn}\") 8. Strip off extras The base32 encoding may result in extra characters at the end of the string. The rstrip String method is used to remove any of this additional padding at the end of the string. b32_urn_clean = b32_urn.rstrip(b\"=\") print(f\"The URN with any padding removed {b32_urn_clean}\") 9. Convert back to a String The object is still in a binary or bytes-like object format. Convert it back into a String primitive using the String decode('utf-8) method where 'utf-8' was the original encoding method. b32_str = b32_urn_clean.decode('utf-8') 10. Convert to lower-case Per the specification, ensure the output is entirely in lowercase. This implements the String lower() method again. final = b32_str.lower() Final Output The final output of the hash algorithm. print(f\"The final result: {final}\") Code The entirety of the Python code for the hash algorithm - can be run as a script or a function. ######################################################### # # Example Constructing a URN for SML DNS NAPTR look-up # ########################################################## # import the modules import hashlib import base64 # get the urn specification = \"urn:oasis:names:tc:ebcore:partyid-type:unregistered:myscheme\" schema = \"BPC01\" party_id = \"bpcBusid01\" urn = specification + \":\" + schema + \"::\" + party_id urn_test_case = \"urn:oasis:names:tc:ebcore:partyid-type:unregistered:myscheme:BPC01::bpcBusid01\" print(f\"urn is concatenated properly: {urn == urn_test_case}\") print(urn) # make sure it's converted to lower case lower_case_urn = urn.lower() print(f\"URN converted to lower case {lower_case_urn}\") # has to be a byte-like object to be hashed, so encode it as utf-8 urn_encoded = lower_case_urn.encode('utf-8') print (f\"URN encoded as utf-8: {urn_encoded}\") # now create the sha256 hash of it sha256_urn = hashlib.sha256(urn_encoded) # get the current value of the buffer stream sha256_digest = sha256_urn.digest() print(f\"Digest of buffered stream containing results thus far: {sha256_digest}\") #encode into b32 b32_urn = base64.b32encode(sha256_digest) print(f\"The base32 encoded representation of the URN: {b32_urn}\") # strip off the equals sign.... b32_urn_clean = b32_urn.rstrip(b\"=\") print(f\"The URN with any padding removed {b32_urn_clean}\") # convert it back to string. b32_str = b32_urn_clean.decode('utf-8') # make sure it's in lower case again. final = b32_str.lower() # This should be your final answer print(f\"The final result: {final}\") Output urn is concatenated properly: True urn:oasis:names:tc:ebcore:partyid-type:unregistered:myscheme:BPC01::bpcBusid01 URN converted to lower case: urn:oasis:names:tc:ebcore:partyid-type:unregistered:myscheme:bpc01::bpcbusid01 URN encoded as utf-8: b'urn:oasis:names:tc:ebcore:partyid-type:unregistered:myscheme:bpc01::bpcbusid01' URN hashed using sha256 <sha256 _hashlib.HASH object @ 0x106202710> Digest of buffered stream containing results thus far: b'\\xc3{4\\xfc3\"\\xdb\\xc1u\\xdcd\\xe8\\xbf\\xe2\\xad\\x86\\xdfjxob\\x1e\\'\\x17\\x8f\\xb0\\x83!\\xec\\x15\\xab~' The base32 encoded representation of the URN: b'YN5TJ7BTELN4C5O4MTUL7YVNQ3PWU6DPMIPCOF4PWCBSD3AVVN7A====' The URN with any padding removed b'YN5TJ7BTELN4C5O4MTUL7YVNQ3PWU6DPMIPCOF4PWCBSD3AVVN7A' The final result: yn5tj7bteln4c5o4mtul7yvnq3pwu6dpmipcof4pwcbsd3avvn7a","title":"SML Hash Functionality"},{"location":"sml_hash_func/#creating-the-sml-urn-hash","text":"The SML look-up is a NAPTR DNS query which returns the URL of the SMP. The record queried is a URN constructed from the combined Specification, Schema, and Party ID and then hashed. After the hash is created, the URN is combined with the look-up domain. This combination of URN and domain is the record locator for the information in the DNS. The Python code, as script, function, or method, provides elaboration and implementation of the process as described in Section 3.2 of the BPC SML Profile Version 1.0 document found on the BPC-Exchange-Framework/BPC-Market-Pilot Github site . The BPC SML Domain The BPC SML Domain is: bpcb2b.net","title":"Creating the SML URN Hash"},{"location":"sml_hash_func/#information-needed-to-create-the-urn","text":"Three data points are required to create the URN: Specification (urn:oasis:names:tc:ebcore:partyid-type) Schema (iso6523:0060) PartyID Note on non-functional requirements This process to create a URN hash for look-up does not specify or require the Specification, Schema, or PartyID in a particular format. The standard articulated for an ebCorePartyId referenced in the Business Document Metadata Service Location Version 1.0 referring to the OASIS ebCore Party Id Type Technical Specification Version 1.0 provides normative guidelines for the Specification and Schema. This code does not validate or enforce compliance with those standards. Conformance to those are assumed, however the code works on any string of data.","title":"Information needed to create the URN"},{"location":"sml_hash_func/#example-creating-the-urn-hash","text":"","title":"Example - Creating the URN hash"},{"location":"sml_hash_func/#1-import-modules","text":"The hashlib and bas64 Python modules are used in this process. import hashlib import base64","title":"1. Import Modules"},{"location":"sml_hash_func/#2-concatenate-the-string","text":"Strings are a primitive data type in Python. Instantiate and initialize string variables for the individual data values and concatenate them into a single string. Simple validation of the correct format of the urn is included. specification = \"urn:oasis:names:tc:ebcore:partyid-type:unregistered:myscheme\" schema = \"BPC01\" party_id = \"bpcBusid01\" urn = specification + \":\" + schema + \"::\" + party_id urn_test_case = \"urn:oasis:names:tc:ebcore:partyid-type:unregistered:myscheme:BPC01::bpcBusid01\" print(f\"urn is concatenated properly: {urn == urn_test_case}\") print(urn) Punctuation Note the use of a single and a double colon as separators between the values. These are includes as part of the string and are required .","title":"2. Concatenate the string"},{"location":"sml_hash_func/#3-convert-to-lower-case","text":"Implements the Python String lower() method. lower_case_urn = urn.lower() print(f\"URN converted to lower case: {lower_case_urn}\")","title":"3. Convert to lower-case"},{"location":"sml_hash_func/#4-encode-as-utf-8","text":"The sha256 and base32 operations done on the string are Buffered Protocols, which requires that they be in a bytes-like object format in Python. This is obtained using the String encode() method specifying \"utf-8\" as the format. The bytes(x, encoding, error) function could also be used here. urn_encoded = lower_case_urn.encode('utf-8') print (f\"URN encoded as utf-8: {urn_encoded}\")","title":"4. Encode as utf-8"},{"location":"sml_hash_func/#5-create-sha256-hash","text":"This implements the sha256() method of the hashlib module imported in Step #1. sha256_urn = hashlib.sha256(urn_encoded) print (f\"URN hashed using sha256 {sha256_urn}\")","title":"5. Create sha256 hash"},{"location":"sml_hash_func/#6-obtain-the-digest","text":"The digest is the concatenation of all of the data fed into the hash so far, i.e., the current value. (Though implemented as a single operation here, the buffered protocol allows for additions and updates to the hash.) The digest() method is included in the hashlib module. sha256_digest = sha256_urn.digest() print(f\"Digest of buffered stream containing results thus far: {sha256_digest}\")","title":"6. Obtain the 'digest'"},{"location":"sml_hash_func/#7-encode-into-base32","text":"Why encode in base32? Encryption using sha256 results in a one-way hash. The original value of the URN is not intended to be derived from that hash as that is cryptographically impossible. (Encoding the sha256 hash into base32 is not one way.) The sha256 hash is 256 bits, or 32 bytes. A two digit hexadecimal representation of the 32 byte hash is 64 characters long. Since base32 encoding has a character set of 32 compared to hexadecimal's 16, the sha256 hashed value can be represented in 32 characters in base32 instead of the 64 required for hex. The irreversibility of the sha256 hash implies that the process is cryptographically significant. It is not. The hashed URN is ultimately used as a dictionary look-up in the DNS record for a given domain . Where a common specification and schema are in use by many participants, it becomes imperative that the PartyIDs are unique for a specific domain . Otherwise, while a sha256 hash can't be reversed, it can be duplicated . The output of this process is a 256 bit/32 byte value represented in a base 32 character set. Take the digest entry, still a bytes-like object, and encode it in base32, resulting in a string 32 characters in length. This implements the b32encode method of the base64 module. b32_urn = base64.b32encode(sha256_digest) print(f\"The base32 encoded representation of the URN: {b32_urn}\")","title":"7.  Encode into base32"},{"location":"sml_hash_func/#8-strip-off-extras","text":"The base32 encoding may result in extra characters at the end of the string. The rstrip String method is used to remove any of this additional padding at the end of the string. b32_urn_clean = b32_urn.rstrip(b\"=\") print(f\"The URN with any padding removed {b32_urn_clean}\")","title":"8.  Strip off extras"},{"location":"sml_hash_func/#9-convert-back-to-a-string","text":"The object is still in a binary or bytes-like object format. Convert it back into a String primitive using the String decode('utf-8) method where 'utf-8' was the original encoding method. b32_str = b32_urn_clean.decode('utf-8')","title":"9. Convert back to a String"},{"location":"sml_hash_func/#10-convert-to-lower-case","text":"Per the specification, ensure the output is entirely in lowercase. This implements the String lower() method again. final = b32_str.lower()","title":"10. Convert to lower-case"},{"location":"sml_hash_func/#final-output","text":"The final output of the hash algorithm. print(f\"The final result: {final}\")","title":"Final Output"},{"location":"sml_hash_func/#code","text":"The entirety of the Python code for the hash algorithm - can be run as a script or a function. ######################################################### # # Example Constructing a URN for SML DNS NAPTR look-up # ########################################################## # import the modules import hashlib import base64 # get the urn specification = \"urn:oasis:names:tc:ebcore:partyid-type:unregistered:myscheme\" schema = \"BPC01\" party_id = \"bpcBusid01\" urn = specification + \":\" + schema + \"::\" + party_id urn_test_case = \"urn:oasis:names:tc:ebcore:partyid-type:unregistered:myscheme:BPC01::bpcBusid01\" print(f\"urn is concatenated properly: {urn == urn_test_case}\") print(urn) # make sure it's converted to lower case lower_case_urn = urn.lower() print(f\"URN converted to lower case {lower_case_urn}\") # has to be a byte-like object to be hashed, so encode it as utf-8 urn_encoded = lower_case_urn.encode('utf-8') print (f\"URN encoded as utf-8: {urn_encoded}\") # now create the sha256 hash of it sha256_urn = hashlib.sha256(urn_encoded) # get the current value of the buffer stream sha256_digest = sha256_urn.digest() print(f\"Digest of buffered stream containing results thus far: {sha256_digest}\") #encode into b32 b32_urn = base64.b32encode(sha256_digest) print(f\"The base32 encoded representation of the URN: {b32_urn}\") # strip off the equals sign.... b32_urn_clean = b32_urn.rstrip(b\"=\") print(f\"The URN with any padding removed {b32_urn_clean}\") # convert it back to string. b32_str = b32_urn_clean.decode('utf-8') # make sure it's in lower case again. final = b32_str.lower() # This should be your final answer print(f\"The final result: {final}\")","title":"Code"},{"location":"sml_hash_func/#output","text":"urn is concatenated properly: True urn:oasis:names:tc:ebcore:partyid-type:unregistered:myscheme:BPC01::bpcBusid01 URN converted to lower case: urn:oasis:names:tc:ebcore:partyid-type:unregistered:myscheme:bpc01::bpcbusid01 URN encoded as utf-8: b'urn:oasis:names:tc:ebcore:partyid-type:unregistered:myscheme:bpc01::bpcbusid01' URN hashed using sha256 <sha256 _hashlib.HASH object @ 0x106202710> Digest of buffered stream containing results thus far: b'\\xc3{4\\xfc3\"\\xdb\\xc1u\\xdcd\\xe8\\xbf\\xe2\\xad\\x86\\xdfjxob\\x1e\\'\\x17\\x8f\\xb0\\x83!\\xec\\x15\\xab~' The base32 encoded representation of the URN: b'YN5TJ7BTELN4C5O4MTUL7YVNQ3PWU6DPMIPCOF4PWCBSD3AVVN7A====' The URN with any padding removed b'YN5TJ7BTELN4C5O4MTUL7YVNQ3PWU6DPMIPCOF4PWCBSD3AVVN7A' The final result: yn5tj7bteln4c5o4mtul7yvnq3pwu6dpmipcof4pwcbsd3avvn7a","title":"Output"},{"location":"smp_query/","text":"e-invoice Onboarding Toolkit API smp_query Module No Representations or Warranties THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"smp_query/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"smp_query/#smp_query-module","text":"","title":"smp_query Module"},{"location":"smp_rest_query/","text":"SMP REST API Query Query to an SMP service to obtain terminal or final \"Endpoint\" destination of the e-invoice is implemented using two REST API web service calls. References See the BPC SMP Profile Version 1.0 (the \"Profile\") document for general guidance to the format of this service call. See the OASIS website for the authoritative OASIS SMP 2.0 Standard (the \"Standard\"). Section 3 of the BPC SMP Profile referencing the REST interface specifies in Section 3.1 that client authentication must not be required when accessing SMP [server] resources. The REST API for the web service calls are referenced in section 3.2 of the BPC SMP Profile, mandating implementation as provided in section 5.2 of the OASIS SMP 2.0 Standard. The BPC SMP Profile implements the OASIS SMP 2.0 Standard Section 3.2 of the BPC SMP Profile mandates implementation of the OASIS SMP 2.0 standard. To the extent that Section 6 of the BPC Profile has a requirement that the SMP client MUST validate the signature of the SMP [server response] as directed in section 5.6.2.2 of the OASIS standard, the OASIS standard is permissive and says the SMP client MAY verify the signature. The REST Web Service calls to the SMP service !!!+ Important \"The rules for constructing the ServiceGroup REST API web service call. In Section 5.4 \"Resources\" The OASIS SMP Standard provides the format used to create the ServiceGroup REST API web service call. This specifies the oasis-bdxr-smp-2(bdxr-smp-2) SMP REST binding, the \"identifier scheme\" and the \"participant id.\" The \"identifier scheme\" is literally the URN specifying the format the participant ID is going to take. 1. Service Group Discovery The first REST API query to the Service Group is created using the SMP REST binding, \"identifier scheme\" and \"participant ID.\" Creating the SMP REST API call #1 to obtain ServiceGroup data The first web service call to obtain the ServiceGroup data is constructed from: 1a. Use the SMP web service being queried with its fully qualified domain. Not specified, but implied to make a web service call, is the scheme or protocol of \"https://\" Further unspecified, but implied as it is required, is the fully qualified application server domain and reference to any sub-domains. In the case of the example, this is \"smp-api.sc-b2b.us.\" The subdomain is \"smp-api.\" The second-level domain is \"sc-b2b.\" The top level domain is \"us.\" The only REST method required to be supported by the OASIS SMP Standard is \"GET.\" Everything after the domain specification is the \"resource\" uri of the GET method request. In the development environment of the Onboarding Toolkit the first part of the URL will be: https://smp-api.sc-b2b.us/, This value will be different in the Market Pilot. In the Market Pilot, use the value bpcb2b.net . The URL will begin with https://bpcb22.net/ 1b. The SMP REST Binding Section 5.5 of the OASIS SMP 2.0 Standard directs the SMP REST Binding should be oasis-bdxr-smp-2 . In the prior Section 5.4 \"Resources\" the example URI indicates an SMP Binding of bdxr-smp-2 . The development and test environment of the Onboarding Toolkit the SMP Binding used bdxr-smp-2 . The Onboarding Toolkit dev URL then grows to: https://smp-api.sc-b2b.us/bdxr-smp-2/ The Market Pilot URL grows to: https://bpcb22.net/bdxr-smp-2/ 1c. The Identifier Scheme The next element in the call to obtain the ServiceGroup data is the \"identifier scheme\" which identifies the format of the PartyID. This value should already be known, as it is the Specification and the Scheme used when creating the hash value for SML U-NAPTR DNS look-up. Together, the Specification and the Scheme create the \"identifier scheme,\" which defines the format of the party ID. Detailed requirements of the identifier scheme are found in the | OASIS ebCore Party Id Type Technical Specification Version 1.0 | ebCorePartyID |. An example of a \"normative\" value for the identifier scheme is: urn:oasis:names:tc:ebcore:partyid-type:iso6523. The Onboarding Toolkit dev URL then grows to: https:\\/\\/smp-api.sc-b2b.us\\/bdxr-smp-2\\/urn:oasis:names:tc:ebcore:partyid-type:iso6523 The Market Pilot URL grows to: https:\\/\\/bpcb22.net\\/bdxr-smp-2\\/urn:oasis:names:tc:ebcore:partyid-type:iso6523 1d. Append the PartyID Add the party ID to the whole thing. The specific format of the 1e. Create the string The ServiceGroup web service call then takes the format of: https://\\< webservice.domain >/\\< smp_rest_binding >/\\< urn > where the URN is \\< specification >:\\< schema >::\\< party_id >. Using the terms employed by the OASIS SMP 2.0 specification the URL is constructed as: https://\\< webservice.domain >/\\< smp_rest_binding >/\\< identifier\\ _scheme >::\\< participant_id > 2. Service Metadata Query The response of the Service Group Discovery returns information necessary to construct the Service Metadata Query. The BPC SMP Profile requires that the Service Group Discovery REST API call must not be skipped and that the presence of Service Metadata should not be assumed. #### 1e. Make the web service call Example protocol = \"https\" uri = \"smp-api.sc-b2b.us\" standard = \"bdxr-smp-2\" identifier_scheme = \"urn:oasis:names:tc:ebcore:partyid-type:iso6523:0088\" participant_id = \"123456789\" urn = identifier_scheme + \"::\" + participant_id query_url_1 = protocol + \"://\" + uri + \":\" + identifier_scheme + \"::\" + participant_id query_url_2 = protocol + \"://\" + uri + \":\" + urn print(f\"Value of query_url_1: {query_url_1}\") print(f\"Value of query_url_2: {query_url_2}\") print(f\"constructed urls are the same: {query_url_1 == query_url_2}\") Output Value of query_url_1: https://smp-api.sc-b2b.us:urn:oasis:names:tc:ebcore:partyid-type:iso6523:0088::123456789 Value of query_url_2: https://smp-api.sc-b2b.us:urn:oasis:names:tc:ebcore:partyid-type:iso6523:0088::123456789 constructed urls are the same: True Call #2 to obtain ServiceMetadata !!!+ important \"Inferring values for the ServiceMetadata REST web service call\" In the BPC Proof of Concept and creation of the Onboarding Toolkit, the service and document schemas defined by the SMP were static. The values had to be agreed The QName Subtype Identifier was used. validation of the queries resulted in assumption of the value of some ServiceMetadata parameters.","title":"SMP REST API Query"},{"location":"smp_rest_query/#smp-rest-api-query","text":"Query to an SMP service to obtain terminal or final \"Endpoint\" destination of the e-invoice is implemented using two REST API web service calls.","title":"SMP REST API Query"},{"location":"smp_rest_query/#references","text":"See the BPC SMP Profile Version 1.0 (the \"Profile\") document for general guidance to the format of this service call. See the OASIS website for the authoritative OASIS SMP 2.0 Standard (the \"Standard\"). Section 3 of the BPC SMP Profile referencing the REST interface specifies in Section 3.1 that client authentication must not be required when accessing SMP [server] resources. The REST API for the web service calls are referenced in section 3.2 of the BPC SMP Profile, mandating implementation as provided in section 5.2 of the OASIS SMP 2.0 Standard. The BPC SMP Profile implements the OASIS SMP 2.0 Standard Section 3.2 of the BPC SMP Profile mandates implementation of the OASIS SMP 2.0 standard. To the extent that Section 6 of the BPC Profile has a requirement that the SMP client MUST validate the signature of the SMP [server response] as directed in section 5.6.2.2 of the OASIS standard, the OASIS standard is permissive and says the SMP client MAY verify the signature.","title":"References"},{"location":"smp_rest_query/#the-rest-web-service-calls-to-the-smp-service","text":"!!!+ Important \"The rules for constructing the ServiceGroup REST API web service call. In Section 5.4 \"Resources\" The OASIS SMP Standard provides the format used to create the ServiceGroup REST API web service call. This specifies the oasis-bdxr-smp-2(bdxr-smp-2) SMP REST binding, the \"identifier scheme\" and the \"participant id.\" The \"identifier scheme\" is literally the URN specifying the format the participant ID is going to take.","title":"The REST Web Service calls to the SMP service"},{"location":"smp_rest_query/#1-service-group-discovery","text":"The first REST API query to the Service Group is created using the SMP REST binding, \"identifier scheme\" and \"participant ID.\"","title":"1. Service Group Discovery"},{"location":"smp_rest_query/#creating-the-smp-rest-api-call-1-to-obtain-servicegroup-data","text":"The first web service call to obtain the ServiceGroup data is constructed from:","title":"Creating the SMP REST API call #1 to obtain ServiceGroup data"},{"location":"smp_rest_query/#1a-use-the-smp-web-service-being-queried-with-its-fully-qualified-domain","text":"Not specified, but implied to make a web service call, is the scheme or protocol of \"https://\" Further unspecified, but implied as it is required, is the fully qualified application server domain and reference to any sub-domains. In the case of the example, this is \"smp-api.sc-b2b.us.\" The subdomain is \"smp-api.\" The second-level domain is \"sc-b2b.\" The top level domain is \"us.\" The only REST method required to be supported by the OASIS SMP Standard is \"GET.\" Everything after the domain specification is the \"resource\" uri of the GET method request. In the development environment of the Onboarding Toolkit the first part of the URL will be: https://smp-api.sc-b2b.us/, This value will be different in the Market Pilot. In the Market Pilot, use the value bpcb2b.net . The URL will begin with https://bpcb22.net/","title":"1a. Use the SMP web service being queried with its fully qualified domain."},{"location":"smp_rest_query/#1b-the-smp-rest-binding","text":"Section 5.5 of the OASIS SMP 2.0 Standard directs the SMP REST Binding should be oasis-bdxr-smp-2 . In the prior Section 5.4 \"Resources\" the example URI indicates an SMP Binding of bdxr-smp-2 . The development and test environment of the Onboarding Toolkit the SMP Binding used bdxr-smp-2 . The Onboarding Toolkit dev URL then grows to: https://smp-api.sc-b2b.us/bdxr-smp-2/ The Market Pilot URL grows to: https://bpcb22.net/bdxr-smp-2/","title":"1b.  The SMP REST Binding"},{"location":"smp_rest_query/#1c-the-identifier-scheme","text":"The next element in the call to obtain the ServiceGroup data is the \"identifier scheme\" which identifies the format of the PartyID. This value should already be known, as it is the Specification and the Scheme used when creating the hash value for SML U-NAPTR DNS look-up. Together, the Specification and the Scheme create the \"identifier scheme,\" which defines the format of the party ID. Detailed requirements of the identifier scheme are found in the | OASIS ebCore Party Id Type Technical Specification Version 1.0 | ebCorePartyID |. An example of a \"normative\" value for the identifier scheme is: urn:oasis:names:tc:ebcore:partyid-type:iso6523. The Onboarding Toolkit dev URL then grows to: https:\\/\\/smp-api.sc-b2b.us\\/bdxr-smp-2\\/urn:oasis:names:tc:ebcore:partyid-type:iso6523 The Market Pilot URL grows to: https:\\/\\/bpcb22.net\\/bdxr-smp-2\\/urn:oasis:names:tc:ebcore:partyid-type:iso6523","title":"1c.  The Identifier Scheme"},{"location":"smp_rest_query/#1d-append-the-partyid","text":"Add the party ID to the whole thing. The specific format of the","title":"1d. Append the PartyID"},{"location":"smp_rest_query/#1e-create-the-string","text":"The ServiceGroup web service call then takes the format of: https://\\< webservice.domain >/\\< smp_rest_binding >/\\< urn > where the URN is \\< specification >:\\< schema >::\\< party_id >. Using the terms employed by the OASIS SMP 2.0 specification the URL is constructed as: https://\\< webservice.domain >/\\< smp_rest_binding >/\\< identifier\\ _scheme >::\\< participant_id >","title":"1e. Create the string"},{"location":"smp_rest_query/#2-service-metadata-query","text":"The response of the Service Group Discovery returns information necessary to construct the Service Metadata Query. The BPC SMP Profile requires that the Service Group Discovery REST API call must not be skipped and that the presence of Service Metadata should not be assumed. #### 1e. Make the web service call","title":"2. Service Metadata Query"},{"location":"smp_rest_query/#example","text":"protocol = \"https\" uri = \"smp-api.sc-b2b.us\" standard = \"bdxr-smp-2\" identifier_scheme = \"urn:oasis:names:tc:ebcore:partyid-type:iso6523:0088\" participant_id = \"123456789\" urn = identifier_scheme + \"::\" + participant_id query_url_1 = protocol + \"://\" + uri + \":\" + identifier_scheme + \"::\" + participant_id query_url_2 = protocol + \"://\" + uri + \":\" + urn print(f\"Value of query_url_1: {query_url_1}\") print(f\"Value of query_url_2: {query_url_2}\") print(f\"constructed urls are the same: {query_url_1 == query_url_2}\")","title":"Example"},{"location":"smp_rest_query/#output","text":"Value of query_url_1: https://smp-api.sc-b2b.us:urn:oasis:names:tc:ebcore:partyid-type:iso6523:0088::123456789 Value of query_url_2: https://smp-api.sc-b2b.us:urn:oasis:names:tc:ebcore:partyid-type:iso6523:0088::123456789 constructed urls are the same: True","title":"Output"},{"location":"smp_rest_query/#call-2-to-obtain-servicemetadata","text":"!!!+ important \"Inferring values for the ServiceMetadata REST web service call\" In the BPC Proof of Concept and creation of the Onboarding Toolkit, the service and document schemas defined by the SMP were static. The values had to be agreed The QName Subtype Identifier was used. validation of the queries resulted in assumption of the value of some ServiceMetadata parameters.","title":"Call #2 to obtain ServiceMetadata"},{"location":"standards/","text":"Standards Reference Links: Documents Reference Standard Component BPC SML Profile Version 1.0. dated 04 January, 2022. SML Business Document Metadata Service Location Version 1.0 OASIS Standard dated 01 August 2017. SML BPC SMP Profile Version 1.0 dated 04 January, 2022. SMP Service Metadata Publishing (SMP) Version 2.0 OASIS Standard dated 14 February 2021. SMP OASIS ebCore Party Id Type Technical Specification Version 1.0 ebCorePartyID OASIS ebXML Messaging Services Version 3.0: Part1, Core Features OASIS Standard, October 1, 2007 ebXML OASIS ebXML Messaging Services Version 3.0: Part 2, Advanced Features dated June 30, 2010 ebXML ebXML Messaging Services Version 3.0: Part 2, Advanced Features ebXML AS4 Profile of ebMS 3.0 Version 1.0 dated January 23, 2013. AS4 XML Schema Definitions XSD Files XSD File : ebms-header-3_0-200704 including snippets of sample XML and full SOAP for message headers. Note that the Namespace URI identified in Part1 is incorrect and returns an error message. XSD File : XSD for Routing Input reference parameter XSD File : MessageFragment XSD XSD File : Refactored Core Messaging XSD Namespace URIs Namespaces ebXML Messaging Services Version 3.0 Core Features) OASIS ebXML Messaging Services 3.0 Conformance Profiles , Committee Specification 1, dated April 24, 2010 references the same namespace URI of http://docs.oasis-open.org/ebxml-msg/ns/ebms/v3.0/profiles/200707.","title":"Standards"},{"location":"standards/#standards","text":"Reference Links:","title":"Standards"},{"location":"standards/#documents","text":"Reference Standard Component BPC SML Profile Version 1.0. dated 04 January, 2022. SML Business Document Metadata Service Location Version 1.0 OASIS Standard dated 01 August 2017. SML BPC SMP Profile Version 1.0 dated 04 January, 2022. SMP Service Metadata Publishing (SMP) Version 2.0 OASIS Standard dated 14 February 2021. SMP OASIS ebCore Party Id Type Technical Specification Version 1.0 ebCorePartyID OASIS ebXML Messaging Services Version 3.0: Part1, Core Features OASIS Standard, October 1, 2007 ebXML OASIS ebXML Messaging Services Version 3.0: Part 2, Advanced Features dated June 30, 2010 ebXML ebXML Messaging Services Version 3.0: Part 2, Advanced Features ebXML AS4 Profile of ebMS 3.0 Version 1.0 dated January 23, 2013. AS4","title":"Documents"},{"location":"standards/#xml-schema-definitions","text":"XSD Files XSD File : ebms-header-3_0-200704 including snippets of sample XML and full SOAP for message headers. Note that the Namespace URI identified in Part1 is incorrect and returns an error message. XSD File : XSD for Routing Input reference parameter XSD File : MessageFragment XSD XSD File : Refactored Core Messaging XSD","title":"XML Schema Definitions"},{"location":"standards/#namespace-uris","text":"Namespaces ebXML Messaging Services Version 3.0 Core Features) OASIS ebXML Messaging Services 3.0 Conformance Profiles , Committee Specification 1, dated April 24, 2010 references the same namespace URI of http://docs.oasis-open.org/ebxml-msg/ns/ebms/v3.0/profiles/200707.","title":"Namespace URIs"},{"location":"test_cases/","text":"E-Invoice Onboarding Tool-kit Working with the code Test Cases Using an .env file Copy the .env.example.dev to .env Some of the test cases rely on local variables imported at runtime. These values are in the \".env.example.dev\" file. This file is at the ./einvoice root of the project. The file MUST be copied or renamed to \".env\" in order for all of the tests to complete successfully. (The tests may also be refactored manually to refer to local dev enivornment variables.) Test modules Every module includes a test module in the ./einvoice/test directory. Test cases are written as functions, not classes. The test cases are written as functions and CAN be directly called from the command line. Use Pytest to run the test cases. The use case for the test cases include using Pytest. The Pytest package must be installed in your Python distribution. From the a terminal console, change directory into the ./einvoice/test directory. To see the list of available test files, use either the file browser or the command line. For Windows: dir .\\einvoice\\test\\ For Mac/*nix/WSL2: ls -al ./einvoice/test/ The ./test directory must be at the same level as the code. Out of the box, Pytest requires that without additional configuration it must be executed from a directory at the same level of the code that's being tested. That is, test scripts are in ./einvoice/test and code files are in ./einvoice/discovery and ./einvoice/delivery. Pytest will automatically look for files formatted as test files, with \"test\" in the lead of the filename. To execute an inidividual test the syntax is: pytest test_app_logging.py No test is dependent on any other, and each may be run on its own, or run them all at once, in any order. The test will run and either the \"assert\" statement(s) inside will pass or it will fail. Failures MUST be resolved prior to attempting to check code into GitHub as our baseline CI/CD process checks for these failures before committing and will not continue if any are found. The included assert statements currently test a variety of cases up to validation of URN creation, query of the NAPTR DNS record, REST API call to the SMP, and validation of the ebMS header against the AS4 conformance profile. The test folder also contains a number of shell scripts to validate the code using a number of linters including flake8, pylint, mypy, pycodestyte, and pydocstyle. Prior to check in, all code must have all warnings from all linters resolved or noted. Successful completion of all test cases.","title":"Test Cases"},{"location":"test_cases/#e-invoice-onboarding-tool-kit","text":"","title":"E-Invoice Onboarding Tool-kit"},{"location":"test_cases/#working-with-the-code","text":"","title":"Working with the code"},{"location":"test_cases/#test-cases","text":"","title":"Test Cases"},{"location":"test_cases/#using-an-env-file","text":"Copy the .env.example.dev to .env Some of the test cases rely on local variables imported at runtime. These values are in the \".env.example.dev\" file. This file is at the ./einvoice root of the project. The file MUST be copied or renamed to \".env\" in order for all of the tests to complete successfully. (The tests may also be refactored manually to refer to local dev enivornment variables.)","title":"Using an .env file"},{"location":"test_cases/#test-modules","text":"Every module includes a test module in the ./einvoice/test directory. Test cases are written as functions, not classes. The test cases are written as functions and CAN be directly called from the command line. Use Pytest to run the test cases. The use case for the test cases include using Pytest. The Pytest package must be installed in your Python distribution. From the a terminal console, change directory into the ./einvoice/test directory. To see the list of available test files, use either the file browser or the command line. For Windows: dir .\\einvoice\\test\\ For Mac/*nix/WSL2: ls -al ./einvoice/test/ The ./test directory must be at the same level as the code. Out of the box, Pytest requires that without additional configuration it must be executed from a directory at the same level of the code that's being tested. That is, test scripts are in ./einvoice/test and code files are in ./einvoice/discovery and ./einvoice/delivery. Pytest will automatically look for files formatted as test files, with \"test\" in the lead of the filename. To execute an inidividual test the syntax is: pytest test_app_logging.py No test is dependent on any other, and each may be run on its own, or run them all at once, in any order. The test will run and either the \"assert\" statement(s) inside will pass or it will fail. Failures MUST be resolved prior to attempting to check code into GitHub as our baseline CI/CD process checks for these failures before committing and will not continue if any are found. The included assert statements currently test a variety of cases up to validation of URN creation, query of the NAPTR DNS record, REST API call to the SMP, and validation of the ebMS header against the AS4 conformance profile. The test folder also contains a number of shell scripts to validate the code using a number of linters including flake8, pylint, mypy, pycodestyte, and pydocstyle. Prior to check in, all code must have all warnings from all linters resolved or noted. Successful completion of all test cases.","title":"Test modules"},{"location":"the_hash/","text":"The Four-Corner Model is premised on a NAPTR DNS look-up to obtain the location of the SMP URI. The SMP URI is then used to query the SMP REST API and obtain the Corner 3 URI. The assumption is that a NAPTR DNS record exists as a key:value pair. A look-up of the \"key\" in the DNS of the NAPTR record will return the \"value.\" The \"key\" is the hashed value of the URN. The URN is the composite of the specification, the schema_id, and the party_id. The hash is: 1) concattonate the elements of the URN into a single string value. Note a single colon between the specification and the schema_id and double colon between the schema_id and the party_id. specification + \":\" + schema_id + \"::\" + party_id The Four-Cormer Model stateDiagram-v2 [*] --> Seller Seller --> Access_Point_1 state Access_Point_1 { [*] --> SML state SML { [*] --> Create_Hash state Create_Hash { [*] --> Receive_inputs Receive_inputs --> Concatonate Concatonate --> to_lower_case to_lower_case --> encode_utf8 encode_utf8 --> sha256_hash sha256_hash --> byte_digest_of_hash byte_digest_of_hash --> base32_hash base32_hash --> strip_extra_chars strip_extra_chars --> decode_to_string decode_to_string --> ensure_lower_case ensure_lower_case --> [*] } Create_Hash --> add_domain add_domain --> dns_query state dns_query { [*] --> hashed_urn hashed_urn --> do_dns_look-up do_dns_look-up --> [*] } dns_query --> [*] } SML --> SMP state SMP { [*] --> Create_requests Create_requests --> Request_1 Request_1 --> Request_2 Request_2 --> [*] } SMP --> [*] } Access_Point_1 --> Access_Point_2 Access_Point_2 --> Buyer Buyer --> [*]","title":"The hash"},{"location":"todo/","text":"To do: List of Deliverables A deployment package which includes Python code to: (In-progress)_ Creation of \"final\" Python package which delivers code artifacts as a library. Documentation (In-progress) Generated from python docstring using Sphinx mkdocs-material framework (In-progress) Documentation of supporting infrastructure including DNS and SMP provisioning specifically called out as a parallel value-add result of the project. No Representations or Warranties THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"To do:<hr>"},{"location":"todo/#to-do","text":"","title":"To do:"},{"location":"todo/#list-of-deliverables","text":"A deployment package which includes Python code to: (In-progress)_ Creation of \"final\" Python package which delivers code artifacts as a library. Documentation (In-progress) Generated from python docstring using Sphinx mkdocs-material framework (In-progress) Documentation of supporting infrastructure including DNS and SMP provisioning specifically called out as a parallel value-add result of the project.","title":"List of Deliverables"},{"location":"tools_and_resources/","text":"Tools and Resources GOAL: Create, test, deploy, and maintain code to the highest professional standards. HOW: Tools and best practices which facilitate development of high quality code with testable and reproducible outcomes. Quick Guide Tool Minimal requirements Programming Language Python 3.6 or above. Computer Supports running Python 3.6 or above. OS Mac, Windows, or Windows w/WSL2. Documents and resources. GitHub and BPC-Technical-Workgroup-Folder - Google Drive Programming Languages The primary programming language for the project is Python. Knowledge of other enabling technologies, specifically shell scripting (e.g., ZSH, BASH, or PowerShell) and CommonMark or GitHub Flavored Markdown may be helpful. All effort will be made to remain within the Python Standard Library . Other publicly hosted packages with an open source license may be implemented. Version of Python Select a minimum version of Python 3.6. This will include newer features such as f-string. Python 3.10 is recommended. Operating System OS Considerations Mac OS Included system version of Python 2.x must be respected. Make sure to use Python virtual environments. Windows Latest version of Python are now available on the Windows Store. Anaconda3 is an especially good option in this OS. Windows w/WSL2 WSL2 allows implementation of native Ubuntu on Windows for a linux based Python install while using Windows tools. Integration of virtual environments and Python executable with an IDE like VS Code can be finicky. Linux Native support for distributed technologies, i.e., Kubernetes and Docker. Chrome OS Limited on-device resources but a growing number of online and cloud development options, e.g., AWS, Azure, OpenShift, JupyterLab and Notebooks. Raspberry PI With native Python support, Linux packages, and cloud options there is no reason dev is not an option. Additional Configuration and Environment Considerations Future looking consideration for implementation of additional Python enabling technology in support of scalability, portability, and resiliency includes: Frameworks: Django Flask FastAPI OpenAPI Containerization and Cloud Services: Docker Cloud services such as: Amazon Web Services (AWS) including lambdas and Route53 DNS Microsoft Azure RedHat OpenShift Additional infrastructure components may be implemented by the Project for testing or prototyping utilization of cloud services. Local testing of Docker containerization may be done on a desktop. Choice of a cloud infrastructure provider to host and mange Docker containers is at the discretion of the application implementer. Python Programming Methodologies, Standards, and Tools: Python Coding Standards: PEP20 - The Zen of Python PEP8 - The Style Guide for Python Code Guiding Design Principles from the Scientific Python Cookiecutter . Python Doc the official Python web site page of references to more documentation. See the list of books below for additional guidance on standards and best practices in Python development . Tools in bold are used to validate code against PEP8 and PEP20 standards and must complete successfully in order to do a pull into GitHub, bold ) . flake8 autopep8 pylint pytest unittest bandit mypy pycodestyle pydocstyle Development methodologies Documentation and use of docstrings PEP257 [Google/numpy style docstings as documented in the Google Python Style Guide . This document is also provides additional best practices for professional Python devleopers. Domain Driven Design. See the list of books below for original and supplemental sources material by Eric Evans and Vaughn Vernon. Test Driven Development. See the list of books below for original source material by Harry J.W. Percival. Agile principles applied appropriate to the the size and state of the project. Books There are many great reference materials in print and on the Internet about Python development. Below are references that may be helpful. The Hitchhiker's Guide to Python by Kenneth Reitz and Tanya Schlusser. Online for free at docs.python-guide.org . Serious Python by Julien Danjou Domain-Driven Design Distilled by Vaughn Vernon Domain Driven Design: Tackling Complexity in the Heart of Software by Eric Evans Test Driven Development with Python: Obey the Testing Goat, etc. by Harry J.W. Percival. Also available online for free . Architecture Patterns with Python by Harry J.W. Percival and Bob Gregory Pro Git by Scott Chacon and Ben Straub. Available as a free download under an open source license.","title":"Tools and Resources"},{"location":"tools_and_resources/#tools-and-resources","text":"GOAL: Create, test, deploy, and maintain code to the highest professional standards. HOW: Tools and best practices which facilitate development of high quality code with testable and reproducible outcomes.","title":"Tools and Resources"},{"location":"tools_and_resources/#quick-guide","text":"Tool Minimal requirements Programming Language Python 3.6 or above. Computer Supports running Python 3.6 or above. OS Mac, Windows, or Windows w/WSL2. Documents and resources. GitHub and BPC-Technical-Workgroup-Folder - Google Drive","title":"Quick Guide"},{"location":"tools_and_resources/#programming-languages","text":"The primary programming language for the project is Python. Knowledge of other enabling technologies, specifically shell scripting (e.g., ZSH, BASH, or PowerShell) and CommonMark or GitHub Flavored Markdown may be helpful. All effort will be made to remain within the Python Standard Library . Other publicly hosted packages with an open source license may be implemented.","title":"Programming Languages"},{"location":"tools_and_resources/#version-of-python","text":"Select a minimum version of Python 3.6. This will include newer features such as f-string. Python 3.10 is recommended.","title":"Version of Python"},{"location":"tools_and_resources/#operating-system","text":"OS Considerations Mac OS Included system version of Python 2.x must be respected. Make sure to use Python virtual environments. Windows Latest version of Python are now available on the Windows Store. Anaconda3 is an especially good option in this OS. Windows w/WSL2 WSL2 allows implementation of native Ubuntu on Windows for a linux based Python install while using Windows tools. Integration of virtual environments and Python executable with an IDE like VS Code can be finicky. Linux Native support for distributed technologies, i.e., Kubernetes and Docker. Chrome OS Limited on-device resources but a growing number of online and cloud development options, e.g., AWS, Azure, OpenShift, JupyterLab and Notebooks. Raspberry PI With native Python support, Linux packages, and cloud options there is no reason dev is not an option.","title":"Operating System"},{"location":"tools_and_resources/#additional-configuration-and-environment-considerations","text":"Future looking consideration for implementation of additional Python enabling technology in support of scalability, portability, and resiliency includes:","title":"Additional Configuration and Environment Considerations"},{"location":"tools_and_resources/#frameworks","text":"Django Flask FastAPI OpenAPI","title":"Frameworks:"},{"location":"tools_and_resources/#containerization-and-cloud-services","text":"Docker Cloud services such as: Amazon Web Services (AWS) including lambdas and Route53 DNS Microsoft Azure RedHat OpenShift Additional infrastructure components may be implemented by the Project for testing or prototyping utilization of cloud services. Local testing of Docker containerization may be done on a desktop. Choice of a cloud infrastructure provider to host and mange Docker containers is at the discretion of the application implementer.","title":"Containerization and Cloud Services:"},{"location":"tools_and_resources/#python-programming-methodologies-standards-and-tools","text":"Python Coding Standards: PEP20 - The Zen of Python PEP8 - The Style Guide for Python Code Guiding Design Principles from the Scientific Python Cookiecutter . Python Doc the official Python web site page of references to more documentation. See the list of books below for additional guidance on standards and best practices in Python development . Tools in bold are used to validate code against PEP8 and PEP20 standards and must complete successfully in order to do a pull into GitHub, bold ) . flake8 autopep8 pylint pytest unittest bandit mypy pycodestyle pydocstyle","title":"Python Programming Methodologies, Standards, and Tools:"},{"location":"tools_and_resources/#development-methodologies","text":"Documentation and use of docstrings PEP257 [Google/numpy style docstings as documented in the Google Python Style Guide . This document is also provides additional best practices for professional Python devleopers. Domain Driven Design. See the list of books below for original and supplemental sources material by Eric Evans and Vaughn Vernon. Test Driven Development. See the list of books below for original source material by Harry J.W. Percival. Agile principles applied appropriate to the the size and state of the project.","title":"Development methodologies"},{"location":"tools_and_resources/#books","text":"There are many great reference materials in print and on the Internet about Python development. Below are references that may be helpful. The Hitchhiker's Guide to Python by Kenneth Reitz and Tanya Schlusser. Online for free at docs.python-guide.org . Serious Python by Julien Danjou Domain-Driven Design Distilled by Vaughn Vernon Domain Driven Design: Tackling Complexity in the Heart of Software by Eric Evans Test Driven Development with Python: Obey the Testing Goat, etc. by Harry J.W. Percival. Also available online for free . Architecture Patterns with Python by Harry J.W. Percival and Bob Gregory Pro Git by Scott Chacon and Ben Straub. Available as a free download under an open source license.","title":"Books"},{"location":"urn/","text":"e-invoice Onboarding Toolkit API URN Module","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"urn/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"urn/#urn-module","text":"","title":"URN Module"},{"location":"urn_handler/","text":"e-invoice Onboarding Toolkit API urn_handler Module No Representations or Warranties THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"urn_handler/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"urn_handler/#urn_handler-module","text":"","title":"urn_handler Module"},{"location":"urn_hasher/","text":"e-invoice Onboarding Toolkit API urn_hasher Module No Representations or Warranties THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"urn_hasher/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"urn_hasher/#urn_hasher-module","text":"","title":"urn_hasher Module"},{"location":"using_the_modules/","text":"Integrating Code Modules The Package Structure and Using the Modules How the package is organized. The top level of the packages is named \"einvoice.\" It is the parent to all other packages and modules. Directory Structure dot Notation ./einvoice einvoice There are two sub-packages called discovery and delivery. A directory named \"test\" contains unit tests for both delivery and discovery. A third directory named \"docs\" is also at this level and contains project documentation. Directory Structure dot Notation ./einvoice einvoice ./einvoice/discovery einvoice.discovery ./einvoice/delivery einvoice.delivery ./einvoice/test einvoice.test ./einvoice/docs NA - does not contain code artifacts Third level directory contains the Python modules containing actual application code. Within the discovery directory there is a \"conf\" directory intended for application configuration work, a \"data\" directory for files and applications to generate test data and scenarios. Directory Structure dot Notation ./einvoice einvoice ./einvoice/discovery einvoice.discovery ./einvoice/delivery einvoice.delivery ./einvoice/test einvoice.test ./einvoice/tests/test_app_logging.py einvoice.discovery.tests.test_app_logging.test_log_creation ./einvoice/docs NA - does not contain code artifacts ./einvoice/discovery/conf einvoice.discovery.conf ./einvoice/discovery/data einvoice.discovery.data ./einvoice/discovery/accessor.py, app_handler.py, app_logging.py, create_tracking_id.py, dns_query.py, einvoice_message_package.py, line_item.py, party_address.py, semantic_model.py, smp_query.py, urn_hasher.py, urn.py einvoice.discovery.accessor.Accessor, einvoice.discovery.app_logging.create_logger, etc. ./einvoice/delivery/import_xsd einvoice.delivery.import_xsd.ImportXSD Fourth level directories are the deepest in the application and contain code in the conf and data directories. Directory Structure dot Notation ./einvoice einvoice ./einvoice/discovery einvoice.discovery ./einvoice/delivery einvoice.delivery ./einvoice/test einvoice.test ./einvoice/docs NA - does not contain code artifacts ./einvoice/discovery/conf einvoice.discovery.conf ./einvoice/discovery/data einvoice.discovery.data ./einvoice/discovery/accessor.py, app_handler.py, app_logging.py, create_tracking_id.py, dns_query.py, einvoice_message_package.py, line_item.py, party_address.py, semantic_model.py, smp_query.py, urn_hasher.py, URN.py einvoice.discovery.accessor.Accessor, einvoice.discovery.app_logging.create_logger, etc. ./einvoice/delivery/import_xsd.py einvoice.delivery.import_xsd.ImportXSD ./einvoice/discovery/conf/config_tool.py, smp_config.py einvoice.discovery.conf.config_tool.EInvoiceConfig, etc. ./einvoice/discovery/data/create_sample_data.py einvoice.discovery.data.create_sample_data.CreateSampleData Additional Files Additional files included in the project which are important. File Purpose ./einvoice/delivery/app.log Application log created by app_logging.py for delivery sub-package. ./einvoice/delivery/web_response.log Response logging to feed into a webservice for delivery sub-package. ./einvoice/discovery/app.log Application log created by app_logging.py for discovery sub-package. ./einvoice/discovery/web_response.log Response logging to feed into a webservice for discovery sub-package. ./einvoice/docs Markdown files compiled into the project documentation. ./einvoice/docs/jupyterlab Stored JupyterLab sandboxes which may be shared via Google Colab or downloaded and run on a Jupyter service instance. ./einvoice/docs/pdf Stored PDF files (entity diagrams) which may be included in the documentation. ./einvoice/docs/drawio Stored PDF files (vector graphic diagrams) which may be included in the documentation. ./einvoice/discovery/data/item_list.csv, per_item_list.csv CSV files which contain same data values to populate an einvoice. ./einvoice/tests/ *.sh An assortment of shell scripts to run various linters on the modules. Includes pylint, mypy, flake8, pycodestyle, pydocstyle, and combinations. .einvoice/.env .env.example.dev Configuration files which contain example values for testing purposes. ebms-header-3_20220119.xsd, sample_msg.xml XSD containing schema definition for ebMS header and a sample message to test against. Note on classes with modules. All module code is in classes and methods. All code in the discovery and delivery sub-packages is encapsulated in a class and a method within a class. There are no excutable functions outside of a class. There is no entry point to execute this code and instantiate any of the classes or methods at the command line at this time. Examples of implementing and executing the code can be found in the test cases , Discovery Validation , or the JupyterLab/Notebooks . Test cases are not encapsulated in classes or methods but are instead named functions. The code is as Pythonic as possible in naming files for exactly what they do. The functionality can be broken down as: Dataclasses - modules which define some of the key entities at use in the project. urn.py - Dataclass definition of an urn object. semantic_model.py - Dataclass for the semantic model (the einvoice itself). party_addresss.py - Dataclass for a party entity within the Four-Corner model. line_item.py - Dataclass for a line item on the semantic model (einvoice). einvoice_message_package.py - Dataclass to contain all the information to be transmitted, i.e., the payload, in the einvoice message. Specific workflow actions - modules which execute specific tasks within the process workflow. urn_hasher.py - takes the inputs of the party_id, specification, and schema_id and creates the NAPTR look-up uri. dns_query.py - take the NAPTR look-up uri and execute it against DNS. The output is the SMP uri and the existing URN is passed forward as well. smp_query.py - receives the SMP uri and URN and creates two REST API calls to the endpoint based on the inputs. Executes the webservice calls and receives a response. Parses the response and returns it as a string containing the URI of corner 3 in the model. import_xsd.py - takes as an input an XML file and checks its validity against an XSD. In this case it is the XML of an ebMS message header checked against an AS4 conformance profile. Other \"helper\" modules - accessor.py - module to run the Delivery Validation process, executed via test scripts. create_sample_data.py - construct sample data entities to use in testing the semantic model. create_tracking_id.py - create an arbitrary id with a given configuration to use to track the message through the process. Could be used in lieu of a UUID. app_handler.py - module closest to being an executable form the command line. A prototyye module to run the delivery validation directly, if all required configuration is complete. app_logger.py - a custom logging implemenation to be used by all the other modules, including test modules, to standardize output and aggregate to single stream each for app logging, to system out, and response to a webservice.","title":"The Modules"},{"location":"using_the_modules/#integrating-code-modules","text":"","title":"Integrating Code Modules"},{"location":"using_the_modules/#the-package-structure-and-using-the-modules","text":"How the package is organized. The top level of the packages is named \"einvoice.\" It is the parent to all other packages and modules. Directory Structure dot Notation ./einvoice einvoice There are two sub-packages called discovery and delivery. A directory named \"test\" contains unit tests for both delivery and discovery. A third directory named \"docs\" is also at this level and contains project documentation. Directory Structure dot Notation ./einvoice einvoice ./einvoice/discovery einvoice.discovery ./einvoice/delivery einvoice.delivery ./einvoice/test einvoice.test ./einvoice/docs NA - does not contain code artifacts Third level directory contains the Python modules containing actual application code. Within the discovery directory there is a \"conf\" directory intended for application configuration work, a \"data\" directory for files and applications to generate test data and scenarios. Directory Structure dot Notation ./einvoice einvoice ./einvoice/discovery einvoice.discovery ./einvoice/delivery einvoice.delivery ./einvoice/test einvoice.test ./einvoice/tests/test_app_logging.py einvoice.discovery.tests.test_app_logging.test_log_creation ./einvoice/docs NA - does not contain code artifacts ./einvoice/discovery/conf einvoice.discovery.conf ./einvoice/discovery/data einvoice.discovery.data ./einvoice/discovery/accessor.py, app_handler.py, app_logging.py, create_tracking_id.py, dns_query.py, einvoice_message_package.py, line_item.py, party_address.py, semantic_model.py, smp_query.py, urn_hasher.py, urn.py einvoice.discovery.accessor.Accessor, einvoice.discovery.app_logging.create_logger, etc. ./einvoice/delivery/import_xsd einvoice.delivery.import_xsd.ImportXSD Fourth level directories are the deepest in the application and contain code in the conf and data directories. Directory Structure dot Notation ./einvoice einvoice ./einvoice/discovery einvoice.discovery ./einvoice/delivery einvoice.delivery ./einvoice/test einvoice.test ./einvoice/docs NA - does not contain code artifacts ./einvoice/discovery/conf einvoice.discovery.conf ./einvoice/discovery/data einvoice.discovery.data ./einvoice/discovery/accessor.py, app_handler.py, app_logging.py, create_tracking_id.py, dns_query.py, einvoice_message_package.py, line_item.py, party_address.py, semantic_model.py, smp_query.py, urn_hasher.py, URN.py einvoice.discovery.accessor.Accessor, einvoice.discovery.app_logging.create_logger, etc. ./einvoice/delivery/import_xsd.py einvoice.delivery.import_xsd.ImportXSD ./einvoice/discovery/conf/config_tool.py, smp_config.py einvoice.discovery.conf.config_tool.EInvoiceConfig, etc. ./einvoice/discovery/data/create_sample_data.py einvoice.discovery.data.create_sample_data.CreateSampleData","title":"The Package Structure and Using the Modules"},{"location":"using_the_modules/#additional-files","text":"Additional files included in the project which are important. File Purpose ./einvoice/delivery/app.log Application log created by app_logging.py for delivery sub-package. ./einvoice/delivery/web_response.log Response logging to feed into a webservice for delivery sub-package. ./einvoice/discovery/app.log Application log created by app_logging.py for discovery sub-package. ./einvoice/discovery/web_response.log Response logging to feed into a webservice for discovery sub-package. ./einvoice/docs Markdown files compiled into the project documentation. ./einvoice/docs/jupyterlab Stored JupyterLab sandboxes which may be shared via Google Colab or downloaded and run on a Jupyter service instance. ./einvoice/docs/pdf Stored PDF files (entity diagrams) which may be included in the documentation. ./einvoice/docs/drawio Stored PDF files (vector graphic diagrams) which may be included in the documentation. ./einvoice/discovery/data/item_list.csv, per_item_list.csv CSV files which contain same data values to populate an einvoice. ./einvoice/tests/ *.sh An assortment of shell scripts to run various linters on the modules. Includes pylint, mypy, flake8, pycodestyle, pydocstyle, and combinations. .einvoice/.env .env.example.dev Configuration files which contain example values for testing purposes. ebms-header-3_20220119.xsd, sample_msg.xml XSD containing schema definition for ebMS header and a sample message to test against.","title":"Additional Files"},{"location":"using_the_modules/#note-on-classes-with-modules","text":"All module code is in classes and methods. All code in the discovery and delivery sub-packages is encapsulated in a class and a method within a class. There are no excutable functions outside of a class. There is no entry point to execute this code and instantiate any of the classes or methods at the command line at this time. Examples of implementing and executing the code can be found in the test cases , Discovery Validation , or the JupyterLab/Notebooks . Test cases are not encapsulated in classes or methods but are instead named functions. The code is as Pythonic as possible in naming files for exactly what they do. The functionality can be broken down as: Dataclasses - modules which define some of the key entities at use in the project. urn.py - Dataclass definition of an urn object. semantic_model.py - Dataclass for the semantic model (the einvoice itself). party_addresss.py - Dataclass for a party entity within the Four-Corner model. line_item.py - Dataclass for a line item on the semantic model (einvoice). einvoice_message_package.py - Dataclass to contain all the information to be transmitted, i.e., the payload, in the einvoice message. Specific workflow actions - modules which execute specific tasks within the process workflow. urn_hasher.py - takes the inputs of the party_id, specification, and schema_id and creates the NAPTR look-up uri. dns_query.py - take the NAPTR look-up uri and execute it against DNS. The output is the SMP uri and the existing URN is passed forward as well. smp_query.py - receives the SMP uri and URN and creates two REST API calls to the endpoint based on the inputs. Executes the webservice calls and receives a response. Parses the response and returns it as a string containing the URI of corner 3 in the model. import_xsd.py - takes as an input an XML file and checks its validity against an XSD. In this case it is the XML of an ebMS message header checked against an AS4 conformance profile. Other \"helper\" modules - accessor.py - module to run the Delivery Validation process, executed via test scripts. create_sample_data.py - construct sample data entities to use in testing the semantic model. create_tracking_id.py - create an arbitrary id with a given configuration to use to track the message through the process. Could be used in lieu of a UUID. app_handler.py - module closest to being an executable form the command line. A prototyye module to run the delivery validation directly, if all required configuration is complete. app_logger.py - a custom logging implemenation to be used by all the other modules, including test modules, to standardize output and aggregate to single stream each for app logging, to system out, and response to a webservice.","title":"Note on classes with modules."},{"location":"working_with_the_code/","text":"Getting the code. Pulling the code from GitHub The E-Invoice-Onboarding-Toolkit is a public repository. The code is freely available under an MIT License for individuals and organizations to pull, review, and modify as they chose in order to further their participation with the project. It is entirely possible to pull the code from GitHub anonymously using a link from within the repo. Pulling the code from GitHub Look for the green \"Code\" button which will provide links to clone the code using https, ssh, the git desktop, or a zip file. This is going to pull the repo at the root ./e-invoice-Onboarding-Toolkit level so this directory must not already exist when pulled down or it will overwrite the contents of the pre-existing directlry. Open the folder as a project within your IDE or editor of choice. Those who would like to become more involved and want to do more than anonymously pull code can contribute by: Creating a GitHub account if one hasn't already been created. Installing the GitHub CLI or the GitHub desktop application Configuring the personal profile and Secure Shell/SSH keys to securely submit code to the repository. Contributing code and creating pull requests to integrate with the repo.","title":"Getting the Code"},{"location":"working_with_the_code/#getting-the-code","text":"","title":"Getting the code."},{"location":"working_with_the_code/#pulling-the-code-from-github","text":"The E-Invoice-Onboarding-Toolkit is a public repository. The code is freely available under an MIT License for individuals and organizations to pull, review, and modify as they chose in order to further their participation with the project. It is entirely possible to pull the code from GitHub anonymously using a link from within the repo. Pulling the code from GitHub Look for the green \"Code\" button which will provide links to clone the code using https, ssh, the git desktop, or a zip file. This is going to pull the repo at the root ./e-invoice-Onboarding-Toolkit level so this directory must not already exist when pulled down or it will overwrite the contents of the pre-existing directlry. Open the folder as a project within your IDE or editor of choice. Those who would like to become more involved and want to do more than anonymously pull code can contribute by: Creating a GitHub account if one hasn't already been created. Installing the GitHub CLI or the GitHub desktop application Configuring the personal profile and Secure Shell/SSH keys to securely submit code to the repository. Contributing code and creating pull requests to integrate with the repo.","title":"Pulling the code from GitHub"}]}