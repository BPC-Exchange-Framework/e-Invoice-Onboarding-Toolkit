{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Project Home Welcome Welcome to the E-Invoice Onboarding Toolkit This is a repository for open source software tools created to facilitate market adoption of e-invoices implemented conformant with the Four-Corner Model of an Exchange Framework. Project Goals GOALS: The features of the project as oultined in the project roadmap . Roadmap Feature Feature Phase Purpose of Feature Feature #1 - SML NAPTR DNS Lookup Discovery 1. Create an ID code based on the Buyer's party ID 2. Look the ID code up in a globabl internet datatbase to get the address of a website which has more informaiton about the Buyer. Feature #2 - SMP REST API Query Discovery 3. Contact the website from the previous step to make sure the Buyer can in fact handle receiving an e-invoice and where to send it. Feature #3 - AS4 Message Exchange Delivery 4. Validate that an e-mail message sent to the Buyer is in the correct format. Project Outcomes OUTCOMES: How the features are implemented. Outcome Feature Phase 1. Hashing functionality to derive the URN for look-up in a DNS NAPTR record. Feature #1 Discovery 2. Execute DNS NATPR lookup and extract the relevant SMP URI. Feature #1 Discovery 3. Two REST requests to an SMP server using a SOAP API to retrieve a Corner 3 URI. Feature #1 Discovery 4. Execute the wbe service requests to the SMP server. Feature #2 Discovery 5. Extract the Corner 3 endpoint URI from the response from the SMP server. Feature #2 Discovery 6. Validate an E-Invoice ebMS message header for compliance with an AS4 conformance profile. Feature #3 Delivery For information about E-Invoices and implementing the Four-Corner Model please visit the Business Payments Coalition website . Additional documentation, reference materials, and standards can be found on the Oasis-Open.org website . Start with the ebXML specification Site Map Project Home FAQ Outcomes Assumptions Tools and Resources Configure a Python Environment Package Requirements Getting the Code Using the Code Using the Modules Test Cases Discovery Validation JupyterLab/Notebooks Infrastructure Components Project Roadmap Project Artifacts Workflow Oasis Resources License","title":"Project Home"},{"location":"#project-home","text":"","title":"Project Home"},{"location":"#welcome","text":"Welcome to the E-Invoice Onboarding Toolkit This is a repository for open source software tools created to facilitate market adoption of e-invoices implemented conformant with the Four-Corner Model of an Exchange Framework.","title":"Welcome"},{"location":"#project-goals","text":"GOALS: The features of the project as oultined in the project roadmap . Roadmap Feature Feature Phase Purpose of Feature Feature #1 - SML NAPTR DNS Lookup Discovery 1. Create an ID code based on the Buyer's party ID 2. Look the ID code up in a globabl internet datatbase to get the address of a website which has more informaiton about the Buyer. Feature #2 - SMP REST API Query Discovery 3. Contact the website from the previous step to make sure the Buyer can in fact handle receiving an e-invoice and where to send it. Feature #3 - AS4 Message Exchange Delivery 4. Validate that an e-mail message sent to the Buyer is in the correct format.","title":"Project Goals"},{"location":"#project-outcomes","text":"OUTCOMES: How the features are implemented. Outcome Feature Phase 1. Hashing functionality to derive the URN for look-up in a DNS NAPTR record. Feature #1 Discovery 2. Execute DNS NATPR lookup and extract the relevant SMP URI. Feature #1 Discovery 3. Two REST requests to an SMP server using a SOAP API to retrieve a Corner 3 URI. Feature #1 Discovery 4. Execute the wbe service requests to the SMP server. Feature #2 Discovery 5. Extract the Corner 3 endpoint URI from the response from the SMP server. Feature #2 Discovery 6. Validate an E-Invoice ebMS message header for compliance with an AS4 conformance profile. Feature #3 Delivery For information about E-Invoices and implementing the Four-Corner Model please visit the Business Payments Coalition website . Additional documentation, reference materials, and standards can be found on the Oasis-Open.org website . Start with the ebXML specification","title":"Project Outcomes"},{"location":"#site-map","text":"Project Home FAQ Outcomes Assumptions Tools and Resources Configure a Python Environment Package Requirements Getting the Code Using the Code Using the Modules Test Cases Discovery Validation JupyterLab/Notebooks Infrastructure Components Project Roadmap Project Artifacts Workflow Oasis Resources License","title":"Site Map"},{"location":"_license/","text":"MIT License Copyright (c) 2022 BPC Open Source Tools Project Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"_license/#mit-license","text":"Copyright (c) 2022 BPC Open Source Tools Project Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"},{"location":"accessor/","text":"e-invoice Onboarding Toolkit API accessor Module ::: ./discovery.accessor.Accessor <!-- handler: python selection: members: - __init__ - call_hash - call_dns_lookup - call_smp_service_group_url - call_smp_service_url rendering: show_root_heading: true show_source: true --> :docstring: :members: call_has call_dns_lookup call_smp_service_group_url call_smp_service_url","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"accessor/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"accessor/#accessor-module","text":"::: ./discovery.accessor.Accessor <!-- handler: python selection: members: - __init__ - call_hash - call_dns_lookup - call_smp_service_group_url - call_smp_service_url rendering: show_root_heading: true show_source: true --> :docstring: :members: call_has call_dns_lookup call_smp_service_group_url call_smp_service_url","title":"accessor Module"},{"location":"app_handler/","text":"e-invoice Onboarding Toolkit API app_logging Module ::: discovery/app_handler.create_logger :docstring: :members: create_logger","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"app_handler/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"app_handler/#app_logging-module","text":"::: discovery/app_handler.create_logger :docstring: :members: create_logger","title":"app_logging Module"},{"location":"app_logging/","text":"e-invoice Onboarding Toolkit API app_logging Module ::: discovery/app_logging.create_logger :docstring: :members: create_logger","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"app_logging/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"app_logging/#app_logging-module","text":"::: discovery/app_logging.create_logger :docstring: :members: create_logger","title":"app_logging Module"},{"location":"artifacts/","text":"The Repository Repository Layout This project includes the following files, i.e., \"artifacts\" in .py , . md , . txt and other formats, updated as of: 02/16/2022 (February 16th, 2022) /E-Invoice-Onboarding-Toolkit . \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 README.md \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u251c\u2500\u2500 einvoice \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 delivery \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u2502 \u251c\u2500\u2500 import_xsd.py \u2502 \u2502 \u251c\u2500\u2500 sample_msg.xml \u2502 \u2502 \u2514\u2500\u2500 tests \u2502 \u251c\u2500\u2500 discovery \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 accessor.py \u2502 \u2502 \u251c\u2500\u2500 app_handler.py \u2502 \u2502 \u251c\u2500\u2500 app_logging.py \u2502 \u2502 \u251c\u2500\u2500 conf \u2502 \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 config_tool.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 smp_config.py \u2502 \u2502 \u251c\u2500\u2500 create_tracking_id.py \u2502 \u2502 \u251c\u2500\u2500 data \u2502 \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 create_sample_data.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 item_list.csv \u2502 \u2502 \u2502 \u2514\u2500\u2500 per_item_list.csv \u2502 \u2502 \u251c\u2500\u2500 dns_query.py \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u2502 \u251c\u2500\u2500 ebms-header.xml \u2502 \u2502 \u251c\u2500\u2500 einvoice_message_package.py \u2502 \u2502 \u251c\u2500\u2500 line_item.py \u2502 \u2502 \u251c\u2500\u2500 party_address.py \u2502 \u2502 \u251c\u2500\u2500 semantic_model.py \u2502 \u2502 \u251c\u2500\u2500 smp_query.py \u2502 \u2502 \u251c\u2500\u2500 urn.py \u2502 \u2502 \u2514\u2500\u2500 urn_hasher.py \u2502 \u251c\u2500\u2500 docs \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 _license.md \u2502 \u2502 \u251c\u2500\u2500 accessor.md \u2502 \u2502 \u251c\u2500\u2500 accessor_results.png \u2502 \u2502 \u251c\u2500\u2500 app_handler.md \u2502 \u2502 \u251c\u2500\u2500 app_log.png \u2502 \u2502 \u251c\u2500\u2500 app_logging.md \u2502 \u2502 \u251c\u2500\u2500 artifacts.md \u2502 \u2502 \u251c\u2500\u2500 assumptions.md \u2502 \u2502 \u251c\u2500\u2500 create_tracking_id.md \u2502 \u2502 \u251c\u2500\u2500 custom_theme \u2502 \u2502 \u2502 \u251c\u2500\u2500 css \u2502 \u2502 \u2502 \u2514\u2500\u2500 main.html \u2502 \u2502 \u251c\u2500\u2500 dns_query.md \u2502 \u2502 \u251c\u2500\u2500 drawio \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Entity Relationships 1.3.drawio \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Functional Capabilities 1.2.drawio \u2502 \u2502 \u2502 \u2514\u2500\u2500 Bounded Context - Participant 1.1.drawio \u2502 \u2502 \u251c\u2500\u2500 einvoice_design.xlsx \u2502 \u2502 \u251c\u2500\u2500 einvoice_message_package.md \u2502 \u2502 \u251c\u2500\u2500 enabling_infrastructure_components.md \u2502 \u2502 \u251c\u2500\u2500 faq.md \u2502 \u2502 \u251c\u2500\u2500 flask_integration_on_docker.md \u2502 \u2502 \u251c\u2500\u2500 git_workflow.md \u2502 \u2502 \u251c\u2500\u2500 google_colab_pages.md \u2502 \u2502 \u251c\u2500\u2500 index.md \u2502 \u2502 \u251c\u2500\u2500 jupyterlab \u2502 \u2502 \u2502 \u251c\u2500\u2500 Validate_bdx-as4.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 Validate_bdx-as4_v2.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 dns_query.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20210119.xsd \u2502 \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u2502 \u2502 \u251c\u2500\u2500 naptr_lookup.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 python_dev.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 sample_msg.xml \u2502 \u2502 \u2502 \u251c\u2500\u2500 tracking_id_sandbox.ipynb \u2502 \u2502 \u2502 \u2514\u2500\u2500 urn_hash_work.ipynb \u2502 \u2502 \u251c\u2500\u2500 line_item.md \u2502 \u2502 \u251c\u2500\u2500 oasis_documentation.md \u2502 \u2502 \u251c\u2500\u2500 outcomes.md \u2502 \u2502 \u251c\u2500\u2500 party_address.md \u2502 \u2502 \u251c\u2500\u2500 pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Entity Relationships 1.4.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Functional Capabilities 1.2.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Functional Capabilities 1.3.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Participant 1.1.pdf \u2502 \u2502 \u2502 \u2514\u2500\u2500 Bounded Context - Participants 1.2.pdf \u2502 \u2502 \u251c\u2500\u2500 project_roadmap.md \u2502 \u2502 \u251c\u2500\u2500 python_dev_env.md \u2502 \u2502 \u251c\u2500\u2500 requirements.md \u2502 \u2502 \u251c\u2500\u2500 semantic_model.md \u2502 \u2502 \u251c\u2500\u2500 smp_query.md \u2502 \u2502 \u251c\u2500\u2500 start_to_finish.md \u2502 \u2502 \u251c\u2500\u2500 successful_tests.png \u2502 \u2502 \u251c\u2500\u2500 test_cases.md \u2502 \u2502 \u251c\u2500\u2500 todo.md \u2502 \u2502 \u251c\u2500\u2500 tools_and_resources.md \u2502 \u2502 \u251c\u2500\u2500 urn.md \u2502 \u2502 \u251c\u2500\u2500 urn_handler.md \u2502 \u2502 \u251c\u2500\u2500 urn_hasher.md \u2502 \u2502 \u251c\u2500\u2500 using_the_modules.md \u2502 \u2502 \u2514\u2500\u2500 working_with_the_code.md \u2502 \u251c\u2500\u2500 mkdocs.yml \u2502 \u2514\u2500\u2500 test \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u251c\u2500\u2500 ez_linter.sh \u2502 \u251c\u2500\u2500 flake8_linter.sh \u2502 \u251c\u2500\u2500 hardcore_linter.sh \u2502 \u251c\u2500\u2500 magic_linter.py \u2502 \u251c\u2500\u2500 mypy_linter.sh \u2502 \u251c\u2500\u2500 pycodestyle_linter.sh \u2502 \u251c\u2500\u2500 pydocstyle_linter.sh \u2502 \u251c\u2500\u2500 pylint_linter.sh \u2502 \u251c\u2500\u2500 test_accessor.py \u2502 \u251c\u2500\u2500 test_app_logging.py \u2502 \u251c\u2500\u2500 test_create_sample_data.py \u2502 \u251c\u2500\u2500 test_create_tracking_id.py \u2502 \u251c\u2500\u2500 test_dns_query.py \u2502 \u251c\u2500\u2500 test_import_xsd.py \u2502 \u251c\u2500\u2500 test_line_item.py \u2502 \u251c\u2500\u2500 test_party_address.py \u2502 \u251c\u2500\u2500 test_semantic_model.py \u2502 \u251c\u2500\u2500 test_smp_query.py \u2502 \u251c\u2500\u2500 test_urn.py \u2502 \u251c\u2500\u2500 test_urn_hasher.py \u2502 \u2514\u2500\u2500 unaptr_response.json \u251c\u2500\u2500 requirements.txt \u2514\u2500\u2500 todo.md 13 directories, 113 files","title":"Project Artifacts"},{"location":"artifacts/#the-repository","text":"","title":"The Repository"},{"location":"artifacts/#repository-layout","text":"This project includes the following files, i.e., \"artifacts\" in .py , . md , . txt and other formats, updated as of: 02/16/2022 (February 16th, 2022) /E-Invoice-Onboarding-Toolkit . \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 README.md \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u251c\u2500\u2500 einvoice \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 delivery \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u2502 \u251c\u2500\u2500 import_xsd.py \u2502 \u2502 \u251c\u2500\u2500 sample_msg.xml \u2502 \u2502 \u2514\u2500\u2500 tests \u2502 \u251c\u2500\u2500 discovery \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 accessor.py \u2502 \u2502 \u251c\u2500\u2500 app_handler.py \u2502 \u2502 \u251c\u2500\u2500 app_logging.py \u2502 \u2502 \u251c\u2500\u2500 conf \u2502 \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 config_tool.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 smp_config.py \u2502 \u2502 \u251c\u2500\u2500 create_tracking_id.py \u2502 \u2502 \u251c\u2500\u2500 data \u2502 \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 create_sample_data.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 item_list.csv \u2502 \u2502 \u2502 \u2514\u2500\u2500 per_item_list.csv \u2502 \u2502 \u251c\u2500\u2500 dns_query.py \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u2502 \u251c\u2500\u2500 ebms-header.xml \u2502 \u2502 \u251c\u2500\u2500 einvoice_message_package.py \u2502 \u2502 \u251c\u2500\u2500 line_item.py \u2502 \u2502 \u251c\u2500\u2500 party_address.py \u2502 \u2502 \u251c\u2500\u2500 semantic_model.py \u2502 \u2502 \u251c\u2500\u2500 smp_query.py \u2502 \u2502 \u251c\u2500\u2500 urn.py \u2502 \u2502 \u2514\u2500\u2500 urn_hasher.py \u2502 \u251c\u2500\u2500 docs \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 _license.md \u2502 \u2502 \u251c\u2500\u2500 accessor.md \u2502 \u2502 \u251c\u2500\u2500 accessor_results.png \u2502 \u2502 \u251c\u2500\u2500 app_handler.md \u2502 \u2502 \u251c\u2500\u2500 app_log.png \u2502 \u2502 \u251c\u2500\u2500 app_logging.md \u2502 \u2502 \u251c\u2500\u2500 artifacts.md \u2502 \u2502 \u251c\u2500\u2500 assumptions.md \u2502 \u2502 \u251c\u2500\u2500 create_tracking_id.md \u2502 \u2502 \u251c\u2500\u2500 custom_theme \u2502 \u2502 \u2502 \u251c\u2500\u2500 css \u2502 \u2502 \u2502 \u2514\u2500\u2500 main.html \u2502 \u2502 \u251c\u2500\u2500 dns_query.md \u2502 \u2502 \u251c\u2500\u2500 drawio \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Entity Relationships 1.3.drawio \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Functional Capabilities 1.2.drawio \u2502 \u2502 \u2502 \u2514\u2500\u2500 Bounded Context - Participant 1.1.drawio \u2502 \u2502 \u251c\u2500\u2500 einvoice_design.xlsx \u2502 \u2502 \u251c\u2500\u2500 einvoice_message_package.md \u2502 \u2502 \u251c\u2500\u2500 enabling_infrastructure_components.md \u2502 \u2502 \u251c\u2500\u2500 faq.md \u2502 \u2502 \u251c\u2500\u2500 flask_integration_on_docker.md \u2502 \u2502 \u251c\u2500\u2500 git_workflow.md \u2502 \u2502 \u251c\u2500\u2500 google_colab_pages.md \u2502 \u2502 \u251c\u2500\u2500 index.md \u2502 \u2502 \u251c\u2500\u2500 jupyterlab \u2502 \u2502 \u2502 \u251c\u2500\u2500 Validate_bdx-as4.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 Validate_bdx-as4_v2.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 dns_query.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20210119.xsd \u2502 \u2502 \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u2502 \u2502 \u251c\u2500\u2500 naptr_lookup.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 python_dev.ipynb \u2502 \u2502 \u2502 \u251c\u2500\u2500 sample_msg.xml \u2502 \u2502 \u2502 \u251c\u2500\u2500 tracking_id_sandbox.ipynb \u2502 \u2502 \u2502 \u2514\u2500\u2500 urn_hash_work.ipynb \u2502 \u2502 \u251c\u2500\u2500 line_item.md \u2502 \u2502 \u251c\u2500\u2500 oasis_documentation.md \u2502 \u2502 \u251c\u2500\u2500 outcomes.md \u2502 \u2502 \u251c\u2500\u2500 party_address.md \u2502 \u2502 \u251c\u2500\u2500 pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Entity Relationships 1.4.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Functional Capabilities 1.2.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Functional Capabilities 1.3.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 Bounded Context - Participant 1.1.pdf \u2502 \u2502 \u2502 \u2514\u2500\u2500 Bounded Context - Participants 1.2.pdf \u2502 \u2502 \u251c\u2500\u2500 project_roadmap.md \u2502 \u2502 \u251c\u2500\u2500 python_dev_env.md \u2502 \u2502 \u251c\u2500\u2500 requirements.md \u2502 \u2502 \u251c\u2500\u2500 semantic_model.md \u2502 \u2502 \u251c\u2500\u2500 smp_query.md \u2502 \u2502 \u251c\u2500\u2500 start_to_finish.md \u2502 \u2502 \u251c\u2500\u2500 successful_tests.png \u2502 \u2502 \u251c\u2500\u2500 test_cases.md \u2502 \u2502 \u251c\u2500\u2500 todo.md \u2502 \u2502 \u251c\u2500\u2500 tools_and_resources.md \u2502 \u2502 \u251c\u2500\u2500 urn.md \u2502 \u2502 \u251c\u2500\u2500 urn_handler.md \u2502 \u2502 \u251c\u2500\u2500 urn_hasher.md \u2502 \u2502 \u251c\u2500\u2500 using_the_modules.md \u2502 \u2502 \u2514\u2500\u2500 working_with_the_code.md \u2502 \u251c\u2500\u2500 mkdocs.yml \u2502 \u2514\u2500\u2500 test \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 ebms-header-3_0-20220119.xsd \u2502 \u251c\u2500\u2500 ez_linter.sh \u2502 \u251c\u2500\u2500 flake8_linter.sh \u2502 \u251c\u2500\u2500 hardcore_linter.sh \u2502 \u251c\u2500\u2500 magic_linter.py \u2502 \u251c\u2500\u2500 mypy_linter.sh \u2502 \u251c\u2500\u2500 pycodestyle_linter.sh \u2502 \u251c\u2500\u2500 pydocstyle_linter.sh \u2502 \u251c\u2500\u2500 pylint_linter.sh \u2502 \u251c\u2500\u2500 test_accessor.py \u2502 \u251c\u2500\u2500 test_app_logging.py \u2502 \u251c\u2500\u2500 test_create_sample_data.py \u2502 \u251c\u2500\u2500 test_create_tracking_id.py \u2502 \u251c\u2500\u2500 test_dns_query.py \u2502 \u251c\u2500\u2500 test_import_xsd.py \u2502 \u251c\u2500\u2500 test_line_item.py \u2502 \u251c\u2500\u2500 test_party_address.py \u2502 \u251c\u2500\u2500 test_semantic_model.py \u2502 \u251c\u2500\u2500 test_smp_query.py \u2502 \u251c\u2500\u2500 test_urn.py \u2502 \u251c\u2500\u2500 test_urn_hasher.py \u2502 \u2514\u2500\u2500 unaptr_response.json \u251c\u2500\u2500 requirements.txt \u2514\u2500\u2500 todo.md 13 directories, 113 files","title":"Repository Layout"},{"location":"assumptions/","text":"About the E-Invoice Onboarding Toolkit About This project offers examples of Python code written to interact with an access point or discovery service of a Four-Corner Model. Please see the Business Payments Coalition website for more information and an explanation of the Model. Assumptions The Four-Corner Model The software included with the project assumes a baseline understanding of the Four-Corner Model and its constituent components. Python The primary programming language chosen for the project is Python. To implement and run the code in this project requires a working knowledge of Python. This wiki and additional documentation are intended to further outline how the software is designed to implement the Four-Corner Model.","title":"Assumptions"},{"location":"assumptions/#about-the-e-invoice-onboarding-toolkit","text":"","title":"About the E-Invoice Onboarding Toolkit"},{"location":"assumptions/#about","text":"This project offers examples of Python code written to interact with an access point or discovery service of a Four-Corner Model. Please see the Business Payments Coalition website for more information and an explanation of the Model.","title":"About"},{"location":"assumptions/#assumptions","text":"","title":"Assumptions"},{"location":"assumptions/#the-four-corner-model","text":"The software included with the project assumes a baseline understanding of the Four-Corner Model and its constituent components.","title":"The Four-Corner Model"},{"location":"assumptions/#python","text":"The primary programming language chosen for the project is Python. To implement and run the code in this project requires a working knowledge of Python. This wiki and additional documentation are intended to further outline how the software is designed to implement the Four-Corner Model.","title":"Python"},{"location":"create_tracking_id/","text":"e-invoice Onboarding Toolkit API create_tracking_id Module ::: ediscovery.accessor.Accessor","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"create_tracking_id/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"create_tracking_id/#create_tracking_id-module","text":"::: ediscovery.accessor.Accessor","title":"create_tracking_id Module"},{"location":"discovery_validation/","text":"Start-to-Finish Start-to-Finish Integration There is not currently an \"end-to-end\" test for the E-Invoice Four-Corner Model to validate the workflow in its entirety. The next best use case is a \"Start-to-Finish\" of the discovery process. Discovery validation entails testing: 1. The hashing functionality to derive the URN for look-up from the specification, the party ID, and the schema ID. 2. Executing the DNS NATPR lookup and extracting the relevant SMP URI. 3. Constructing the two REST requests including the smp service group url and the smp service url . 4. Executing the two REST requests to the SMP server. 5. Extracting the Corner 3 endpoint URI from the response from the SMP server. This funcitonality is provided in the accessor.py module and validation is done in a single test case called test_accessor.py. Execute the \"Start-to-Finish\" test as reference in the more detailed instructions for running the test cases . ./einvoice/discovery/pytest tests/test_accessor.py Successful completion of \"Start-to-Finish\" test case. Further review and analysis of the the Start-to_Finish process can be found in the app.log which for the accessor.py module resides in the ./einvoice/discovery directory. Successful completion of \"Start-to-Finish\" test case recorded in the app.log file.","title":"Discovery Validation"},{"location":"discovery_validation/#start-to-finish","text":"","title":"Start-to-Finish"},{"location":"discovery_validation/#start-to-finish-integration","text":"There is not currently an \"end-to-end\" test for the E-Invoice Four-Corner Model to validate the workflow in its entirety. The next best use case is a \"Start-to-Finish\" of the discovery process. Discovery validation entails testing: 1. The hashing functionality to derive the URN for look-up from the specification, the party ID, and the schema ID. 2. Executing the DNS NATPR lookup and extracting the relevant SMP URI. 3. Constructing the two REST requests including the smp service group url and the smp service url . 4. Executing the two REST requests to the SMP server. 5. Extracting the Corner 3 endpoint URI from the response from the SMP server. This funcitonality is provided in the accessor.py module and validation is done in a single test case called test_accessor.py. Execute the \"Start-to-Finish\" test as reference in the more detailed instructions for running the test cases . ./einvoice/discovery/pytest tests/test_accessor.py Successful completion of \"Start-to-Finish\" test case. Further review and analysis of the the Start-to_Finish process can be found in the app.log which for the accessor.py module resides in the ./einvoice/discovery directory. Successful completion of \"Start-to-Finish\" test case recorded in the app.log file.","title":"Start-to-Finish Integration"},{"location":"dns_query/","text":"e-invoice Onboarding Toolkit API dns_query Module","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"dns_query/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"dns_query/#dns_query-module","text":"","title":"dns_query Module"},{"location":"einvoice_message_package/","text":"e-invoice Onboarding Toolkit API einvoice_message_package Module","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"einvoice_message_package/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"einvoice_message_package/#einvoice_message_package-module","text":"","title":"einvoice_message_package Module"},{"location":"faq/","text":"FAQ Q: Who is the audience for this project? A: This software is intended for those interested in participating as service endpoints in a Four-Corner Model framework. The code to implement in the repository is written in the Python programing language. Other toolsets to facilitate the initiative such as Markdown or Docker may also be incorporated where appropriate. Q: What do I need in order to use this code? A: Python 1. Intermediate knowledge of Python. 2. Python 3.6 or greater, Python 3.10 or greater is recommended. . Q: Does this code provide a full end-to-end solution to process an e-invoice? A: This code answers some very domain specific questions regarding e-invoice discovery and delivery using a Four-Corners exchange framework. Specifically it's helpful with: Discovery 1. The hashing functionality to derive the URN for look-up in a DNS NAPTR record. 2. How to do the DNS NATPR lookup and extract the relevant SMP URI. 3. How to construct the two REST requests to an SMP server to retrieve a Corner 3 URI. 4. How to execute the REST requests to the SMP server. 5. How to extract the Corner 3 endpoint URI from the response from the SMP server. Delivery 1. Validating an e-invoice ebXML message header for compliance with an AS4 conformance profile. Q: How do I use the code? A: Here are some ways the code can be examined or worked with: 1. Discovery Valdiation of the URI discovery process.. 2. Test Cases which demonstrate functionality of the modules. 3. Jupyter Notebook sandbox environments at Google Colab Pages which isolate and demonstrate the code in a sandbox. 4. Package/Library API see the Index for links to the code API on the modules themselves.","title":"FAQ"},{"location":"faq/#faq","text":"Q: Who is the audience for this project? A: This software is intended for those interested in participating as service endpoints in a Four-Corner Model framework. The code to implement in the repository is written in the Python programing language. Other toolsets to facilitate the initiative such as Markdown or Docker may also be incorporated where appropriate. Q: What do I need in order to use this code? A: Python 1. Intermediate knowledge of Python. 2. Python 3.6 or greater, Python 3.10 or greater is recommended. . Q: Does this code provide a full end-to-end solution to process an e-invoice? A: This code answers some very domain specific questions regarding e-invoice discovery and delivery using a Four-Corners exchange framework. Specifically it's helpful with: Discovery 1. The hashing functionality to derive the URN for look-up in a DNS NAPTR record. 2. How to do the DNS NATPR lookup and extract the relevant SMP URI. 3. How to construct the two REST requests to an SMP server to retrieve a Corner 3 URI. 4. How to execute the REST requests to the SMP server. 5. How to extract the Corner 3 endpoint URI from the response from the SMP server. Delivery 1. Validating an e-invoice ebXML message header for compliance with an AS4 conformance profile. Q: How do I use the code? A: Here are some ways the code can be examined or worked with: 1. Discovery Valdiation of the URI discovery process.. 2. Test Cases which demonstrate functionality of the modules. 3. Jupyter Notebook sandbox environments at Google Colab Pages which isolate and demonstrate the code in a sandbox. 4. Package/Library API see the Index for links to the code API on the modules themselves.","title":"FAQ"},{"location":"git_workflow/","text":"Sample git workflow A minimal git \"script\" to work with the code. This is a sample workflow of a very rudimentary process to create a branch in Github, add code, and push up to the repo on Github. Create a new branch: git checkout -b <insert branch name here`> Implement your changes Add into the repo: git add . git commit -m <your comment here> git push :pushes your changes up to the remote branch Either create a pull request in Github, or: git checkout main git merge <branch you want to merge here> git push to push main changes up to remote branch No Representations or Warranties This software is free and Open Source offered under an MIT license. The developers of the software make no representations or warranties as to the software or its fitness for a particular purpose. This code is meant for educational and research purposes only. The code is offered \"as-is\" and is not intended to be used in a production environment. It is intended for developers of software related to the 4-corners Model to use as a stepping-off point for further development efforts.","title":"Workflow"},{"location":"git_workflow/#sample-git-workflow","text":"","title":"Sample git workflow"},{"location":"git_workflow/#a-minimal-git-script-to-work-with-the-code","text":"This is a sample workflow of a very rudimentary process to create a branch in Github, add code, and push up to the repo on Github. Create a new branch: git checkout -b <insert branch name here`> Implement your changes Add into the repo: git add . git commit -m <your comment here> git push :pushes your changes up to the remote branch Either create a pull request in Github, or: git checkout main git merge <branch you want to merge here> git push to push main changes up to remote branch","title":"A minimal git \"script\" to work with the code."},{"location":"google_colab_pages/","text":"Jupyter Notebooks on Google Colab Colab Sandboxes JupyterLab is a sandbox development environment which allows for, among other things, rapid prototyping or testing of small units of code. They provide a framework to execute code without building a whole application or even a complete module. Most of the code already incorporated into the project started out in a JupyterLab runtime environment. JupyterLab is also useful for introspection of a piece of code. JupyterLab artifacts worked on for the project are stored as static documents in GitHub in the E-Invoice-Onboarding-Toolkit project under ./einvoice/docs/jupyterlab. Google Colab pages implement JupyterLab runtime with live sandbox environments. Pages can be linked from the E-Invoice-Onboarding-Toolkit GitHub repository, or pulled from the repository and saved locally by anyone with a Google account. URN hashing and DNS NAPTR lookup. The Colab JupyterLab Notebook with examples of how to hash the specification, the schema_id, and the party_id to create the URN and perform the NAPTR DNS query is at this Colab page . Examples 6, 7, 8, and 9 run the hash and submit against a DNS in real-time. The JupyterLab file is: urn_hash_work.ipynb . SMP query The Colab JupyterLab Notebook page with examples of how to transform the URN and party_id and submit it to the SMP URI is at this Colab page . They JupyterLab Notebook file is: smp_url_transformations.ipynb . ebMS Message Header validation The Colab JupyterLab Notebook pages with examples of reading an XSD file and validating an XML file has two Google Colab pages for different aspects of the work. Inspection and validation of the XSD file has this Google Colab Page . The JupyterLab file is: ebMS XML 3 schema.ipynb . Validation of an xml file against the XSD is done using this Google Colab Page The JupyterFile is: Validate_bdx-as4.ipynb . For ease of access these files are copies stored on the drive of one of the project Developers and is free and open to anyone to view and run. Interested individuals should make copies of the Labs for themselves and run on Google Colab under their own account or an instance of JupytyerLab running on Anaconda, VS Code, or a Python install.","title":"JupyterLab/Notebooks"},{"location":"google_colab_pages/#jupyter-notebooks-on-google-colab","text":"","title":"Jupyter Notebooks on Google Colab"},{"location":"google_colab_pages/#colab-sandboxes","text":"JupyterLab is a sandbox development environment which allows for, among other things, rapid prototyping or testing of small units of code. They provide a framework to execute code without building a whole application or even a complete module. Most of the code already incorporated into the project started out in a JupyterLab runtime environment. JupyterLab is also useful for introspection of a piece of code. JupyterLab artifacts worked on for the project are stored as static documents in GitHub in the E-Invoice-Onboarding-Toolkit project under ./einvoice/docs/jupyterlab. Google Colab pages implement JupyterLab runtime with live sandbox environments. Pages can be linked from the E-Invoice-Onboarding-Toolkit GitHub repository, or pulled from the repository and saved locally by anyone with a Google account.","title":"Colab Sandboxes"},{"location":"google_colab_pages/#urn-hashing-and-dns-naptr-lookup","text":"The Colab JupyterLab Notebook with examples of how to hash the specification, the schema_id, and the party_id to create the URN and perform the NAPTR DNS query is at this Colab page . Examples 6, 7, 8, and 9 run the hash and submit against a DNS in real-time. The JupyterLab file is: urn_hash_work.ipynb .","title":"URN hashing and DNS NAPTR lookup."},{"location":"google_colab_pages/#smp-query","text":"The Colab JupyterLab Notebook page with examples of how to transform the URN and party_id and submit it to the SMP URI is at this Colab page . They JupyterLab Notebook file is: smp_url_transformations.ipynb .","title":"SMP query"},{"location":"google_colab_pages/#ebms-message-header-validation","text":"The Colab JupyterLab Notebook pages with examples of reading an XSD file and validating an XML file has two Google Colab pages for different aspects of the work. Inspection and validation of the XSD file has this Google Colab Page . The JupyterLab file is: ebMS XML 3 schema.ipynb . Validation of an xml file against the XSD is done using this Google Colab Page The JupyterFile is: Validate_bdx-as4.ipynb . For ease of access these files are copies stored on the drive of one of the project Developers and is free and open to anyone to view and run. Interested individuals should make copies of the Labs for themselves and run on Google Colab under their own account or an instance of JupytyerLab running on Anaconda, VS Code, or a Python install.","title":"ebMS Message Header validation"},{"location":"infrastructure_components/","text":"Additional Infrastructure Build-out The code is intended to interact with other participants in the Four-Corner Model, including Access Providers, DNS servers and SMP service providers. SML Q: How do you test the toolkit? How do you create a NAPTR DNS record entry on a domain? A: In order to do the SML look-up, the appropriate NAPTR records must be in place. The assumption is that a NAPTR DNS record exists as a key:value pair. A look-up of the \"key\" in the DNS of the NAPTR record will return the \"value.\" The \"key\" is the hashed value of the urn. The value being sought and returned is the URI of the SMP for the next step in the Model. Access Point 1 in Corner 2 may be acting in the role of the SML and handling tasks associated with it. Theses task could include: Constructing the URN Creaitng the hash value of the URN Queryhing the DNS NATPR record URN Returning the SMP URI The Python modules provide examples of some ways the tasks of SML could be accomplished, either as, or by, an Access Point or an organization on its own behalf. For testing purposes there is an application to update a DNS entry with a NAPTR record key:value pair of URN:SMP URI repsonse. The applicatiion updates a the DNS via Amazon Web Services Route53 using the test domain of sc-b2b.us. This allows for the registration of URN hashes in the DNS domain of sc-b2b.us. These entries are live in the DNS and accessible worldwide. The REST API is available at https://sml-api.sc-b2b.us/docs to register SML entries, which are the DNS NATPR records on the sc-b2b.us domain. This process creates the URN hash based in inputs provided by the user. Organizations wishing to register a test URN to use for validation can open an issue in the project for assistance in using the web interface. Once these SML/DNS NATPR entries are created, they can queried using the toolkit to make public queries to DNS NAPTR look-up as soon as propated through the DNS. The code implemented to create the NAPTR DNS record on AWS Route53 is available in the GitHub repository: BPC-OpenSourceTools/sml-service-r53 . SMP There is an application to test the SMP REST API service calls on the same domain as the SML at https://smp-api.sc-b2b.us/docs . This is a REST API to make web service calls to test the toolkit. The SMP s a web service queried by a SOAP API call to return the Corner 3 URI or terminal endpoint. The specification for the actual API can be found in the document: Service Metadata Publishing (SMP) Version 2.0 dated 14 February 2021 as an Oasis standard. Section 5.4 Resources Resource URI Method XML resource root element HTTP Status Description of returned content ServiceGroup ./bdxr-smp-2/[{identifier scheme}::]{participant id} See section 3.6 for {participant id} format GET <ServiceGroup> 200; 500; 404 Holds the Participant Identifier of the recipient, and a list of references to individual ServiceMetadata resources that are associated with that participant identifier. ServiceMetadata ./bdxr-smp-2/[{identifier scheme}::]{participant id}/services/{service ID} See section 3.7 for {service ID} format GET <ServiceMetadata> 200; 500; 404 Holds all of the metadata about a Service, or a redirection URL to another Service Metadata Publisher holding this information. The SMP service registers a URN for query. Note that the API specification is essentially the URN with modifications to include some additional service capability codes but mostly to accomodate characters that would otherwise be illegal in a URL. After registering a URN(s) on the SML service, go to the SMP service at https://sml-api.sc-b2b.us/docs to register the urn there in order to get a reponse for testing SMP query functionality. The code implemented to create the NAPTR DNS record on AWS Route53 is available in the GitHub repository: BPC-OpenSourceTools/smp-service .","title":"Infrastructure Components"},{"location":"infrastructure_components/#additional-infrastructure-build-out","text":"The code is intended to interact with other participants in the Four-Corner Model, including Access Providers, DNS servers and SMP service providers.","title":"Additional Infrastructure Build-out"},{"location":"infrastructure_components/#sml","text":"Q: How do you test the toolkit? How do you create a NAPTR DNS record entry on a domain? A: In order to do the SML look-up, the appropriate NAPTR records must be in place. The assumption is that a NAPTR DNS record exists as a key:value pair. A look-up of the \"key\" in the DNS of the NAPTR record will return the \"value.\" The \"key\" is the hashed value of the urn. The value being sought and returned is the URI of the SMP for the next step in the Model. Access Point 1 in Corner 2 may be acting in the role of the SML and handling tasks associated with it. Theses task could include: Constructing the URN Creaitng the hash value of the URN Queryhing the DNS NATPR record URN Returning the SMP URI The Python modules provide examples of some ways the tasks of SML could be accomplished, either as, or by, an Access Point or an organization on its own behalf. For testing purposes there is an application to update a DNS entry with a NAPTR record key:value pair of URN:SMP URI repsonse. The applicatiion updates a the DNS via Amazon Web Services Route53 using the test domain of sc-b2b.us. This allows for the registration of URN hashes in the DNS domain of sc-b2b.us. These entries are live in the DNS and accessible worldwide. The REST API is available at https://sml-api.sc-b2b.us/docs to register SML entries, which are the DNS NATPR records on the sc-b2b.us domain. This process creates the URN hash based in inputs provided by the user. Organizations wishing to register a test URN to use for validation can open an issue in the project for assistance in using the web interface. Once these SML/DNS NATPR entries are created, they can queried using the toolkit to make public queries to DNS NAPTR look-up as soon as propated through the DNS. The code implemented to create the NAPTR DNS record on AWS Route53 is available in the GitHub repository: BPC-OpenSourceTools/sml-service-r53 .","title":"SML"},{"location":"infrastructure_components/#smp","text":"There is an application to test the SMP REST API service calls on the same domain as the SML at https://smp-api.sc-b2b.us/docs . This is a REST API to make web service calls to test the toolkit. The SMP s a web service queried by a SOAP API call to return the Corner 3 URI or terminal endpoint. The specification for the actual API can be found in the document: Service Metadata Publishing (SMP) Version 2.0 dated 14 February 2021 as an Oasis standard. Section 5.4 Resources Resource URI Method XML resource root element HTTP Status Description of returned content ServiceGroup ./bdxr-smp-2/[{identifier scheme}::]{participant id} See section 3.6 for {participant id} format GET <ServiceGroup> 200; 500; 404 Holds the Participant Identifier of the recipient, and a list of references to individual ServiceMetadata resources that are associated with that participant identifier. ServiceMetadata ./bdxr-smp-2/[{identifier scheme}::]{participant id}/services/{service ID} See section 3.7 for {service ID} format GET <ServiceMetadata> 200; 500; 404 Holds all of the metadata about a Service, or a redirection URL to another Service Metadata Publisher holding this information. The SMP service registers a URN for query. Note that the API specification is essentially the URN with modifications to include some additional service capability codes but mostly to accomodate characters that would otherwise be illegal in a URL. After registering a URN(s) on the SML service, go to the SMP service at https://sml-api.sc-b2b.us/docs to register the urn there in order to get a reponse for testing SMP query functionality. The code implemented to create the NAPTR DNS record on AWS Route53 is available in the GitHub repository: BPC-OpenSourceTools/smp-service .","title":"SMP"},{"location":"line_item/","text":"e-invoice Onboarding Toolkit API line_item Module No Representations or Warranties THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"line_item/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"line_item/#line_item-module","text":"","title":"line_item Module"},{"location":"oasis_documentation/","text":"OASIS Resources Reference Links: Documents OASIS Specifications OASIS ebXML Messaging Services Version 3.0: Part1, Core Features OASIS Standard, October 1, 2007, has: OASIS ebXML Messaging Services Version 3.0: Part 2, Advanced Features dated June 30, 2010 with Normative Reference of: ebXML Messaging Services Version 3.0: Part 2, Advanced Features which is referenced by the following three namespace URIs. OASIS ebXML Messaging Services 3.0 Conformance Profiles , Committee Specification 1, dated April 24, 2010 references the same namespace URI of http://docs.oasis-open.org/ebxml-msg/ns/ebms/v3.0/profiles/200707. AS4 Profile of ebMS 3.0 Version 1.0 dated January 23, 2013. Service Metadata Publishing (SMP) Version 2.0 dated 14 February 2021 as an Oasis standard. XML Schema Definitions XSD Files XSD File : ebms-header-3_0-200704 including snippets of sample XML and full SOAP for message headers. Note that the Namespace URI identified in Part1 is incorrect and returns an error message. XSD File : XSD for Routing Input reference parameter XSD File : MessageFragment XSD XSD File : Refactored Core Messaging XSD Namespace URIs Namespaces Namespace URI : ebXML Messaging Services Version 3.0 Core Features) and references: Namespace URI : ebXML Messaging V3 Part 2: Multihop Routing Namespace URI : ebXML Messaging V3 Part 2: Message Fragments","title":"OASIS Resources"},{"location":"oasis_documentation/#oasis-resources","text":"Reference Links:","title":"OASIS Resources"},{"location":"oasis_documentation/#documents","text":"OASIS Specifications OASIS ebXML Messaging Services Version 3.0: Part1, Core Features OASIS Standard, October 1, 2007, has: OASIS ebXML Messaging Services Version 3.0: Part 2, Advanced Features dated June 30, 2010 with Normative Reference of: ebXML Messaging Services Version 3.0: Part 2, Advanced Features which is referenced by the following three namespace URIs. OASIS ebXML Messaging Services 3.0 Conformance Profiles , Committee Specification 1, dated April 24, 2010 references the same namespace URI of http://docs.oasis-open.org/ebxml-msg/ns/ebms/v3.0/profiles/200707. AS4 Profile of ebMS 3.0 Version 1.0 dated January 23, 2013. Service Metadata Publishing (SMP) Version 2.0 dated 14 February 2021 as an Oasis standard.","title":"Documents"},{"location":"oasis_documentation/#xml-schema-definitions","text":"XSD Files XSD File : ebms-header-3_0-200704 including snippets of sample XML and full SOAP for message headers. Note that the Namespace URI identified in Part1 is incorrect and returns an error message. XSD File : XSD for Routing Input reference parameter XSD File : MessageFragment XSD XSD File : Refactored Core Messaging XSD","title":"XML Schema Definitions"},{"location":"oasis_documentation/#namespace-uris","text":"Namespaces Namespace URI : ebXML Messaging Services Version 3.0 Core Features) and references: Namespace URI : ebXML Messaging V3 Part 2: Multihop Routing Namespace URI : ebXML Messaging V3 Part 2: Message Fragments","title":"Namespace URIs"},{"location":"outcomes/","text":"Project Outcomes: Functionality Discovery a. Hashing functionality to derive the URN for look-up in a DNS NAPTR record. b. DNS NATPR lookup and extract the relevant SMP URI. c. Two REST requests to an SMP server to retrieve a Corner 3 URI. d. Execute the REST requests to the SMP server. e. Extract the Corner 3 endpoint URI from the response from the SMP server. Delivery a. Validate an e-invoice ebXML message header for compliance with an AS4 conformance profile. Implementation Functional Python code: Construct the URN from the specification, schema ID, and party ID, urn_hasher.py Hash the URN per the requirements to create a NAPTR record for a DNS look-up to obtain SMP service URI. urn_hasher.py accessor.py Execute DNS look-up to obtain the SMP service URI. accessor.py dns_query.py Query the SMP URI using the ebXML specifcation. accessor.py smp_query.py Dataclass object comprised of specification, schema ID, party ID, and a sample JSON E-Invoice payload. einvoice_message_package.py line_item_py party_address.py semnantic_model.py URN.py Test cases implemented using Test Driven Development test_accessor.py test_app_logging.py test_create_sample_data.py test_create_tracking_id.py test_dns_query.py test_import_xsd.py test_line_item.py test_party_address.py test_semantic_model.py test_smp_query.py test_urn.py test_urn_hasher.py Logging implemented through custom logging using standard Python modules. app_loggiing.py Documentation and code artifacts for Infrastructure components: Demonstrating implementation of DNS infrastructure using Amazon Route53 and code to provision, update, and delete NATPR records, acting as the SML. Demonstrating implementation of SMP infrastructure to reply to the REST API for service functionally and AS4 final endpoint. Documentation Previously created documentation and diagrams which were outcomes of analysis and process review. Jupyter Lab Notebooks running on Google Colab for real-time examples of a dev sandbox. Hash URN and SML query Lab Notebook (Hash URN and SML query are in the same Notebook) SMP query Lab Notebook Review of AS4 XSD specification Lab Notebook Validation of ebMS sample message header against AS4 XSD Lab Notebook Implementation Guide Documentation site written to facilitate utilization of the code and work product to be delivered via readthedocs.org site though the GitHub repository. readthedocs.org site registration/creation Create document set using mkdocs-material hosted on GitHub repository. Create list of assumptions FAQ and Outcomes pages for starting point/baseline documentation. Consolidation of documentation in the GitHub repository. To do A deployment package which includes Python code to: (In-progress)_ Creation of \"final\" Python package which delivers code artifacts as a library. Documentation (In-progress) Generated from python docstring using Sphinx mkdocs-material framework (In-progress) Documentation of supporting infrastructure including DNS and SMP provisioning. Notes Test-driven development methodology is being implemented to include test cases for code as it is being developed and delivered. CI/CD process implemented via GitHub workflow has been validated to ensure PEP8 code standards and checks using flake8, pylint, and pytest are valid. All changes and updates to code must pass CI/CD before it's merged into the repo.","title":"Outcomes"},{"location":"outcomes/#project-outcomes","text":"","title":"Project Outcomes:"},{"location":"outcomes/#functionality","text":"Discovery a. Hashing functionality to derive the URN for look-up in a DNS NAPTR record. b. DNS NATPR lookup and extract the relevant SMP URI. c. Two REST requests to an SMP server to retrieve a Corner 3 URI. d. Execute the REST requests to the SMP server. e. Extract the Corner 3 endpoint URI from the response from the SMP server. Delivery a. Validate an e-invoice ebXML message header for compliance with an AS4 conformance profile.","title":"Functionality"},{"location":"outcomes/#implementation","text":"Functional Python code: Construct the URN from the specification, schema ID, and party ID, urn_hasher.py Hash the URN per the requirements to create a NAPTR record for a DNS look-up to obtain SMP service URI. urn_hasher.py accessor.py Execute DNS look-up to obtain the SMP service URI. accessor.py dns_query.py Query the SMP URI using the ebXML specifcation. accessor.py smp_query.py Dataclass object comprised of specification, schema ID, party ID, and a sample JSON E-Invoice payload. einvoice_message_package.py line_item_py party_address.py semnantic_model.py URN.py Test cases implemented using Test Driven Development test_accessor.py test_app_logging.py test_create_sample_data.py test_create_tracking_id.py test_dns_query.py test_import_xsd.py test_line_item.py test_party_address.py test_semantic_model.py test_smp_query.py test_urn.py test_urn_hasher.py Logging implemented through custom logging using standard Python modules. app_loggiing.py Documentation and code artifacts for Infrastructure components: Demonstrating implementation of DNS infrastructure using Amazon Route53 and code to provision, update, and delete NATPR records, acting as the SML. Demonstrating implementation of SMP infrastructure to reply to the REST API for service functionally and AS4 final endpoint. Documentation Previously created documentation and diagrams which were outcomes of analysis and process review. Jupyter Lab Notebooks running on Google Colab for real-time examples of a dev sandbox. Hash URN and SML query Lab Notebook (Hash URN and SML query are in the same Notebook) SMP query Lab Notebook Review of AS4 XSD specification Lab Notebook Validation of ebMS sample message header against AS4 XSD Lab Notebook Implementation Guide Documentation site written to facilitate utilization of the code and work product to be delivered via readthedocs.org site though the GitHub repository. readthedocs.org site registration/creation Create document set using mkdocs-material hosted on GitHub repository. Create list of assumptions FAQ and Outcomes pages for starting point/baseline documentation. Consolidation of documentation in the GitHub repository.","title":"Implementation"},{"location":"outcomes/#to-do","text":"A deployment package which includes Python code to: (In-progress)_ Creation of \"final\" Python package which delivers code artifacts as a library. Documentation (In-progress) Generated from python docstring using Sphinx mkdocs-material framework (In-progress) Documentation of supporting infrastructure including DNS and SMP provisioning.","title":"To do"},{"location":"outcomes/#notes","text":"Test-driven development methodology is being implemented to include test cases for code as it is being developed and delivered. CI/CD process implemented via GitHub workflow has been validated to ensure PEP8 code standards and checks using flake8, pylint, and pytest are valid. All changes and updates to code must pass CI/CD before it's merged into the repo.","title":"Notes"},{"location":"party_address/","text":"e-invoice Onboarding Toolkit API party_address Module","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"party_address/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"party_address/#party_address-module","text":"","title":"party_address Module"},{"location":"project_roadmap/","text":"Project Roadmap Discovery #1 - SML NAPTR DNS Lookup Feature \u2013 Access Point A sends UNAPTR DNS query with a Party ID/Party ID Schema hash and obtains a valid response with connection information to the SMP. Action Actor Scoped? Generate the request to Access Point A, which includes Party ID, Party ID Schema, Invoice Data Seller No Transform and format contents of Seller\u2019s request to create UNAPTR DNS query Access Point A Yes Query DNS. Access Point A Yes Return response to query SML \u2013 Reply from UNAPTR DNS query. No Receive query response from DNS, which is the URI to the SMP Access Point A Yes Discovery #2 - SMP REST API Query Feature \u2013Access Point A sends a REST API query to the SMP URI to obtain a valid response with connection info of target Access Point and customers invoice capabilities. Action Actor Scoped? Send response with SMP URI to Access Point. SML No (not in this feature) Create REST query to service provider to obtain buyer\u2019s service capabilities. Access Point A Yes Send REST query to service provider to obtain participant\u2019s service capabilities. Access Point A Yes Receive query and send response with Sellers Capabilities and route to endpoint. SMP No Receive response to query of participant\u2019s capabilities. Access Point A Yes Delivery - AS4 Message Exchange Feature \u2013 An invoice with a semantically correct format is delivered using AS4 protocol. Action Actor Scoped? Compose semantically correct E-Invoice based on response from service provider about participant\u2019s capabilities. Access Point A Yes Format E-Invoice in compliant AS4 format. Access Point A Yes Send E-Invoice to final destination obtained from SMP service provider. Access Point A Yes Receives the request. Access Point B No","title":"Project Roadmap"},{"location":"project_roadmap/#project-roadmap","text":"","title":"Project Roadmap"},{"location":"project_roadmap/#discovery-1-sml-naptr-dns-lookup","text":"Feature \u2013 Access Point A sends UNAPTR DNS query with a Party ID/Party ID Schema hash and obtains a valid response with connection information to the SMP. Action Actor Scoped? Generate the request to Access Point A, which includes Party ID, Party ID Schema, Invoice Data Seller No Transform and format contents of Seller\u2019s request to create UNAPTR DNS query Access Point A Yes Query DNS. Access Point A Yes Return response to query SML \u2013 Reply from UNAPTR DNS query. No Receive query response from DNS, which is the URI to the SMP Access Point A Yes","title":"Discovery #1 - SML NAPTR DNS Lookup"},{"location":"project_roadmap/#discovery-2-smp-rest-api-query","text":"Feature \u2013Access Point A sends a REST API query to the SMP URI to obtain a valid response with connection info of target Access Point and customers invoice capabilities. Action Actor Scoped? Send response with SMP URI to Access Point. SML No (not in this feature) Create REST query to service provider to obtain buyer\u2019s service capabilities. Access Point A Yes Send REST query to service provider to obtain participant\u2019s service capabilities. Access Point A Yes Receive query and send response with Sellers Capabilities and route to endpoint. SMP No Receive response to query of participant\u2019s capabilities. Access Point A Yes","title":"Discovery #2 - SMP REST API Query"},{"location":"project_roadmap/#delivery-as4-message-exchange","text":"Feature \u2013 An invoice with a semantically correct format is delivered using AS4 protocol. Action Actor Scoped? Compose semantically correct E-Invoice based on response from service provider about participant\u2019s capabilities. Access Point A Yes Format E-Invoice in compliant AS4 format. Access Point A Yes Send E-Invoice to final destination obtained from SMP service provider. Access Point A Yes Receives the request. Access Point B No","title":"Delivery - AS4 Message Exchange"},{"location":"python_dev_env/","text":"Configure a Python Dev Environment Respecting individual preferences and work style these are some suggested guidelines for creation of a Python development environment. These are consistent with Python standards and best practices and appropriate as a starting point for professional software development in Python. Installing Python The correct method of installing Python varies depending on the OS. Here are some considerations based on popular OS. OS Considerations MacOS Mac OS comes configured with Python 2.x. This version of Python is required by the OS and removal will impair system function. Homebrew is a package installer for Mac. Using Homebrew to install Python versions prior to 3.7 may generate errors on instal due to deprecated libraries. That isues has been resolved for versions 3.7 and higher. Apple XCode Developer Tools installs Git and a version of Python. Available through the App Store it is a large download and system intensive program which may not run smoothly on older or less robust systmes. A more granular installation would be the XCode Command Line Tools which installs Git combined with a Python install pulled directly from Python.org. WindowsOS Python is now available on the Windows Store , though updates may lag behind current Python releases at python.org before arriving on the Windows Store. The option to set environment variables via a UI on a per user basis facilitates multiple installed versions simultaneously. VS Code from Miscrosoft integrates direcltly with a system installled version of Python. Windows WLS2 A fully native Python install on Ubuntu is available for Windows Subsystem for Linux 2 . The version of Python may need to be updated from a secondary repository as the official Ubuntu version trails official Python releases. Integration between VS Code running on Windows and integration with WSL2 Python may require custom configuration. Linux A variety of package managers based on the installed distro enable installation and updates through a GUI or command line. Python3 Python is officially referred to and invoked by specfiying either Python 2.x as \"Python2\" or Python 3.x.x as \"Python3.\" The difference is generally trivial except on Macs where Python2 is included as part of the OS install. On Mac and Linux based systems, adding an alias to .bashrc or .zshrc is an easy way to prevent inadvertent references to an incorrect version of Python, e.g., alias python='python3' alias pip='pip3' Note that the above included an alias for pip to pip3 as well. Create a virtual environment to use for Dev A Python virtual environment is a development sandbox which allows for segmentation of development environments. This allows for management of different combinations and versions of Python releases, deployed packages, development and testing environments, and shifting between entirely different development projects. See the Python documentation for venv for a more detailed explanation and rationalization of Python virtual environments. The use of Python virtual environments can't be overstated as a best practice to organize Python versions and package management. PEP-405 Creating virtual environments to use in Python programming can be done entirely with packages that are include in the Python install or by additional third party applications. The choice of tools to create and manage Python virtual environments is dependent on situation, preference, and use case. Tool/App Use Case venv Implementation of the virtualenv as a Python module included in the Python install since v.3.3. This tool does not require installation outside of the Python distribution itself. virtualenv Includes features not included in venv (see the comparison ). Anaconda A heavyweight package and virtual environment manager. It acts as an \"all in one\" for Python application versions, package management, virtual environments, additional programming languages such as R and Julia and tools such as visualizers and IDEs. The full fledged install can overtax some systems and performance can suffer from an overly ambitious installation configuration. A personal license for individuals is free for non-commercial use. Use by for-profit or governmental organizations with more than 200 people requires licensing. miniconda A slimmed down version of Anaconda focused on virtual environment and package management, includes only conda and Python, not open source, but free. conda The open source package manager utilized by Anaconda and miniconda. pip Included in Python 3.4 and later, this tool does not manage the virtual environment but does handle package management for both venv and virtualenv. Not all python tools have been integrated into the Anaconda repositories or packages for install. Some, such as mkdocs, must still be installed via pip even when using Anaconda3 or miniconda. 'virtualenv venv' vs. 'venv virtualenv' Avoid the confusion of the typical example given in the documentation of virtualenv which uses the command executed as \"virtualenv venv.\" This calls virtualenv to create a virtual environment named venv . Compare with \"venv virtualenv\" which calls venv to create a virtual environment called virtualenv . For most practical purposes when using Python 3.6 or greater it doesn't matter whether venv or virtualenv is used to create the virtual instance. It's recommended to name a virutal environment with a single word unique identifier as the word will be prefixed to the terminal command line when the virtual environment is activated. Other Python Tools Other tools such as virtualenvwrapper , pipenv , pew , tox and nox , poetry , and black may be useful but are not currently utilized in this project. Pyenv was deprecated in Python 3.5 and not utilized.","title":"Configure a Python Dev Environment"},{"location":"python_dev_env/#configure-a-python-dev-environment","text":"Respecting individual preferences and work style these are some suggested guidelines for creation of a Python development environment. These are consistent with Python standards and best practices and appropriate as a starting point for professional software development in Python.","title":"Configure a Python Dev Environment"},{"location":"python_dev_env/#installing-python","text":"The correct method of installing Python varies depending on the OS. Here are some considerations based on popular OS. OS Considerations MacOS Mac OS comes configured with Python 2.x. This version of Python is required by the OS and removal will impair system function. Homebrew is a package installer for Mac. Using Homebrew to install Python versions prior to 3.7 may generate errors on instal due to deprecated libraries. That isues has been resolved for versions 3.7 and higher. Apple XCode Developer Tools installs Git and a version of Python. Available through the App Store it is a large download and system intensive program which may not run smoothly on older or less robust systmes. A more granular installation would be the XCode Command Line Tools which installs Git combined with a Python install pulled directly from Python.org. WindowsOS Python is now available on the Windows Store , though updates may lag behind current Python releases at python.org before arriving on the Windows Store. The option to set environment variables via a UI on a per user basis facilitates multiple installed versions simultaneously. VS Code from Miscrosoft integrates direcltly with a system installled version of Python. Windows WLS2 A fully native Python install on Ubuntu is available for Windows Subsystem for Linux 2 . The version of Python may need to be updated from a secondary repository as the official Ubuntu version trails official Python releases. Integration between VS Code running on Windows and integration with WSL2 Python may require custom configuration. Linux A variety of package managers based on the installed distro enable installation and updates through a GUI or command line. Python3 Python is officially referred to and invoked by specfiying either Python 2.x as \"Python2\" or Python 3.x.x as \"Python3.\" The difference is generally trivial except on Macs where Python2 is included as part of the OS install. On Mac and Linux based systems, adding an alias to .bashrc or .zshrc is an easy way to prevent inadvertent references to an incorrect version of Python, e.g., alias python='python3' alias pip='pip3' Note that the above included an alias for pip to pip3 as well.","title":"Installing Python"},{"location":"python_dev_env/#create-a-virtual-environment-to-use-for-dev","text":"A Python virtual environment is a development sandbox which allows for segmentation of development environments. This allows for management of different combinations and versions of Python releases, deployed packages, development and testing environments, and shifting between entirely different development projects. See the Python documentation for venv for a more detailed explanation and rationalization of Python virtual environments. The use of Python virtual environments can't be overstated as a best practice to organize Python versions and package management. PEP-405 Creating virtual environments to use in Python programming can be done entirely with packages that are include in the Python install or by additional third party applications. The choice of tools to create and manage Python virtual environments is dependent on situation, preference, and use case. Tool/App Use Case venv Implementation of the virtualenv as a Python module included in the Python install since v.3.3. This tool does not require installation outside of the Python distribution itself. virtualenv Includes features not included in venv (see the comparison ). Anaconda A heavyweight package and virtual environment manager. It acts as an \"all in one\" for Python application versions, package management, virtual environments, additional programming languages such as R and Julia and tools such as visualizers and IDEs. The full fledged install can overtax some systems and performance can suffer from an overly ambitious installation configuration. A personal license for individuals is free for non-commercial use. Use by for-profit or governmental organizations with more than 200 people requires licensing. miniconda A slimmed down version of Anaconda focused on virtual environment and package management, includes only conda and Python, not open source, but free. conda The open source package manager utilized by Anaconda and miniconda. pip Included in Python 3.4 and later, this tool does not manage the virtual environment but does handle package management for both venv and virtualenv. Not all python tools have been integrated into the Anaconda repositories or packages for install. Some, such as mkdocs, must still be installed via pip even when using Anaconda3 or miniconda. 'virtualenv venv' vs. 'venv virtualenv' Avoid the confusion of the typical example given in the documentation of virtualenv which uses the command executed as \"virtualenv venv.\" This calls virtualenv to create a virtual environment named venv . Compare with \"venv virtualenv\" which calls venv to create a virtual environment called virtualenv . For most practical purposes when using Python 3.6 or greater it doesn't matter whether venv or virtualenv is used to create the virtual instance. It's recommended to name a virutal environment with a single word unique identifier as the word will be prefixed to the terminal command line when the virtual environment is activated. Other Python Tools Other tools such as virtualenvwrapper , pipenv , pew , tox and nox , poetry , and black may be useful but are not currently utilized in this project. Pyenv was deprecated in Python 3.5 and not utilized.","title":"Create a virtual environment to use for Dev"},{"location":"qq/","text":"Flask Integration, Docker, etc.","title":"Flask Integration, Docker, etc."},{"location":"qq/#flask-integration-docker-etc","text":"","title":"Flask Integration, Docker, etc."},{"location":"requirements/","text":"Project Package Requirements Currently implemented packages: This project utilizes the following packages, all of which should be available under an Open Source license via PyPI . List updated as of: 02/16/2022 (February 16th, 2022) Make sure to source the virtual environment first and then ' pip install <package> ' or ' conda install <package> ' to bring in the package. alabaster argcomplete argh astroid attrs Babel brotlipy certifi cffi charset-normalizer click colorama conda conda-package-handling cryptography dnspython docutils elementpath Faker flake8 future ghp-import idna imagesize importlib-metadata iniconfig isort Jinja2 joblib lazy-object-proxy livereload lunr Markdown MarkupSafe mccabe mergedeep mkautodoc mkdocs mkdocs-autorefs mkdocs-bootstrap mkdocs-material mkdocs-material-extensions mkdocs-print-site-plugin mkdocstrings mypy mypy-extensions nltk packaging pipx platformdirs pluggy psutil py pycodestyle pycosat pycparser pydocstyle pyflakes Pygments pylint pymdown-extensions pyOpenSSL pyparsing PySocks pytest python-dateutil python-dotenv pytkdocs pytz PyYAML pyyaml_env_tag regex requests ruamel-yaml-conda six snowballstemmer text-unidecode toml tomli tornado tqdm types-requests types-urllib3 typing_extensions urllib3 userpath watchdog wrapt xmlschema zipp","title":"Package Requirements"},{"location":"requirements/#project-package-requirements","text":"","title":"Project Package Requirements"},{"location":"requirements/#currently-implemented-packages","text":"This project utilizes the following packages, all of which should be available under an Open Source license via PyPI . List updated as of: 02/16/2022 (February 16th, 2022) Make sure to source the virtual environment first and then ' pip install <package> ' or ' conda install <package> ' to bring in the package. alabaster argcomplete argh astroid attrs Babel brotlipy certifi cffi charset-normalizer click colorama conda conda-package-handling cryptography dnspython docutils elementpath Faker flake8 future ghp-import idna imagesize importlib-metadata iniconfig isort Jinja2 joblib lazy-object-proxy livereload lunr Markdown MarkupSafe mccabe mergedeep mkautodoc mkdocs mkdocs-autorefs mkdocs-bootstrap mkdocs-material mkdocs-material-extensions mkdocs-print-site-plugin mkdocstrings mypy mypy-extensions nltk packaging pipx platformdirs pluggy psutil py pycodestyle pycosat pycparser pydocstyle pyflakes Pygments pylint pymdown-extensions pyOpenSSL pyparsing PySocks pytest python-dateutil python-dotenv pytkdocs pytz PyYAML pyyaml_env_tag regex requests ruamel-yaml-conda six snowballstemmer text-unidecode toml tomli tornado tqdm types-requests types-urllib3 typing_extensions urllib3 userpath watchdog wrapt xmlschema zipp","title":"Currently implemented packages:"},{"location":"semantic_model/","text":"e-invoice Onboarding Toolkit API semantic_model Module No Representations or Warranties THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"semantic_model/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"semantic_model/#semantic_model-module","text":"","title":"semantic_model Module"},{"location":"smp_query/","text":"e-invoice Onboarding Toolkit API smp_query Module No Representations or Warranties THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"smp_query/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"smp_query/#smp_query-module","text":"","title":"smp_query Module"},{"location":"test_cases/","text":"E-Invoice Onboarding Tool-kit Working with the code Test Cases Every module includes a test module in the ./einvoice/test directory. Test cases are written as functions, not classes. The test cases are written as functions and CAN be directly called from the command line. Use Pytest to run the test cases. The use case for the test cases include using Pytest. The Pytest package must be installed in your Python distribution. From the a terminal console, change directory into the ./einvoice/test directory. To see the list of available test files, use either the file browser or the command line. For Windows: dir .\\einvoice\\tests\\ For Mac/*nix/WSL2: ls -al ./einvoice/tests/ The ./test directory must be at the same level as the code. Out of the box, Pytest requires that without additional configuration it must be executed from a directory at the same level of the code that's being tested. That is, test scripts are in ./einvoice/test and code files are in ./einvoice/discovery and ./einvoice/delivery. Pytest will automatically look for files formatted as test files, with \"test\" in the lead of the filename. To execute an inidividual test the syntax is: pytest test_app_logging.py No test is dependent on any other, and each may be run on its own, or run them all at once, in any order. The test will run and either the \"assert\" statement(s) inside will pass or it will fail. Failures MUST be resolved prior to attempting to check code into GitHub as our baseline CI/CD process checks for these failures before committing and will not continue if any are found. The included assert statements currently test a variety of cases up to validation of URN creation, query of the NAPTR DNS record, REST API call to the SMP, and validation of the ebMS header against the AS4 conformance profile. The test folder also contains a number of shell scripts to validate the code using a number of linters including flake8, pylint, mypy, pycodestyte, and pydocstyle. Prior to check in, all code must have all warnings from all linters resolved or noted. Successful completion of all test cases.","title":"Test Cases"},{"location":"test_cases/#e-invoice-onboarding-tool-kit","text":"","title":"E-Invoice Onboarding Tool-kit"},{"location":"test_cases/#working-with-the-code","text":"","title":"Working with the code"},{"location":"test_cases/#test-cases","text":"Every module includes a test module in the ./einvoice/test directory. Test cases are written as functions, not classes. The test cases are written as functions and CAN be directly called from the command line. Use Pytest to run the test cases. The use case for the test cases include using Pytest. The Pytest package must be installed in your Python distribution. From the a terminal console, change directory into the ./einvoice/test directory. To see the list of available test files, use either the file browser or the command line. For Windows: dir .\\einvoice\\tests\\ For Mac/*nix/WSL2: ls -al ./einvoice/tests/ The ./test directory must be at the same level as the code. Out of the box, Pytest requires that without additional configuration it must be executed from a directory at the same level of the code that's being tested. That is, test scripts are in ./einvoice/test and code files are in ./einvoice/discovery and ./einvoice/delivery. Pytest will automatically look for files formatted as test files, with \"test\" in the lead of the filename. To execute an inidividual test the syntax is: pytest test_app_logging.py No test is dependent on any other, and each may be run on its own, or run them all at once, in any order. The test will run and either the \"assert\" statement(s) inside will pass or it will fail. Failures MUST be resolved prior to attempting to check code into GitHub as our baseline CI/CD process checks for these failures before committing and will not continue if any are found. The included assert statements currently test a variety of cases up to validation of URN creation, query of the NAPTR DNS record, REST API call to the SMP, and validation of the ebMS header against the AS4 conformance profile. The test folder also contains a number of shell scripts to validate the code using a number of linters including flake8, pylint, mypy, pycodestyte, and pydocstyle. Prior to check in, all code must have all warnings from all linters resolved or noted. Successful completion of all test cases.","title":"Test Cases"},{"location":"the_hash/","text":"The Four-Corner Model is premised on a NAPTR DNS look-up to obtain the location of the SMP URI. The SMP URI is then used to query the SMP REST API and obtain the Corner 3 URI. The assumption is that a NAPTR DNS record exists as a key:value pair. A look-up of the \"key\" in the DNS of the NAPTR record will return the \"value.\" The \"key\" is the hashed value of the URN. The URN is the composite of the specification, the schema_id, and the party_id. The hash is: 1) concattonate the elements of the URN into a single string value. Note a single colon between the specification and the schema_id and double colon between the schema_id and the party_id. specification + \":\" + schema_id + \"::\" + party_id The Four-Cormer Model stateDiagram-v2 [*] --> Seller Seller --> Access_Point_1 state Access_Point_1 { [*] --> SML state SML { [*] --> Create_Hash state Create_Hash { [*] --> Receive_inputs Receive_inputs --> Concatonate Concatonate --> to_lower_case to_lower_case --> encode_utf8 encode_utf8 --> sha256_hash sha256_hash --> byte_digest_of_hash byte_digest_of_hash --> base32_hash base32_hash --> strip_extra_chars strip_extra_chars --> decode_to_string decode_to_string --> ensure_lower_case ensure_lower_case --> [*] } Create_Hash --> add_domain add_domain --> dns_query state dns_query { [*] --> hashed_urn hashed_urn --> do_dns_look-up do_dns_look-up --> [*] } dns_query --> [*] } SML --> SMP state SMP { [*] --> Create_requests Create_requests --> Request_1 Request_1 --> Request_2 Request_2 --> [*] } SMP --> [*] } Access_Point_1 --> Access_Point_2 Access_Point_2 --> Buyer Buyer --> [*]","title":"The hash"},{"location":"todo/","text":"To do: List of Deliverables A deployment package which includes Python code to: (In-progress)_ Creation of \"final\" Python package which delivers code artifacts as a library. Documentation (In-progress) Generated from python docstring using Sphinx mkdocs-material framework (In-progress) Documentation of supporting infrastructure including DNS and SMP provisioning specifically called out as a parallel value-add result of the project. No Representations or Warranties THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"To do:<hr>"},{"location":"todo/#to-do","text":"","title":"To do:"},{"location":"todo/#list-of-deliverables","text":"A deployment package which includes Python code to: (In-progress)_ Creation of \"final\" Python package which delivers code artifacts as a library. Documentation (In-progress) Generated from python docstring using Sphinx mkdocs-material framework (In-progress) Documentation of supporting infrastructure including DNS and SMP provisioning specifically called out as a parallel value-add result of the project.","title":"List of Deliverables"},{"location":"tools_and_resources/","text":"Tools and Resources GOAL: Create, test, deploy, and maintain code to the highest professional standards. HOW: Tools and best practices which facilitate development of high quality code with testable and reproducible outcomes. Quick Guide Tool Minimal requirements Programming Language Python 3.6 or above. Computer Supports running Python 3.6 or above. OS Mac, Windows, or Windows w/WSL2. Documents and resources. GitHub and BPC-Technical-Workgroup-Folder - Google Drive Programming Languages The primary programming language for the project is Python. Knowledge of other enabling technologies, specifically shell scripting (e.g., ZSH, BASH, or PowerShell) and CommonMark or GitHub Flavored Markdown may be helpful. All effort will be made to remain within the Python Standard Library . Other publicly hosted packages with an open source license may be implemented. Version of Python Select a minimum version of Python 3.6. This will include newer features such as f-string. Python 3.10 is recommended. Operating System OS Considerations Mac OS Included system version of Python 2.x must be respected. Make sure to use Python virtual environments. Windows Latest version of Python are now available on the Windows Store. Anaconda3 is an especially good option in this OS. Windows w/WSL2 WSL2 allows implementation of native Ubuntu on Windows for a linux based Python install while using Windows tools. Integration of virtual environments and Python executable with an IDE like VS Code can be finicky. Linux Native support for distributed technologies, i.e., Kubernetes and Docker. Chrome OS Limited on-device resources but a growing number of online and cloud development options, e.g., AWS, Azure, OpenShift, JupyterLab and Notebooks. Raspberry PI With native Python support, Linux packages, and cloud options there is no reason dev is not an option. Additional Configuration and Environment Considerations Future looking consideration for implementation of additional Python enabling technology in support of scalability, portability, and resiliency includes: Frameworks: Django Flask FastAPI OpenAPI Containerization and Cloud Services: Docker Cloud services such as: Amazon Web Services (AWS) including lambdas and Route53 DNS Microsoft Azure RedHat OpenShift Additional infrastructure components may be implemented by the Project for testing or prototyping utilization of cloud services. Local testing of Docker containerization may be done on a desktop. Choice of a cloud infrastrucute provider to host and mange Docker contaners is at the discretion of the application implementer. Python Programming Methodologies, Standards, and Tools: Python Coding Standards: PEP20 - The Zen of Python PEP8 - The Style Guide for Python Code Guiding Design Principles from the Scientific Python Cookiecutter . Python Doc the official Python web site page of references to more documentation. See the list of books below for additional guidance on standards and best practices in Python development . Tools in bold are used to validate code against PEP8 and PEP20 standards and must complete successfully in order to do a pull into GitHub, bold ) . flake8 autopep8 pylint pytest unittest bandit mypy pycodestyle pydocstyle Development methodologies Documentation and use of docstrings PEP257 [Google/numpy style docstings as documented in the Google Python Style Guide . This document is also provides additional best practices for professional Python devleopers. Domain Driven Design. See the list of books below for original and supplemental sources material by Eric Evans and Vaughn Vernon. Test Driven Development. See the list of books below for original source material by Harry J.W. Percival. Agile principles applied appropriate to the the size and state of the project. Books There are many great reference materials in print and on the Internet about Python development. Below are references that may be helpful. The Hitchhiker's Guide to Python by Kenneth Reitz and Tanya Schlusser. Online for free at docs.python-guide.org . Serious Python by Julien Danjou Domain-Driven Design Distilled by Vaughn Vernon Domain Driven Design: Tackling Complexity in the Heart of Software by Eric Evans Test Driven Development with Python: Obey the Testing Goat, etc. by Harry J.W. Percival. Also available online for free . Architecture Patterns with Python by Harry J.W. Percival and Bob Gregory Pro Git by Scott Chacon and Ben Straub. Available as a free download under an open source license.","title":"Tools and Resources"},{"location":"tools_and_resources/#tools-and-resources","text":"GOAL: Create, test, deploy, and maintain code to the highest professional standards. HOW: Tools and best practices which facilitate development of high quality code with testable and reproducible outcomes.","title":"Tools and Resources"},{"location":"tools_and_resources/#quick-guide","text":"Tool Minimal requirements Programming Language Python 3.6 or above. Computer Supports running Python 3.6 or above. OS Mac, Windows, or Windows w/WSL2. Documents and resources. GitHub and BPC-Technical-Workgroup-Folder - Google Drive","title":"Quick Guide"},{"location":"tools_and_resources/#programming-languages","text":"The primary programming language for the project is Python. Knowledge of other enabling technologies, specifically shell scripting (e.g., ZSH, BASH, or PowerShell) and CommonMark or GitHub Flavored Markdown may be helpful. All effort will be made to remain within the Python Standard Library . Other publicly hosted packages with an open source license may be implemented.","title":"Programming Languages"},{"location":"tools_and_resources/#version-of-python","text":"Select a minimum version of Python 3.6. This will include newer features such as f-string. Python 3.10 is recommended.","title":"Version of Python"},{"location":"tools_and_resources/#operating-system","text":"OS Considerations Mac OS Included system version of Python 2.x must be respected. Make sure to use Python virtual environments. Windows Latest version of Python are now available on the Windows Store. Anaconda3 is an especially good option in this OS. Windows w/WSL2 WSL2 allows implementation of native Ubuntu on Windows for a linux based Python install while using Windows tools. Integration of virtual environments and Python executable with an IDE like VS Code can be finicky. Linux Native support for distributed technologies, i.e., Kubernetes and Docker. Chrome OS Limited on-device resources but a growing number of online and cloud development options, e.g., AWS, Azure, OpenShift, JupyterLab and Notebooks. Raspberry PI With native Python support, Linux packages, and cloud options there is no reason dev is not an option.","title":"Operating System"},{"location":"tools_and_resources/#additional-configuration-and-environment-considerations","text":"Future looking consideration for implementation of additional Python enabling technology in support of scalability, portability, and resiliency includes:","title":"Additional Configuration and Environment Considerations"},{"location":"tools_and_resources/#frameworks","text":"Django Flask FastAPI OpenAPI","title":"Frameworks:"},{"location":"tools_and_resources/#containerization-and-cloud-services","text":"Docker Cloud services such as: Amazon Web Services (AWS) including lambdas and Route53 DNS Microsoft Azure RedHat OpenShift Additional infrastructure components may be implemented by the Project for testing or prototyping utilization of cloud services. Local testing of Docker containerization may be done on a desktop. Choice of a cloud infrastrucute provider to host and mange Docker contaners is at the discretion of the application implementer.","title":"Containerization and Cloud Services:"},{"location":"tools_and_resources/#python-programming-methodologies-standards-and-tools","text":"Python Coding Standards: PEP20 - The Zen of Python PEP8 - The Style Guide for Python Code Guiding Design Principles from the Scientific Python Cookiecutter . Python Doc the official Python web site page of references to more documentation. See the list of books below for additional guidance on standards and best practices in Python development . Tools in bold are used to validate code against PEP8 and PEP20 standards and must complete successfully in order to do a pull into GitHub, bold ) . flake8 autopep8 pylint pytest unittest bandit mypy pycodestyle pydocstyle","title":"Python Programming Methodologies, Standards, and Tools:"},{"location":"tools_and_resources/#development-methodologies","text":"Documentation and use of docstrings PEP257 [Google/numpy style docstings as documented in the Google Python Style Guide . This document is also provides additional best practices for professional Python devleopers. Domain Driven Design. See the list of books below for original and supplemental sources material by Eric Evans and Vaughn Vernon. Test Driven Development. See the list of books below for original source material by Harry J.W. Percival. Agile principles applied appropriate to the the size and state of the project.","title":"Development methodologies"},{"location":"tools_and_resources/#books","text":"There are many great reference materials in print and on the Internet about Python development. Below are references that may be helpful. The Hitchhiker's Guide to Python by Kenneth Reitz and Tanya Schlusser. Online for free at docs.python-guide.org . Serious Python by Julien Danjou Domain-Driven Design Distilled by Vaughn Vernon Domain Driven Design: Tackling Complexity in the Heart of Software by Eric Evans Test Driven Development with Python: Obey the Testing Goat, etc. by Harry J.W. Percival. Also available online for free . Architecture Patterns with Python by Harry J.W. Percival and Bob Gregory Pro Git by Scott Chacon and Ben Straub. Available as a free download under an open source license.","title":"Books"},{"location":"urn/","text":"e-invoice Onboarding Toolkit API URN Module","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"urn/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"urn/#urn-module","text":"","title":"URN Module"},{"location":"urn_handler/","text":"e-invoice Onboarding Toolkit API urn_handler Module No Representations or Warranties THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"urn_handler/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"urn_handler/#urn_handler-module","text":"","title":"urn_handler Module"},{"location":"urn_hasher/","text":"e-invoice Onboarding Toolkit API urn_hasher Module No Representations or Warranties THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"e-invoice Onboarding Toolkit API<hr/>"},{"location":"urn_hasher/#e-invoice-onboarding-toolkit-api","text":"","title":"e-invoice Onboarding Toolkit API"},{"location":"urn_hasher/#urn_hasher-module","text":"","title":"urn_hasher Module"},{"location":"using_the_modules/","text":"Integrating Code Modules The Package Structure and Using the Modules How the package is organized. The top level of the packages is named \"einvoice.\" It is the parent to all other packages and modules. Directory Structure dot Notation ./einvoice einvoice There are two sub-packages called discovery and delivery. A directory named \"test\" contains unit tests for both delivery and discovery. A third directory named \"docs\" is also at this level and contains project documentation. Directory Structure dot Notation ./einvoice einvoice ./einvoice/discovery einvoice.discovery ./einvoice/delivery einvoice.delivery ./einvoice/test einvoice.test ./einvoice/docs NA - does not contain code artifacts Third level directory contains the Python modules containing actual application code. Within the discovery directory there is a \"conf\" directory intended for application configuration work, a \"data\" directory for files and applications to generate test data and scenarios. Directory Structure dot Notation ./einvoice einvoice ./einvoice/discovery einvoice.discovery ./einvoice/delivery einvoice.delivery ./einvoice/test einvoice.test ./einvoice/tests/test_app_logging.py einvoice.discovery.tests.test_app_logging.test_log_creation ./einvoice/docs NA - does not contain code artifacts ./einvoice/discovery/conf einvoice.discovery.conf ./einvoice/discovery/data einvoice.discovery.data ./einvoice/discovery/accessor.py, app_handler.py, app_logging.py, create_tracking_id.py, dns_query.py, einvoice_message_package.py, line_item.py, party_address.py, semantic_model.py, smp_query.py, urn_hasher.py, urn.py einvoice.discovery.accessor.Accessor, einvoice.discovery.app_logging.create_logger, etc. ./einvoice/delivery/import_xsd einvoice.delivery.import_xsd.ImportXSD Fourth level directories are the deepest in the application and contain code in the conf and data directories. Directory Structure dot Notation ./einvoice einvoice ./einvoice/discovery einvoice.discovery ./einvoice/delivery einvoice.delivery ./einvoice/test einvoice.test ./einvoice/docs NA - does not contain code artifacts ./einvoice/discovery/conf einvoice.discovery.conf ./einvoice/discovery/data einvoice.discovery.data ./einvoice/discovery/accessor.py, app_handler.py, app_logging.py, create_tracking_id.py, dns_query.py, einvoice_message_package.py, line_item.py, party_address.py, semantic_model.py, smp_query.py, urn_hasher.py, URN.py einvoice.discovery.accessor.Accessor, einvoice.discovery.app_logging.create_logger, etc. ./einvoice/delivery/import_xsd.py einvoice.delivery.import_xsd.ImportXSD ./einvoice/discovery/conf/config_tool.py, smp_config.py einvoice.discovery.conf.config_tool.EInvoiceConfig, etc. ./einvoice/discovery/data/create_sample_data.py einvoice.discovery.data.create_sample_data.CreateSampleData Additional Files Additional files included in the project which are important. File Purpose ./einvoice/delivery/app.log Application log created by app_logging.py for delivery sub-package. ./einvoice/delivery/web_response.log Response logging to feed into a webservice for delivery sub-package. ./einvoice/discovery/app.log Application log created by app_logging.py for discovery sub-package. ./einvoice/discovery/web_response.log Response logging to feed into a webservice for discovery sub-package. ./einvoice/docs Markdown files compiled into the project documentation. ./einvoice/docs/jupyterlab Stored JupyterLab sandboxes which may be shared via Google Colab or downloaded and run on a Jupyter service instance. ./einvoice/docs/pdf Stored PDF files (entity diagrams) which may be included in the documentation. ./einvoice/docs/drawio Stored PDF files (vector graphic diagrams) which may be included in the documentation. ./einvoice/discovery/data/item_list.csv, per_item_list.csv CSV files which contain same data values to populate an einvoice. ./einvoice/tests/ *.sh An assortment of shell scripts to run various linters on the modules. Includes pylint, mypy, flake8, pycodestyle, pydocstyle, and combinations. .einvoice/.env .env.example.dev Configuration files which contain example values for testing purposes. ebms-header-3_20220119.xsd, sample_msg.xml XSD containing schema definition for ebMS header and a sample message to test against. Note on classes with modules. All module code is in classes and methods. All code in the discovery and delivery sub-packages is encapsulated in a class and a method within a class. There are no excutable functions outside of a class. There is no entry point to execute this code and instantiate any of the classes or methods at the command line at this time. Examples of implementing and executing the code can be found in the test cases , Discovery Validation , or the JupyterLab/Notebooks . Test cases are not encapsulated in classes or methods but are instead named functions. The code is as Pythonic as possible in naming files for exactly what they do. The functionality can be broken down as: Dataclasses - modules which define some of the key entities at use in the project. urn.py - Dataclass definition of an urn object. semantic_model.py - Dataclass for the semantic model (the einvoice itself). party_addresss.py - Dataclass for a party entity within the Four-Corner model. line_item.py - Dataclass for a line item on the semantic model (einvoice). einvoice_message_package.py - Dataclass to contain all the information to be transmitted, i.e., the payload, in the einvoice message. Specific workflow actions - modules which execute specific tasks within the process workflow. urn_hasher.py - takes the inputs of the party_id, specification, and schema_id and creates the NAPTR look-up uri. dns_query.py - take the NAPTR look-up uri and execute it against DNS. The output is the SMP uri and the existing URN is passed forward as well. smp_query.py - receives the SMP uri and URN and creates two REST API calls to the endpoint based on the inputs. Executes the webservice calls and receives a response. Parses the response and returns it as a string containing the URI of corner 3 in the model. import_xsd.py - takes as an input an XML file and checks its validity against an XSD. In this case it is the XML of an ebMS message header checked against an AS4 conformance profile. Other \"helper\" modules - accessor.py - module to run the Delivery Validation process, executed via test scripts. create_sample_data.py - construct sample data entities to use in testing the semantic model. create_tracking_id.py - create an arbitrary id with a given configuration to use to track the message through the process. Could be used in lieu of a UUID. app_handler.py - module closest to being an executable form the command line. A prototyye module to run the delivery validation directly, if all required configuration is complete. app_logger.py - a custom logging implemenation to be used by all the other modules, including test modules, to standardize output and aggregate to single stream each for app logging, to system out, and response to a webservice.","title":"The Modules"},{"location":"using_the_modules/#integrating-code-modules","text":"","title":"Integrating Code Modules"},{"location":"using_the_modules/#the-package-structure-and-using-the-modules","text":"How the package is organized. The top level of the packages is named \"einvoice.\" It is the parent to all other packages and modules. Directory Structure dot Notation ./einvoice einvoice There are two sub-packages called discovery and delivery. A directory named \"test\" contains unit tests for both delivery and discovery. A third directory named \"docs\" is also at this level and contains project documentation. Directory Structure dot Notation ./einvoice einvoice ./einvoice/discovery einvoice.discovery ./einvoice/delivery einvoice.delivery ./einvoice/test einvoice.test ./einvoice/docs NA - does not contain code artifacts Third level directory contains the Python modules containing actual application code. Within the discovery directory there is a \"conf\" directory intended for application configuration work, a \"data\" directory for files and applications to generate test data and scenarios. Directory Structure dot Notation ./einvoice einvoice ./einvoice/discovery einvoice.discovery ./einvoice/delivery einvoice.delivery ./einvoice/test einvoice.test ./einvoice/tests/test_app_logging.py einvoice.discovery.tests.test_app_logging.test_log_creation ./einvoice/docs NA - does not contain code artifacts ./einvoice/discovery/conf einvoice.discovery.conf ./einvoice/discovery/data einvoice.discovery.data ./einvoice/discovery/accessor.py, app_handler.py, app_logging.py, create_tracking_id.py, dns_query.py, einvoice_message_package.py, line_item.py, party_address.py, semantic_model.py, smp_query.py, urn_hasher.py, urn.py einvoice.discovery.accessor.Accessor, einvoice.discovery.app_logging.create_logger, etc. ./einvoice/delivery/import_xsd einvoice.delivery.import_xsd.ImportXSD Fourth level directories are the deepest in the application and contain code in the conf and data directories. Directory Structure dot Notation ./einvoice einvoice ./einvoice/discovery einvoice.discovery ./einvoice/delivery einvoice.delivery ./einvoice/test einvoice.test ./einvoice/docs NA - does not contain code artifacts ./einvoice/discovery/conf einvoice.discovery.conf ./einvoice/discovery/data einvoice.discovery.data ./einvoice/discovery/accessor.py, app_handler.py, app_logging.py, create_tracking_id.py, dns_query.py, einvoice_message_package.py, line_item.py, party_address.py, semantic_model.py, smp_query.py, urn_hasher.py, URN.py einvoice.discovery.accessor.Accessor, einvoice.discovery.app_logging.create_logger, etc. ./einvoice/delivery/import_xsd.py einvoice.delivery.import_xsd.ImportXSD ./einvoice/discovery/conf/config_tool.py, smp_config.py einvoice.discovery.conf.config_tool.EInvoiceConfig, etc. ./einvoice/discovery/data/create_sample_data.py einvoice.discovery.data.create_sample_data.CreateSampleData","title":"The Package Structure and Using the Modules"},{"location":"using_the_modules/#additional-files","text":"Additional files included in the project which are important. File Purpose ./einvoice/delivery/app.log Application log created by app_logging.py for delivery sub-package. ./einvoice/delivery/web_response.log Response logging to feed into a webservice for delivery sub-package. ./einvoice/discovery/app.log Application log created by app_logging.py for discovery sub-package. ./einvoice/discovery/web_response.log Response logging to feed into a webservice for discovery sub-package. ./einvoice/docs Markdown files compiled into the project documentation. ./einvoice/docs/jupyterlab Stored JupyterLab sandboxes which may be shared via Google Colab or downloaded and run on a Jupyter service instance. ./einvoice/docs/pdf Stored PDF files (entity diagrams) which may be included in the documentation. ./einvoice/docs/drawio Stored PDF files (vector graphic diagrams) which may be included in the documentation. ./einvoice/discovery/data/item_list.csv, per_item_list.csv CSV files which contain same data values to populate an einvoice. ./einvoice/tests/ *.sh An assortment of shell scripts to run various linters on the modules. Includes pylint, mypy, flake8, pycodestyle, pydocstyle, and combinations. .einvoice/.env .env.example.dev Configuration files which contain example values for testing purposes. ebms-header-3_20220119.xsd, sample_msg.xml XSD containing schema definition for ebMS header and a sample message to test against.","title":"Additional Files"},{"location":"using_the_modules/#note-on-classes-with-modules","text":"All module code is in classes and methods. All code in the discovery and delivery sub-packages is encapsulated in a class and a method within a class. There are no excutable functions outside of a class. There is no entry point to execute this code and instantiate any of the classes or methods at the command line at this time. Examples of implementing and executing the code can be found in the test cases , Discovery Validation , or the JupyterLab/Notebooks . Test cases are not encapsulated in classes or methods but are instead named functions. The code is as Pythonic as possible in naming files for exactly what they do. The functionality can be broken down as: Dataclasses - modules which define some of the key entities at use in the project. urn.py - Dataclass definition of an urn object. semantic_model.py - Dataclass for the semantic model (the einvoice itself). party_addresss.py - Dataclass for a party entity within the Four-Corner model. line_item.py - Dataclass for a line item on the semantic model (einvoice). einvoice_message_package.py - Dataclass to contain all the information to be transmitted, i.e., the payload, in the einvoice message. Specific workflow actions - modules which execute specific tasks within the process workflow. urn_hasher.py - takes the inputs of the party_id, specification, and schema_id and creates the NAPTR look-up uri. dns_query.py - take the NAPTR look-up uri and execute it against DNS. The output is the SMP uri and the existing URN is passed forward as well. smp_query.py - receives the SMP uri and URN and creates two REST API calls to the endpoint based on the inputs. Executes the webservice calls and receives a response. Parses the response and returns it as a string containing the URI of corner 3 in the model. import_xsd.py - takes as an input an XML file and checks its validity against an XSD. In this case it is the XML of an ebMS message header checked against an AS4 conformance profile. Other \"helper\" modules - accessor.py - module to run the Delivery Validation process, executed via test scripts. create_sample_data.py - construct sample data entities to use in testing the semantic model. create_tracking_id.py - create an arbitrary id with a given configuration to use to track the message through the process. Could be used in lieu of a UUID. app_handler.py - module closest to being an executable form the command line. A prototyye module to run the delivery validation directly, if all required configuration is complete. app_logger.py - a custom logging implemenation to be used by all the other modules, including test modules, to standardize output and aggregate to single stream each for app logging, to system out, and response to a webservice.","title":"Note on classes with modules."},{"location":"working_with_the_code/","text":"Getting the code. Pulling the code from GitHub The E-Invoice-Onboarding-Toolkit is a public repository. The code is freely available under an MIT License for individuals and organizations to pull, review, and modify as they chose in order to further their participation with the project. It is entirely possible to pull the code from GitHub anonymously using a link from within the repo. Pulling the code from GitHub Look for the green \"Code\" button which will provide links to clone the code using https, ssh, the git desktop, or a zip file. This is going to pull the repo at the root ./e-invoice-Onboarding-Toolkit level so this directory must not already exist when pulled down or it will overwrite the contents of the pre-existing directlry. Open the folder as a project within your IDE or editor of choice. Those who would like to become more involved and want to do more than anonymously pull code can contribute by: Creating a GitHub account if one hasn't already been created. Installing the GitHub CLI or the GitHub desktop application Configuring the personal profile and Secure Shell/SSH keys to securely submit code to the repository. Contributing code and creating pull requests to integrate with the repo.","title":"Getting the Code"},{"location":"working_with_the_code/#getting-the-code","text":"","title":"Getting the code."},{"location":"working_with_the_code/#pulling-the-code-from-github","text":"The E-Invoice-Onboarding-Toolkit is a public repository. The code is freely available under an MIT License for individuals and organizations to pull, review, and modify as they chose in order to further their participation with the project. It is entirely possible to pull the code from GitHub anonymously using a link from within the repo. Pulling the code from GitHub Look for the green \"Code\" button which will provide links to clone the code using https, ssh, the git desktop, or a zip file. This is going to pull the repo at the root ./e-invoice-Onboarding-Toolkit level so this directory must not already exist when pulled down or it will overwrite the contents of the pre-existing directlry. Open the folder as a project within your IDE or editor of choice. Those who would like to become more involved and want to do more than anonymously pull code can contribute by: Creating a GitHub account if one hasn't already been created. Installing the GitHub CLI or the GitHub desktop application Configuring the personal profile and Secure Shell/SSH keys to securely submit code to the repository. Contributing code and creating pull requests to integrate with the repo.","title":"Pulling the code from GitHub"}]}